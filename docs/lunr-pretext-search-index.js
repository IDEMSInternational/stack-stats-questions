var ptx_lunr_search_style = "textbook";
var ptx_lunr_docs = [
{
  "id": "frontmatter",
  "level": "1",
  "url": "frontmatter.html",
  "type": "Front Matter",
  "number": "",
  "title": "Front Matter",
  "body": "     "
},
{
  "id": "sec-conceptual-understanding",
  "level": "1",
  "url": "sec-conceptual-understanding.html",
  "type": "Section",
  "number": "1.1",
  "title": "Conceptual Understanding",
  "body": " Conceptual Understanding    Edit a boxplot to match a histogram        Edit a boxplot to match a histogram    <p>Move the qualrtiles and median lines in the box plot so that it is representative of the data displayed in the histogram below.<\/p> [[jsxgraph input-ref-ans1=\"sR1\" input-ref-ans2=\"sR2\" input-ref-ans3=\"sR3\" input-ref-ans4=\"sR4\" input-ref-ans5=\"sR5\" input-ref-ans6=\"sR6\" input-ref-ans7=\"sR7\" input-ref-ans8=\"sR8\"]] function plot_histogram(data, numbars, board) { var numel = data.length; var min_bound = Math.floor(Math.min.apply(Math, data)); var max_bound = Math.ceil(Math.max.apply(Math, data)); var range = max_bound - min_bound; var numbars = Math.abs(Math.ceil(numbars)); if (numbars == 0) { numbars = 1; } var barwidth = range \/ numbars; \/\/var tot = data.reduce((a, b) => a + b, 0); var relfreq = []; for (var b = 0; b < numbars; b++) { var data_in_bar = data.filter(function(d) { if (b == 0) { return (d >= min_bound + b * barwidth) && (d <= min_bound + (b + 1) * barwidth) } else { return (d > min_bound + b * barwidth) && (d <= min_bound + (b + 1) * barwidth) } }); relfreq.push(data_in_bar.length) } var ymax = Math.max.apply(Math, relfreq) \/ barwidth; board.setBoundingBox([min_bound - 0.2 * min_bound, ymax * 1.25, max_bound * 1.2, -(ymax * 0.2)], false); \/\/ create axes var origin = board.create('point', [min_bound - 0.1 * min_bound, 0], { face: '', visible: false, size: 2, name: '', fixed: true }); var y_end = board.create('point', [min_bound - 0.1 * min_bound, ymax * 1.1], { face: '', visible: false, size: 2, name: '', fixed: true }); var x_end = board.create('point', [max_bound * 1.1, 0], { face: '', visible: false, size: 2, name: '', fixed: true }); var x_axis = board.create('segment', [origin, x_end], { strokeColor: 'black', strokeWidth: 1 }); var y_axis = board.create('segment', [origin, y_end], { strokeColor: 'black', strokeWidth: 1 }); var Lx = Math.ceil(range \/ 3); var x_tick_pos = [min_bound, min_bound + Lx, min_bound + 2 * Lx, min_bound + 3 * Lx]; var x_tick_label = [min_bound, min_bound + Lx, min_bound + 2 * Lx, min_bound + 3 * Lx]; x_tick_pos.forEach(function(el, index, arr) { arr[index] = el - 0.9 * min_bound }); var t_x = board.create('ticks', [x_axis, x_tick_pos], { drawLabels: true, labels: x_tick_label, minorTicks: 0, label: { autoPosition: true, offset: [-7.5, -12.5] } }); var Ly = Math.ceil(ymax \/ 3); var y_tick_pos = [0, Ly, 2 * Ly, Math.ceil(ymax)]; var t_y = board.create('ticks', [y_axis, y_tick_pos], { labels: y_tick_pos, drawLabels: true, minorTicks: 0, label: { autoPosition: true, offset: [-25, 0] } }); \/\/plot histogram for (var i = 0; i < numbars; i++) { var p0 = board.create('point', [min_bound + (i) * barwidth, 0], { face: '', visible: false, size: 2, name: '', fixed: true }); var p1 = board.create('point', [min_bound + (i) * barwidth, relfreq[i] \/ barwidth], { face: '', visible: false, size: 2, name: '', fixed: true }); var p2 = board.create('point', [min_bound + (i + 1) * barwidth, 0], { face: '', visible: false, size: 2, name: '', fixed: true }); var p3 = board.create('point', [min_bound + (i + 1) * barwidth, relfreq[i] \/ barwidth], { face: '', visible: false, size: 2, name: '', fixed: true }); board.create('polygon', [p0, p1, p3, p2], { borders: { strokeColor: 'blue' }, fillColor: '' }) } return ymax; } var data = {#dat#}; var numbars = {#numbars#}; var board = JXG.JSXGraph.initBoard(divid, { axis: false, keepaspectratio: false, showCopyright: false, showNavigation: false, pan: {enable: false} }); var maxy = plot_histogram(data, numbars, board); \/\/ Creating box plot \/\/ Define parameters from histogram for box plot var min_x = Math.floor(Math.min.apply(Math, data)); var max_x = Math.ceil(Math.max.apply(Math, data)); var max_y = maxy*1.2; var mid_y = maxy*1.15; var min_y = maxy*1.1; var lq_x = min_x + (max_x - min_x)\/4; var med_x = min_x + (max_x - min_x)\/2; var uq_x = min_x + 3*(max_x - min_x)\/4; \/\/create upper and lower bounds for the box plot var bot_line = board.create('line', [[0, min_y], [1, min_y]], { straightFirst: true, straightLast: true, strokeWidth: 2, visible: false, fixed: true }); var top_line = board.create('line', [[0, max_y], [1, max_y]], { straightFirst: true, straightLast: true, strokeWidth: 2, visible: false, fixed: true }); \/\/ --------------lq vertical and left horizontal lines start var top_lq = board.create('point', [lq_x, max_y], { name: '', visible: false }); var bot_lq = board.create('point', [lq_x, min_y], { name: '', visible: false }); var mid_lq = board.create('point', [lq_x, mid_y], { name: '', visible: false }); var mid_min = board.create('point', [min_x, mid_y], { name: '', visible: false }); var lq_line = board.create('segment', [top_lq, bot_lq], { strokeWidth: 2, visible: true }); var mid_line_left = board.create('segment', [mid_lq, mid_min], { strokeWidth: 2, visible: true, fixed: true }); lq_line.on('drag', function() { bot_lq.moveTo([bot_lq.X(), min_y]); top_lq.moveTo([top_lq.X(), max_y]); mid_lq.moveTo([top_lq.X(), mid_y]); }); \/\/ --------------lq vertical and left horizontal lines end \/\/ --------------med vertical line start var top_med = board.create('point', [med_x, max_y], { name: '', visible: false }); var bot_med = board.create('point', [med_x, min_y], { name: '', visible: false }); var med_line = board.create('segment', [top_med, bot_med], { strokeWidth: 2, visible: true }); med_line.on('drag', function() { bot_med.moveTo([bot_med.X(), min_y]); top_med.moveTo([top_med.X(), max_y]); }); \/\/ --------------med vertical line end \/\/ --------------uq vertical and right horizontal lines start var top_uq = board.create('point', [uq_x, max_y], { name: '', visible: false }); var bot_uq = board.create('point', [uq_x, min_y], { name: '', visible: false }); var uq_line = board.create('segment', [top_uq, bot_uq], { strokeWidth: 2, visible: true }); var mid_uq = board.create('point', [uq_x, mid_y], { name: '', visible: false }); var mid_max = board.create('point', [max_x, mid_y], { name: '', visible: false }); var mid_line_right = board.create('segment', [mid_uq, mid_max], { strokeWidth: 2, visible: true, fixed: true }); uq_line.on('drag', function() { bot_uq.moveTo([bot_uq.X(), min_y]); top_uq.moveTo([top_uq.X(), max_y]); mid_uq.moveTo([top_uq.X(), mid_y]); }); \/\/ --------------uq vertical and right horizontal lines end \/\/ --------------top horizontal line start var top_line = board.create('segment', [top_lq, top_uq], { strokeWidth: 2, visible: true, fixed: true }); top_uq.on('drag', function() { this.moveTo([this.X(), max_y]); top_lq.moveTo([this.X(), max_y]); }); top_lq.on('drag', function() { top_uq.moveTo([this.X(), max_y]); this.moveTo([this.X(), max_y]); }); top_line.on('drag', function() { top_uq.moveTo([top_uq.X(), max_y]); top_lq.moveTo([top_lq.X(), max_y]); }); \/\/ --------------top horizontal line end \/\/ --------------bottom horizontal line start var bot_line = board.create('segment', [bot_lq, bot_uq], { strokeWidth: 2, visible: true, fixed: true }); bot_uq.on('drag', function() { this.moveTo([this.X(), max_y]); bot_lq.moveTo([this.X(), max_y]); }); bot_lq.on('drag', function() { bot_uq.moveTo([this.X(), max_y]); this.moveTo([this.X(), max_y]); }); bot_line.on('drag', function() { bot_uq.moveTo([bot_uq.X(), min_y]); bot_lq.moveTo([bot_lq.X(), mmin_y]); }); \/\/ --------------top horizontal line end \/\/ max and min lines var min_line = board.create('segment', [[min_x,min_y], [min_x,max_y]], { strokeWidth: 2, visible: true, fixed: true }); var max_line = board.create('segment', [[max_x,min_y], [max_x,max_y]], { strokeWidth: 2, visible: true, fixed: true }); \/* Set answers from state of graph *\/ stack_jxg.bind_point(sR1,top_lq); stack_jxg.bind_point(sR2,bot_lq); stack_jxg.bind_point(sR3,top_med); stack_jxg.bind_point(sR4,bot_med); stack_jxg.bind_point(sR5,top_uq); stack_jxg.bind_point(sR6,bot_uq); stack_jxg.bind_point(sR7,mid_lq); stack_jxg.bind_point(sR8,mid_uq); board.unsuspendUpdate(); [[\/jsxgraph]] <p style=\"display:none;\">[[input:ans1]] [[input:ans2]] [[input:ans3]] [[input:ans4]] [[input:ans5]] [[input:ans6]] [[input:ans7]] [[input:ans8]] [[validation:ans1]] [[validation:ans2]] [[validation:ans3]] [[validation:ans4]] [[validation:ans5]] [[validation:ans6]] [[validation:ans7]] [[validation:ans8]]<\/p> <p>[[feedback:prt2]] [[feedback:prt1]] [[feedback:prt3]]<\/p>      1  0.1  0    2025073100    \/* bounds for data *\/ dat_min: rand(101)+100; dat_max: dat_min+30+rand(21); \/* Data size *\/ n: rand(500)+500; \/* Number of bars in histogram *\/ numbars: 30; \/* Selecting Data Type: 1=Normal, 2=Gamma Left, 3=Gamma Right *\/ type: rand([1,2,3]); \/* Define basic data set *\/ dat: if type = 1 then makelist(float(quantile_normal(rand(1.0),0,1)),i,1,n) else makelist(float(quantile_gamma(rand(1.0),2,20)),i,1,n); \/* Set skew if Gamma *\/ dat: if type = 3 then lmax(dat)-lmin(dat)+2-dat else dat; \/* Place data between the bounds *\/ dat: ((dat-lmin(dat))\/(lmax(dat)-lmin(dat)))*(dat_max-dat_min)+dat_min; \/* Range of data *\/ range: dat_max-dat_min; \/* Answers *\/ med: median(dat); lq: quantile(dat,1\/4); uq: quantile(dat,3\/4);       <p>Type = {@type@}, Median = {@med@}, LQ = {@lq@}, UQ = {@uq@}<\/p>      1  0  0   <span style=\"font-size: 1.5em; color:green;\"><i class=\"fa fa-check\"><\/i><\/span> Correct answer, well done.    <span style=\"font-size: 1.5em; color:orange;\"><i class=\"fa fa-adjust\"><\/i><\/span> Your answer is partially correct.    <span style=\"font-size: 1.5em; color:red;\"><i class=\"fa fa-times\"><\/i><\/span> Incorrect answer.   .  *10  dot  1  i  cos-1  lang  [  0    ans1  algebraic  lq  15  1  0   0    0  0  0  0  0     ans2  algebraic  lq  15  1  0   0    0  0  0  0  0     ans3  algebraic  med  15  1  0   0    0  0  0  0  0     ans4  algebraic  med  15  1  0   0    0  0  0  0  0     ans5  algebraic  uq  15  1  0   0    0  0  0  0  0     ans6  algebraic  uq  15  1  0   0    0  0  0  0  0     ans7  algebraic  lq  15  1  0   0    0  0  0  0  0     ans8  algebraic  uq  15  1  0   0    0  0  0  0  0     prt1  1.0000000  1  1   opt_1:0.05*range; opt_2:0.1*range; large_ans:if ans3[1]>=med then 1 else 0; large_ans_text:if ans3[1]>=med then \"large\" else \"small\";    0   NumAbsolute  ans3[1]  med  opt_1  0  =  1   -1  prt1-1-T   Well done, your estimate for the median is close enough.   =  0   1  prt1-1-F       1   NumAbsolute  ans3[1]  med  opt_2  0  +  0.5   -1  prt1-2-T   Your estimate for the median is almost close enough, it's a bit too {@large_ans_text@}.   -  0   2  prt1-2-F   Unfortunately your estimate of the median is not close enough to a correct estimate.     2   AlgEquiv  large_ans  1   0  +  0   -1  prt1-3-T   Your estimate is too large.   -  0   -1  prt1-3-F   Your estimate is too small.      prt2  1.0000000  1  1   opt_1:0.05*range; opt_2:0.1*range; large_ans:if ans1[1]>=lq then 1 else 0; large_ans_text:if ans1[1]>=lq then \"large\" else \"small\";    0   NumAbsolute  ans1[1]  lq  opt_1  0  =  1   -1  prt2-1-T   Well done, your estimate for the lower quartile is close enough.   =  0   1  prt2-1-F       1   NumAbsolute  ans1[1]  lq  opt_2  0  +  0.5   -1  prt2-2-T   Your estimate for the lower quartile is almost close enough, it's a bit too {@large_ans_text@}.   -  0   2  prt2-2-F   Unfortunately your estimate of the lower quartile is not close enough to a correct estimate.     2   AlgEquiv  large_ans  1   0  +  0   -1  prt2-3-T   Your estimate is too large.   -  0   -1  prt2-3-F   Your estimate is too small.      prt3  1.0000000  1  1   opt_1:0.05*range; opt_2:0.1*range; large_ans:if ans5[1]>=uq then 1 else 0; large_ans_text:if ans5[1]>=uq then \"large\" else \"small\";    0   NumAbsolute  ans5[1]  uq  opt_1  0  =  1   -1  prt3-1-T   Well done, your estimate for the upper quartile is close enough.   =  0   1  prt3-1-F       1   NumAbsolute  ans5[1]  uq  opt_2  0  +  0.5   -1  prt3-2-T   Your estimate for the upper quartile is almost close enough, it's a bit too {@large_ans_text@}.   -  0   2  prt3-2-F   Unfortunately your estimate of the upper quartile is not close enough to a correct estimate.     2   AlgEquiv  large_ans  1   0  +  0   -1  prt3-3-T   Your estimate is too large.   -  0   -1  prt3-3-F   Your estimate is too small.     77384836  235567728  1589206665  767841902  1092264646  309265945  970716851  1115168224  2117995222  16411044  1431488676  824330149  1190443805  243149845  2107269049  835664865  1519590387  485579999  152679216  930324489  1935418237  453203050  1327552098  1420484212  458531632  1812056681  594436593  1220322723  1087557332  361407698  651252019  1752621535  1337254718  1398461573  1369267218  193444948  1884462108  1167804306  1647681732  1265122426  1113491355  1610693537  1785573104  2030037368  1187620484  192368422  1636864513  1453794362  202149253  587550808  1370276933  1939551163  2048641242  13384177  1333548865  1389042349  1896602370  548771737  993113194  1984043286  2067058933  270564681  1001345827  707949520  1434884362  1073417388  354622202  1195281229  1225492636  1519547855  291239905  1550307927  1107902666  1025552944  1205263867  1390150655  1438702232  1000667137  1937094549  1450864969  1533160264  1973522587  228822236  532624089  132889023  1250938820  753358693  1897991048  588362107   <\n>  <\n>        Fill ANOVA table for 2-year tomato data        Fill ANOVA table for 2-year tomato data    <p>An experiment was conducted for two years to investigate the effect three factors of light, heat and variety, each at two levels, on the yields of tomatoes.<\/p> <p>Here is an incomplete analysis of variance (ANOVA) table for the tomato data for the <b>\\(2\\) years together<\/b>. <\/p> <p>Complete the ANOVA table.<\/p> <p><b>Give the values to \\(1\\) decimal place.<\/b><\/p> <p> <style type=\"text\/css\"> #maintable td.blue {color:#00F;} <\/style> <table> <caption><\/caption> <thead> <tr> <th scope=\"col\" style=\"text-align: center;border: 1px solid black; \" width=\"100\">Term<\/th> <th scope=\"col\" style=\"text-align: center; border: 1px solid black;\" width=\"100\">Df<\/th> <th scope=\"col\" style=\"text-align: center; border: 1px solid black;\" width=\"100\">Sum Sq<\/th> <th scope=\"col\" style=\"text-align: center;border: 1px solid black;\" width=\"100\">Mean Sq<\/th> <th scope=\"col\" style=\"text-align: center; border: 1px solid black;\" width=\"100\">F Value<\/th> <\/tr> <\/thead> <tbody> <tr> <td style=\"text-align: center;border: 1px solid black; \">Light<\/td> <td style=\"text-align: center;border: 1px solid black; \">{@light_df@}<\/td> <td style=\"text-align: center;border: 1px solid black; \">{@light_ss@}<\/td> <td style=\"text-align: center;border: 1px solid black; \">[[input:ans4]] [[validation:ans4]] [[feedback:prt4]]<\/td> <td style=\"text-align: center;border: 1px solid black; \">[[input:ans8]] [[validation:ans8]] [[feedback:prt8]]<\/td> <\/tr> <tr> <td style=\"text-align: center;border: 1px solid black; \">Heat<\/td> <td style=\"text-align: center;border: 1px solid black; \">{@heat_df@}<\/td> <td style=\"text-align: center;border: 1px solid black; \">{@heat_ss@}<\/td> <td style=\"text-align: center;border: 1px solid black; \">[[input:ans5]] [[validation:ans5]] [[feedback:prt5]]<\/td> <td style=\"text-align: center;border: 1px solid black; \">[[input:ans9]] [[validation:ans9]] [[feedback:prt9]]<\/td> <\/tr> <tr> <td style=\"text-align: center;border: 1px solid black; \">Variety<\/td> <td style=\"text-align: center;border: 1px solid black; \">[[input:ans1]] [[validation:ans1]] [[feedback:prt1a]]<\/td> <td style=\"text-align: center;border: 1px solid black; \">{@variety_ss@}<\/td> <td style=\"text-align: center;border: 1px solid black; \">[[input:ans6]] [[validation:ans6]] [[feedback:prt6]]<\/td> <td style=\"text-align: center;border: 1px solid black; \">[[input:ans10]] [[validation:ans10]] [[feedback:prt10]]<\/td> <\/tr> <tr> <td style=\"text-align: center;border: 1px solid black; \">Residuals<\/td> <td style=\"text-align: center;border: 1px solid black; \">[[input:ans2]] [[validation:ans2]] [[feedback:prt2]]<\/td> <td style=\"text-align: center;border: 1px solid black; \">[[input:ans3]] [[validation:ans3]] [[feedback:prt3]]<\/td> <td style=\"text-align: center;border: 1px solid black; \">[[input:ans7]] [[validation:ans7]] [[feedback:prt7]]<\/td> <td style=\"text-align: center;border: 1px solid black; \"><\/td> <\/tr> <tr> <td style=\"text-align: center;border: 1px solid black; \">Total<\/td> <td style=\"text-align: center;border: 1px solid black; \">{@total_df@}<\/td> <td style=\"text-align: center;border: 1px solid black; \">{@total_ss@}<\/td> <td style=\"text-align: center;border: 1px solid black; \"><\/td> <td style=\"text-align: center;border: 1px solid black; \"><\/td> <\/tr> <\/tbody> <\/table> <\/p>    <p>The complete ANOVA table is shown below.<\/p> <p>There are a few key points to remember:<\/p> <ul> <li>The residual is the \"left over\" after taking into account the variables. So the residual Df and sum of squares is the difference between the total values and the sum of the variables values.<\/li> <li>The mean sum of squares is simply the sum of squares per Df.<\/li> <li>The F value is the ratio of the mean sum of squares and the residual sum of squares. It allows us to compare the variability explained by a variable compared to the unexplained (residual) variability.<\/li> <\/ul> <p> <table> <caption><\/caption> <thead> <tr> <th scope=\"col\" style=\"text-align: center;border: 1px solid black; \" width=\"100\">Term<\/th> <th scope=\"col\" style=\"text-align: center; border: 1px solid black;\" width=\"100\">Df<\/th> <th scope=\"col\" style=\"text-align: center; border: 1px solid black;\" width=\"100\">Sum Sq<\/th> <th scope=\"col\" style=\"text-align: center;border: 1px solid black;\" width=\"100\">Mean Sq<\/th> <th scope=\"col\" style=\"text-align: center; border: 1px solid black;\" width=\"100\">F Value<\/th> <\/tr> <\/thead> <tbody> <tr> <td style=\"text-align: center;border: 1px solid black; \">Light<\/td> <td class=\"blue\" style=\"text-align: center;border: 1px solid black; \">{@light_df@}<\/td> <td style=\"text-align: center;border: 1px solid black; \">{@light_ss@}<\/td> <td style=\"color:#00F; text-align: center;border: 1px solid black; \">{@ta4@}<\/td> <td style=\"color:#00F; text-align: center;border: 1px solid black; \">{@ta8@}<\/td> <\/tr> <tr> <td style=\"text-align: center;border: 1px solid black; \">Heat<\/td> <td style=\"text-align: center;border: 1px solid black; \">{@heat_df@}<\/td> <td style=\"text-align: center;border: 1px solid black; \">{@heat_ss@}<\/td> <td style=\"color:#00F; text-align: center;border: 1px solid black; \">{@ta5@}<\/td> <td style=\"color:#00F; text-align: center;border: 1px solid black; \">{@ta9@}<\/td> <\/tr> <tr> <td style=\"text-align: center;border: 1px solid black; \">Variety<\/td> <td style=\"color:#00F; text-align: center;border: 1px solid black; \">{@ta1@}<\/td> <td style=\"text-align: center;border: 1px solid black; \">{@variety_ss@}<\/td> <td style=\"color:#00F; text-align: center;border: 1px solid black; \">{@ta6@}<\/td> <td style=\"color:#00F; text-align: center;border: 1px solid black; \">{@ta10@}<\/td> <\/tr> <tr> <td style=\"text-align: center;border: 1px solid black; \">Residuals<\/td> <td style=\"color:#00F; text-align: center;border: 1px solid black; \">{@ta2@}<\/td> <td style=\"color:#00F; text-align: center;border: 1px solid black; \">{@ta3@}<\/td> <td style=\"color:#00F; text-align: center;border: 1px solid black; \">{@ta7@}<\/td> <td style=\"text-align: center;border: 1px solid black; \"><\/td> <\/tr> <tr> <td style=\"text-align: center;border: 1px solid black; \">Total<\/td> <td style=\"text-align: center;border: 1px solid black; \">{@total_df@}<\/td> <td style=\"text-align: center;border: 1px solid black; \">{@total_ss@}<\/td> <td style=\"text-align: center;border: 1px solid black; \"><\/td> <td style=\"text-align: center;border: 1px solid black; \"><\/td> <\/tr> <\/tbody> <\/table> <\/p>   1  0.1  0    2025073100    dp(x, n) := float(round((x+10^(-8))*10^n)\/10^n); light_df:1 ; heat_df: 1; variety_df: 1; total_df: 23; resid_df: total_df-heat_df-light_df-variety_df; light_ss: dp(float((rand(10)\/10)+(rand(6)+5)),1); heat_ss: dp(float((rand(10)\/10)+(rand(10)+40)),1); variety_ss: dp(float((rand(10)\/10)+(rand(6)+3)+light_ss),1); resid_ss: dp(float((rand(10)\/10)+(rand(20)+95)),1); total_ss: dp(light_ss+heat_ss+variety_ss+resid_ss,1); light_ms: dp(light_ss\/light_df,1); heat_ms: dp(heat_ss\/heat_df,1); variety_ms: dp(variety_ss\/variety_df,1); resid_ms: dp(resid_ss\/resid_df,1); light_f: dp(light_ms\/resid_ms,1); heat_f: dp(heat_ms\/resid_ms,1); variety_f: dp(variety_ms\/resid_ms,1); ta1:variety_df; ta2:resid_df; ta3:resid_ss; ta4:light_ms; ta5:heat_ms; ta6:variety_ms; ta7:resid_ms; ta8:light_f; ta9:heat_f; ta10:variety_f;       <p>This question note was 1. This is marginally better, but someone should fix this.<\/p> {@ta1@} {@ta2@} {@ta3@} {@ta4@} {@ta5@} {@ta6@} {@ta7@} {@ta8@} {@ta9@} {@ta10@}      1  0  0   <span style=\"font-size: 1.5em; color:green;\"><i class=\"fa fa-check\"><\/i><\/span> Well done.    <span style=\"font-size: 1.5em; color:orange;\"><i class=\"fa fa-adjust\"><\/i><\/span> Your answer is partially correct.    <span style=\"font-size: 1.5em; color:red;\"><i class=\"fa fa-times\"><\/i><\/span> Incorrect answer.   .  *10  dot  1  i  cos-1  lang  [  0    ans1  numerical  ta1  5  1  0   0    0  0  0  0  0  maxdp:1    ans10  numerical  ta10  5  1  0   0    0  0  0  0  0  maxdp:1    ans2  numerical  ta2  5  1  0   0    0  0  0  0  0  maxdp:1    ans3  numerical  ta3  5  1  0   0    0  0  0  0  0  maxdp:1    ans4  numerical  ta4  5  1  0   0    0  0  0  0  0  maxdp:1    ans5  numerical  ta5  5  1  0   0    0  0  0  0  0  maxdp:1    ans6  numerical  ta6  5  1  0   0    0  0  0  0  0  maxdp:1    ans7  numerical  ta7  5  1  0   0    0  0  0  0  0  maxdp:1    ans8  numerical  ta8  5  1  0   0    0  0  0  0  0  maxdp:1    ans9  numerical  ta9  5  1  0   0    0  0  0  0  0  maxdp:1    prt10  1.0000000  1  1   s_ta10: dp(ans6\/ans7,1);    0   AlgEquiv  ans10  s_ta10   0  =  1   -1  prt10-1-T   Correct F value based on your mean sum of squares and residual sum of squares.   =  0   1  prt10-1-F       1   AlgEquiv  ans10  ta10   0  +  1   -1  prt10-2-T   Hmm, how did this happen? Your F value is correct, but your mean sum of squares or residual sum of squares is not. Did you make a typing mistake? Anyway you still get some marks :)   -  0   -1  prt10-2-F   The F value is the ratio of the mean sum of squares over the residual sum of squares.      prt1a  1.0000000  1  1      0   AlgEquiv  ans1  ta1   0  =  1   -1  prt2-1-T     =  0   -1  prt2-1-F   In the tomato data there are two varieties, hence there is \\(1\\) i.e. \\((n-1)\\) degrees of freedom.      prt2  1.0000000  1  1   s_ta2: total_df-light_df-heat_df-ans1    0   AlgEquiv  ans2  s_ta2   0  =  1   -1  prt2-1-T   Correct residual Df based on the Df values of light, heat and variety in your table.   =  0   1  prt2-1-F       1   AlgEquiv  ans2  ta2   0  +  1   -1  prt2-2-T   Hmm, how did this happen? Your residual Df is correct, but your variety Df is not. Did you make a typing mistake? Anyway you still get some marks :)   -  0   -1  prt2-2-F   Residual is the \"left over\" from the variables. So the residual degrees of freedom is the total degree of freedom of the data minus the degrees of freedoms of the variables.      prt3  1.0000000  1  1      0   AlgEquiv  ans3  ta3   0  =  1   -1  prt3-1-T     =  0   -1  prt3-1-F   Like the degrees of freedom, the residual sum of squares is the total sum of squares minus the sums of squares of the variables.      prt4  1.0000000  1  1      0   AlgEquiv  ans4  ta4   0  =  1   -1  prt4-1-T     =  0   -1  prt4-1-F   Mean sum of squares is the sum of squares per degree of freedom.      prt5  1.0000000  1  1      0   AlgEquiv  ans5  ta5   0  =  1   -1  prt5-1-T     =  0   -1  prt5-1-F   Mean sum of squares is the sum of squares per degree of freedom.      prt6  1.0000000  1  1   s_ta6: dp(variety_ss\/ans1,1);    0   AlgEquiv  ans6  s_ta6   0  =  1   -1  prt6-1-T   Correct mean square value based on your sum of squares and Df.   =  0   1  prt6-1-F       1   AlgEquiv  ans6  ta6   0  +  1   -1  prt6-2-T   Hmm, how did this happen? Your mean sum of squares is correct, but your Df is not. Did you make a typing mistake? Anyway you still get some marks :)   -  0   -1  prt6-2-F   Mean sum of squares is the sum of squares per degree of freedom.      prt7  1.0000000  1  1   s_ta7: dp(ans3\/ans2,1);    0   AlgEquiv  ans7  s_ta7   0  =  1   -1  prt7-1-T   Correct residual mean square value based on your residual sum of squares and Df.   =  0   1  prt7-1-F       1   AlgEquiv  ans7  ta7   0  +  1   -1  prt7-2-T   Hmm, how did this happen? Your mean sum of squares is correct, but your sum of squares or Df is not. Did you make a typing mistake? Anyway you still get some marks :)   -  0   -1  prt7-2-F   Mean sum of squares is the sum of squares per degree of freedom.      prt8  1.0000000  1  1   s_ta8: dp(ans4\/ans7,1);    0   AlgEquiv  ans8  s_ta8   0  =  1   -1  prt8-1-T   Correct F value based on your mean sum of squares and residual sum of squares.   =  0   1  prt8-1-F       1   AlgEquiv  ans8  ta8   0  +  1   -1  prt8-2-T   Hmm, how did this happen? Your F value is correct, but your mean ss is not. Did you make a typing mistake? Anyway you still get some marks :)   -  0   -1  prt8-2-F   The F value is the ratio of the mean sum of squares over the residual sum of squares.      prt9  1.0000000  1  1   s_ta9: dp(ans5\/ans7,1);    0   AlgEquiv  ans9  s_ta9   0  =  1   -1  prt9-1-T   Correct F value based on your mean sum of squares and residual sum of squares.   =  0   1  prt9-1-F       1   AlgEquiv  ans9  ta9   0  +  0   -1  prt9-2-T   Hmm, how did this happen? Your F value is correct, but your mean sum of squares or residual sum of squares is not. Did you make a typing mistake? Anyway you still get some marks :)   -  0   -1  prt9-2-F   The F value is the ratio of the mean sum of squares over the residual sum of squares.     2084736791  419774382  1951587842  1155796730  555237110  662068959  863426754  772871690  957528482  1643677683  2263400  1290080932  77179216  1649034504  105007370  217508555   1  Test case assuming the teacher's input gets full marks.   ans1  ta1    ans10  ta10    ans2  ta2    ans3  ta3    ans4  ta4    ans5  ta5    ans6  ta6    ans7  ta7    ans8  ta8    ans9  ta9    prt10  1.0000000  0.0000000  prt10-1-T    prt1a  1.0000000  0.0000000  prt2-1-T    prt2  1.0000000  0.0000000  prt2-1-T    prt3  1.0000000  0.0000000  prt3-1-T    prt4  1.0000000  0.0000000  prt4-1-T    prt5  1.0000000  0.0000000  prt5-1-T    prt6  1.0000000  0.0000000  prt6-1-T    prt7  1.0000000  0.0000000  prt7-1-T    prt8  1.0000000  0.0000000  prt8-1-T    prt9  1.0000000  0.0000000  prt9-1-T         Fill ANOVA table for a millet experiment        Fill ANOVA table for a millet experiment    <p>An experiment is conducted on {@plots@} plots to understand the effect of several factors on the yield of millet.<\/p> <p>The factors are: {@variety@} varieties of millet, {@weeding@} types of weeding and {@fert@} different levels of fertiliser.<\/p> <p>Complete the ANOVA table for the experiment.<\/p> <p><b>Give the values to \\(1\\) decimal place.<\/b><\/p> <p> <style type=\"text\/css\"> #maintable td.blue {color:#00F;} <\/style> <table> <caption><\/caption> <thead> <tr> <th scope=\"col\" style=\"text-align: center;border: 1px solid black; \" width=\"100\">Term<\/th> <th scope=\"col\" style=\"text-align: center; border: 1px solid black;\" width=\"100\">Df<\/th> <th scope=\"col\" style=\"text-align: center; border: 1px solid black;\" width=\"100\">Sum Sq<\/th> <th scope=\"col\" style=\"text-align: center;border: 1px solid black;\" width=\"100\">Mean Sq<\/th> <th scope=\"col\" style=\"text-align: center; border: 1px solid black;\" width=\"100\">F Value<\/th> <\/tr> <\/thead> <tbody> <tr> <td style=\"text-align: center;border: 1px solid black; \">Variety<\/td> <td style=\"text-align: center;border: 1px solid black; \">[[input:ans_variety_df]] [[validation:ans_variety_df]] [[feedback:prt1_variety_df]]<\/td> <td style=\"text-align: center;border: 1px solid black; \">{@variety_ss@}<\/td> <td style=\"text-align: center;border: 1px solid black; \">[[input:ans_variety_ms]] [[validation:ans_variety_ms]] [[feedback:prt_variety_ms]]<\/td> <td style=\"text-align: center;border: 1px solid black; \">[[input:ans_variety_f]] [[validation:ans_variety_f]] [[feedback:prt_variety_f]]<\/td> <\/tr> <tr> <td style=\"text-align: center;border: 1px solid black; \">Weeding<\/td> <td style=\"text-align: center;border: 1px solid black; \">[[input:ans_weeding_df]] [[validation:ans_weeding_df]] [[feedback:prt_weeding_df]]<\/td> <td style=\"text-align: center;border: 1px solid black; \">{@weeding_ss@}<\/td> <td style=\"text-align: center;border: 1px solid black; \">[[input:ans_weeding_ms]] [[validation:ans_weeding_ms]] [[feedback:prt_weeding_ms]]<\/td> <td style=\"text-align: center;border: 1px solid black; \">[[input:ans_weeding_f]] [[validation:ans_weeding_f]] [[feedback:prt_weeding_f]]<\/td> <\/tr> <tr> <td style=\"text-align: center;border: 1px solid black; \">Fertiliser<\/td> <td style=\"text-align: center;border: 1px solid black; \">[[input:ans_fert_df]] [[validation:ans_fert_df]] [[feedback:prt_fert_df]]<\/td> <td style=\"text-align: center;border: 1px solid black; \">{@fert_ss@}<\/td> <td style=\"text-align: center;border: 1px solid black; \">[[input:ans_fert_ms]] [[validation:ans_fert_ms]] [[feedback:prt_fert_ms]]<\/td> <td style=\"text-align: center;border: 1px solid black; \">[[input:ans_fert_f]] [[validation:ans_fert_f]] [[feedback:prt_fert_f]]<\/td> <\/tr> <tr> <td style=\"text-align: center;border: 1px solid black; \">Residuals<\/td> <td style=\"text-align: center;border: 1px solid black; \">[[input:ans_resid_df]] [[validation:ans_resid_df]] [[feedback:prt_resid_df]]<\/td> <td style=\"text-align: center;border: 1px solid black; \">[[input:ans_resid_ss]] [[validation:ans_resid_ss]] [[feedback:prt_resid_ss]]<\/td> <td style=\"text-align: center;border: 1px solid black; \">[[input:ans_resid_ms]] [[validation:ans_resid_ms]] [[feedback:prt_resid_ms]]<\/td> <td style=\"text-align: center;border: 1px solid black; \"><\/td> <\/tr> <tr> <td style=\"text-align: center;border: 1px solid black; \">Total<\/td> <td style=\"text-align: center;border: 1px solid black; \">[[input:ans_total_df]] [[validation:ans_total_df]] [[feedback:prt1_total_df]]<\/td> <td style=\"text-align: center;border: 1px solid black; \">{@total_ss@}<\/td> <td style=\"text-align: center;border: 1px solid black; \"><\/td> <td style=\"text-align: center;border: 1px solid black; \"><\/td> <\/tr> <\/tbody> <\/table> <\/p>    <p>The complete ANOVA table is shown below.<\/p> <p>There are a few key points to remember:<\/p> <ul> <li>The residual is the \"left over\" after taking into account the variables. So the residual Df and sum of squares is the difference between the total values and the sum of the variables values.<\/li> <li>The mean sum of squares is simply the sum of squares per Df.<\/li> <li>The F value is the ratio of the mean sum of squares and the residual sum of squares. It allows us to compare the variability explained by a variable compared to the unexplained (residual) variability.<\/li> <\/ul> <p> <table> <caption><\/caption> <thead> <tr> <th scope=\"col\" style=\"text-align: center;border: 1px solid black; \" width=\"100\">Term<\/th> <th scope=\"col\" style=\"text-align: center; border: 1px solid black;\" width=\"100\">Df<\/th> <th scope=\"col\" style=\"text-align: center; border: 1px solid black;\" width=\"100\">Sum Sq<\/th> <th scope=\"col\" style=\"text-align: center;border: 1px solid black;\" width=\"100\">Mean Sq<\/th> <th scope=\"col\" style=\"text-align: center; border: 1px solid black;\" width=\"100\">F Value<\/th> <\/tr> <\/thead> <tbody> <tr> <td style=\"text-align: center;border: 1px solid black; \">Variety<\/td> <td style=\"color:#00F; text-align: center;border: 1px solid black; \">{@variety_df@}<\/td> <td style=\"text-align: center;border: 1px solid black; \">{@variety_ss@}<\/td> <td style=\"color:#00F; text-align: center;border: 1px solid black; \">{@variety_ms@}<\/td> <td style=\"color:#00F; text-align: center;border: 1px solid black; \">{@variety_f@}<\/td> <\/tr> <tr> <td style=\"text-align: center;border: 1px solid black; \">Weeding<\/td> <td style=\"color:#00F; text-align: center;border: 1px solid black; \">{@weeding_df@}<\/td> <td style=\"text-align: center;border: 1px solid black; \">{@weeding_ss@}<\/td> <td style=\"color:#00F; text-align: center;border: 1px solid black; \">{@weeding_ms@}<\/td> <td style=\"color:#00F; text-align: center;border: 1px solid black; \">{@weeding_f@}<\/td> <\/tr> <tr> <td style=\"text-align: center;border: 1px solid black; \">Fertiliser<\/td> <td style=\"color:#00F; text-align: center;border: 1px solid black; \">{@fert_df@}<\/td> <td style=\"text-align: center;border: 1px solid black; \">{@fert_ss@}<\/td> <td style=\"color:#00F; text-align: center;border: 1px solid black; \">{@fert_ms@}<\/td> <td style=\"color:#00F; text-align: center;border: 1px solid black; \">{@fert_f@}<\/td> <\/tr> <tr> <td style=\"text-align: center;border: 1px solid black; \">Residuals<\/td> <td style=\"color:#00F; text-align: center;border: 1px solid black; \">{@resid_df@}<\/td> <td style=\"color:#00F; text-align: center;border: 1px solid black; \">{@resid_ss@}<\/td> <td style=\"color:#00F; text-align: center;border: 1px solid black; \">{@resid_ms@}<\/td> <td style=\"text-align: center;border: 1px solid black; \"><\/td> <\/tr> <tr> <td style=\"text-align: center;border: 1px solid black; \">Total<\/td> <td style=\"color:#00F; text-align: center;border: 1px solid black; \">{@total_df@}<\/td> <td style=\"text-align: center;border: 1px solid black; \">{@total_ss@}<\/td> <td style=\"text-align: center;border: 1px solid black; \"><\/td> <td style=\"text-align: center;border: 1px solid black; \"><\/td> <\/tr> <\/tbody> <\/table> <\/p>   1  0.1  0    2025073100    dp(x, n) := float(round((x+10^(-8))*10^n)\/10^n); plots: 30+rand(10); variety: 4+rand(3); weeding: 2+rand(2); fert: 3+rand(2); variety_df:variety-1; weeding_df: weeding-1; fert_df: fert-1; total_df: plots-1; resid_df: total_df-weeding_df-variety_df-fert_df; variety_ss: dp(float((rand(10)\/10)+(rand(10)+20)),1); weeding_ss: dp(float((rand(10)\/10)+(rand(10)+10)),1); fert_ss: dp(float((rand(10)\/10)+rand(6)+40),1); resid_ss: dp(float((rand(10)\/10)+(rand(20)+65)),1); total_ss: dp(variety_ss+weeding_ss+fert_ss+resid_ss,1); variety_ms: dp(variety_ss\/variety_df,1); weeding_ms: dp(weeding_ss\/weeding_df,1); fert_ms: dp(fert_ss\/fert_df,1); resid_ms: dp(resid_ss\/resid_df,1); variety_f: dp(variety_ms\/resid_ms,1); weeding_f: dp(weeding_ms\/resid_ms,1); fert_f: dp(fert_ms\/resid_ms,1); ta1:fert_df; ta2:resid_df; ta3:resid_ss; ta4:variety_ms; ta5:weeding_ms; ta6:fert_ms; ta7:resid_ms; ta8:variety_f; ta9:weeding_f; ta10:fert_f; ta11: variety_df; ta12: weeding_df; ta13: total_df;       <p>This question note was 1. This is marginally better, but someone should fix this.<\/p> {@ta1@} {@ta2@} {@ta3@} {@ta4@} {@ta5@} {@ta6@} {@ta7@} {@ta8@} {@ta9@} {@ta10@} {@ta11@} {@ta12@} {@ta13@}      1  0  0   <span style=\"font-size: 1.5em; color:green;\"><i class=\"fa fa-check\"><\/i><\/span> Well done.    <span style=\"font-size: 1.5em; color:orange;\"><i class=\"fa fa-adjust\"><\/i><\/span> Your answer is partially correct.    <span style=\"font-size: 1.5em; color:red;\"><i class=\"fa fa-times\"><\/i><\/span> Incorrect answer.   .  *10  dot  1  i  cos-1  lang  [  0    ans_fert_df  numerical  ta1  5  1  0   0    0  0  0  0  0  maxdp:1    ans_fert_f  numerical  ta10  5  1  0   0    0  0  0  0  0  maxdp:1    ans_fert_ms  numerical  ta6  5  1  0   0    0  0  0  0  0  maxdp:1    ans_resid_df  numerical  ta2  5  1  0   0    0  0  0  0  0  maxdp:1    ans_resid_ms  numerical  ta7  5  1  0   0    0  0  0  0  0  maxdp:1    ans_resid_ss  numerical  ta3  5  1  0   0    0  0  0  0  0  maxdp:1    ans_total_df  numerical  ta13  5  1  0   0    0  0  0  0  0     ans_variety_df  numerical  ta11  5  1  0   0    0  0  0  0  0     ans_variety_f  numerical  ta8  5  1  0   0    0  0  0  0  0  maxdp:1    ans_variety_ms  numerical  ta4  5  1  0   0    0  0  0  0  0  maxdp:1    ans_weeding_df  numerical  ta12  5  1  0   0    0  0  0  0  0     ans_weeding_f  numerical  ta9  5  1  0   0    0  0  0  0  0  maxdp:1    ans_weeding_ms  numerical  ta5  5  1  0   0    0  0  0  0  0  maxdp:1    prt_fert_df  1.0000000  1  1      0   AlgEquiv  ans_fert_df  ta1   0  =  1   -1  prt2-1-T     =  0   -1  prt2-1-F   There are {@fert@} levels of fertiliser, hence there are {@ta1@} i.e. \\((n-1)\\) degrees of freedom.      prt_fert_f  1.0000000  1  1   s_ta10: dp(ans_fert_ms\/ans_resid_ms,1);    0   NumAbsolute  ans_fert_f  s_ta10  0.1  0  =  1   -1  prt10-1-T   Correct F value based on your mean sum of squares and residual sum of squares.   =  0   1  prt10-1-F       1   NumAbsolute  ans_fert_f  ta10  0.1  0  +  1   -1  prt10-2-T   Hmm, how did this happen? Your F value is correct, but your mean sum of squares or residual sum of squares is not. Did you make a typing mistake? Anyway you still get some marks :)   -  0   -1  prt10-2-F   The F value is the ratio of the mean sum of squares over the residual sum of squares.      prt_fert_ms  1.0000000  1  1   s_ta6: dp(fert_ss\/ans_fert_df,1);    0   AlgEquiv  ans_fert_ms  s_ta6   0  =  1   -1  prt6-1-T   Correct mean square value based on your sum of squares and Df.   =  0   1  prt6-1-F   {@fert_ss@} {@ans_fert_df@}     1   AlgEquiv  ans_fert_ms  ta6   0  +  1   -1  prt6-2-T   Hmm, how did this happen? Your mean sum of squares is correct, but your Df is not. Did you make a typing mistake? Anyway you still get some marks :)   -  0   -1  prt6-2-F   Mean sum of squares is the sum of squares per degree of freedom.      prt_resid_df  1.0000000  1  1   s_ta2: ans_total_df-ans_variety_df-ans_weeding_df-ans_fert_df    0   AlgEquiv  ans_resid_df  s_ta2   0  =  1   -1  prt2-1-T   Correct residual Df based on the total and factor Df values in your table.   =  0   1  prt2-1-F       1   AlgEquiv  ans_resid_df  ta2   0  +  1   -1  prt2-2-T   Hmm, how did this happen? Your residual Df is correct, but some of your other Df values are not. Did you make a typing mistake? Anyway you still get some marks :)   -  0   -1  prt2-2-F   Residual is the \"left over\" from the variables. So the residual degrees of freedom is the total degree of freedom of the data minus the degrees of freedoms of the factors.      prt_resid_ms  1.0000000  1  1   s_ta7: dp(ans_resid_ss\/ans_resid_df,1);    0   NumAbsolute  ans_resid_ms  s_ta7  0.1  0  =  1   -1  prt7-1-T   Correct residual mean square value based on your residual sum of squares and Df.   =  0   1  prt7-1-F       1   NumAbsolute  ans_resid_ms  ta7  0.1  0  +  1   -1  prt7-2-T   Hmm, how did this happen? Your mean sum of squares is correct, but your sum of squares or Df is not. Did you make a typing mistake? Anyway you still get some marks :)   -  0   -1  prt7-2-F   Mean sum of squares is the sum of squares per degree of freedom.      prt_resid_ss  1.0000000  1  1      0   AlgEquiv  ans_resid_ss  ta3   0  =  1   -1  prt3-1-T     =  0   -1  prt3-1-F   Like the degrees of freedom, the residual sum of squares is the total sum of squares minus the sums of squares of the variables.      prt_variety_f  1.0000000  1  1   s_ta8: dp(ans_variety_ms\/ans_resid_ms,1);    0   NumAbsolute  ans_variety_f  s_ta8  0.1  0  =  1   -1  prt8-1-T   Correct F value based on your mean sum of squares and residual sum of squares.   =  0   1  prt8-1-F       1   NumAbsolute  ans_variety_f  ta8  0.1  0  +  1   -1  prt8-2-T   Hmm, how did this happen? Your F value is correct, but your mean ss is not. Did you make a typing mistake? Anyway you still get some marks :)   -  0   -1  prt8-2-F   The F value is the ratio of the mean sum of squares over the residual sum of squares.      prt_variety_ms  1.0000000  1  1   s_ta4: dp(variety_ss\/ans_variety_df,1);    0   AlgEquiv  ans_variety_ms  s_ta4   0  =  1   -1  prt4-1-T   Correct mean square value based on your sum of squares and Df.   =  0   1  prt4-1-F       1   AlgEquiv  ans_variety_ms  ta4   0  +  1   -1  prt4-2-T   Hmm, how did this happen? Your mean sum of squares is correct, but your Df is not. Did you make a typing mistake? Anyway you still get some marks :)   -  0   -1  prt4-2-F   Mean sum of squares is the sum of squares per degree of freedom.      prt_weeding_df  1.0000000  1  1      0   AlgEquiv  ans_weeding_df  ta12   0  =  1   -1  prt12-1-T     =  0   -1  prt12-1-F   There are {@weeding@} levels of weeding, hence there are {@ta12@} i.e. \\((n-1)\\) degrees of freedom.      prt_weeding_f  1.0000000  1  1   s_ta9: dp(ans_weeding_ms\/ans_resid_ms,1);    0   NumAbsolute  ans_weeding_f  s_ta9  0.1  0  =  1   -1  prt9-1-T   Correct F value based on your mean sum of squares and residual sum of squares.   =  0   1  prt9-1-F       1   AlgEquiv  ans_weeding_f  ta9   0  +  1   -1  prt9-2-T   Hmm, how did this happen? Your F value is correct, but your mean sum of squares or residual sum of squares is not. Did you make a typing mistake? Anyway you still get some marks :)   -  0   -1  prt9-2-F   The F value is the ratio of the mean sum of squares over the residual sum of squares.      prt_weeding_ms  1.0000000  1  1   s_ta5: dp(weeding_ss\/ans_weeding_df,1);    0   AlgEquiv  ans_weeding_ms  s_ta5   0  =  1   -1  prt5-1-T   Correct mean square value based on your sum of squares and Df.   =  0   1  prt5-1-F       1   AlgEquiv  ans_weeding_ms  ta5   0  +  1   -1  prt_weeding_ms-2-T   Hmm, how did this happen? Your mean mean square is correct, but your Df is not. Did you make a typing mistake? Anyway you still get some marks :)   -  0   -1  prt_weeding_ms-2-F   Mean sum of squares is the sum of squares per degree of freedom.      prt1_total_df  1.0000000  1  1      0   AlgEquiv  ans_total_df  ta13   0  =  1   -1  prt13-1-T     =  0   -1  prt13-1-F   The total degrees of freedom is the number of observations minus \\(1\\), so {@total_df@}.      prt1_variety_df  1.0000000  1  1      0   AlgEquiv  ans_variety_df  ta11   0  =  1   -1  prt11-1-T     =  0   -1  prt11-1-F   There are {@variety@} different varieties, hence there are {@ta11@} i.e. \\((n-1)\\) degrees of freedom.     408042425  1844761798  1192345098  1960516951  1781511457  802855958  286416426  714241569  2043431606  876461352  1540175555  521137151  92500197  500830597  1694534167   1  Test case assuming the teacher's input gets full marks.   ans_fert_df  ta1    ans_fert_f  ta10    ans_fert_ms  ta6    ans_resid_df  ta2    ans_resid_ms  ta7    ans_resid_ss  ta3    ans_total_df  ta13    ans_variety_df  ta11    ans_variety_f  ta8    ans_variety_ms  ta4    ans_weeding_df  ta12    ans_weeding_f  ta9    ans_weeding_ms  ta5    prt_fert_df  1.0000000  0.0000000  prt2-1-T    prt_fert_f  1.0000000  0.0000000  prt10-1-T    prt_fert_ms  1.0000000  0.0000000  prt6-1-T    prt_resid_df  1.0000000  0.0000000  prt2-1-T    prt_resid_ms  1.0000000  0.0000000  prt7-1-T    prt_resid_ss  1.0000000  0.0000000  prt3-1-T    prt_variety_f  1.0000000  0.0000000  prt8-1-T    prt_variety_ms  1.0000000  0.0000000  prt4-1-T    prt_weeding_df  1.0000000  0.0000000  prt12-1-T    prt_weeding_f  1.0000000  0.0000000  prt9-1-T    prt_weeding_ms  1.0000000  0.0000000  prt5-1-T    prt1_total_df  1.0000000  0.0000000  prt13-1-T    prt1_variety_df  1.0000000  0.0000000  prt11-1-T         Interpret and match dotplots to respective boxplots        Interpret and match dotplots to respective boxplots    <p>Below are stacked Dot Plots and Box Plots for four different sets of data.<\/p> <p>Which box plot matches with each dot plot?<\/p> <p>Dot plots:<\/p> <p>[[jsxgraph]] \/\/ Create empty list of points var p = []; \/\/ Create board var board = JXG.JSXGraph.initBoard(divid, { boundingbox: [{#xmin#}, {#ymax#}, {#xmax#}, {#ymin#}], keepaspectratio: false, showCopyright: false, axis:true, pan:{enabled:false} }); \/\/Create points of Data Set 4 var lx4 = {#datx4#}; var ly4 = {#daty4#}; var i = 0; for (i = 0; i <= lx4.length - 1; i++) { p[i] = board.create('point', [lx4[i], ly4[i]], { face: 'x', name: '', size: 2, fixed:true }); } \/\/Create Label for Data 4 var txt = board.create('text', [{#xmin#}+1, {#maxfreq4+ver_diff-3#}, \"D4\"], { fontSize: 20,fixed: true }); \/\/Create divisor between V3 and V4 var div1 = board.create('line', [ [{#xmin#},{#maxfreq4+ver_diff+0.5#}], [{#xmax#},{#maxfreq4+ver_diff+0.5#}] ], { straightFirst: false, straightLast: false, strokeWidth: 1, dash:2 }); \/\/Create divisor between V2 and V3 var div2 = board.create('line', [ [{#xmin#},{#maxfreq4+maxfreq3+2*ver_diff+0.5#}], [{#xmax#},{#maxfreq4+maxfreq3+2*ver_diff+0.5#}] ], { straightFirst: false, straightLast: false, strokeWidth: 1, dash:2 }); \/\/Create divisor between V1 and V2 var div3 = board.create('line', [ [{#xmin#},{#maxfreq4+maxfreq3+maxfreq2+3*ver_diff+0.5#}], [{#xmax#},{#maxfreq4+maxfreq3+maxfreq2+3*ver_diff+0.5#}] ], { straightFirst: false, straightLast: false, strokeWidth: 1, dash:2 }); \/\/Create points of Data Set 3 var lx3 = {#datx3#}; var ly3 = {#daty3#}; var i = 0; for (i = 0; i <= lx3.length - 1; i++) { p[i] = board.create('point', [lx3[i], ly3[i]], { face: 'x', name: '', size: 2, fixed:true }); } \/\/Create Label for Data 3 var txt = board.create('text', [{#xmin#}+1, {#maxfreq3+maxfreq4+2*ver_diff-3#}, \"D3\"], { fontSize: 20,fixed: true }); \/\/Create points of Data Set 2 var lx2 = {#datx2#}; var ly2 = {#daty2#}; var i = 0; for (i = 0; i <= lx2.length - 1; i++) { p[i] = board.create('point', [lx2[i], ly2[i]], { face: 'x', name: '', size: 2, fixed:true }); } \/\/Create Label for Data 2 var txt = board.create('text', [{#xmin#}+1, {#maxfreq2+maxfreq3+maxfreq4+3*ver_diff-3#}, \"D2\"], { fontSize: 20,fixed: true }); \/\/Create points of Data Set 1 var lx1 = {#datx1#}; var ly1 = {#daty1#}; var i = 0; for (i = 0; i <= lx1.length - 1; i++) { p[i] = board.create('point', [lx1[i], ly1[i]], { face: 'x', name: '', size: 2, fixed:true }); } \/\/Create Label for Data 1 var txt = board.create('text', [{#xmin#}+1, {#maxfreq1+maxfreq2+maxfreq3+maxfreq4+4*ver_diff-3#}, \"D1\"], { fontSize: 20,fixed: true }); [[\/jsxgraph]]<\/p> <p>Box Plots:<\/p> <p> [[jsxgraph]] \/\/ Create board var board = JXG.JSXGraph.initBoard(divid, { boundingbox: [{#xmin#}, 10, {#xmax#}, -1], keepaspectratio: false, showCopyright: false, axis:true, pan:{enabled:false} }); \/\/Create variables for graph 1 var min1 ={#info1[1]#}; var lq1 = {#info1[2]#}; var med1 = {#info1[3]#}; var uq1 = {#info1[4]#}; var max1 = {#info1[5]#}; \/\/Create graph 1 var d11 = board.create('line', [[min1, 7],[min1, 8]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d12 = board.create('line', [[max1, 7],[max1, 8]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d13 = board.create('line', [[med1, 7],[med1, 8]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d14 = board.create('line', [[lq1, 7],[lq1, 8]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d15 = board.create('line', [[uq1, 7],[uq1, 8]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d16 = board.create('line', [[uq1, 7],[lq1, 7]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d17 = board.create('line', [[uq1, 8],[lq1, 8]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d18 = board.create('line', [[min1, 7.5],[lq1, 7.5]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d19 = board.create('line', [[max1, 7.5],[uq1, 7.5]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); \/\/Create Label for graph 1 var txt = board.create('text', [{#xmin#}+0.5, 8, \"A\"], { fontSize: 20,fixed: true }); \/\/Create variables for graph 2 var min2 ={#info2[1]#}; var lq2 = {#info2[2]#}; var med2 = {#info2[3]#}; var uq2 = {#info2[4]#}; var max2 = {#info2[5]#}; \/\/Create graph 2 var d21 = board.create('line', [[min2, 5],[min2, 6]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d22 = board.create('line', [[max2, 5],[max2, 6]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d23 = board.create('line', [[med2, 5],[med2, 6]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d24 = board.create('line', [[lq2, 5],[lq2, 6]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d25 = board.create('line', [[uq2, 5],[uq2, 6]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d26 = board.create('line', [[uq2, 5],[lq2, 5]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d27 = board.create('line', [[uq2, 6],[lq2, 6]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d28 = board.create('line', [[min2, 5.5],[lq2, 5.5]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d29 = board.create('line', [[max2, 5.5],[uq2, 5.5]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); \/\/Create Label for graph 2 var txt = board.create('text', [{#xmin#}+0.5, 6, \"B\"], { fontSize: 20,fixed: true }); \/\/Create variables for graph 3 var min3 ={#info3[1]#}; var lq3 = {#info3[2]#}; var med3 = {#info3[3]#}; var uq3 = {#info3[4]#}; var max3 = {#info3[5]#}; \/\/Create graph 3 var d31 = board.create('line', [[min3, 3],[min3, 4]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d32 = board.create('line', [[max3, 3],[max3, 4]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d33 = board.create('line', [[med3, 3],[med3, 4]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d34 = board.create('line', [[lq3, 3],[lq3, 4]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d35 = board.create('line', [[uq3, 3],[uq3, 4]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d36 = board.create('line', [[uq3, 3],[lq3, 3]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d37 = board.create('line', [[uq3, 4],[lq3, 4]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d38 = board.create('line', [[min3, 3.5],[lq3, 3.5]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d39 = board.create('line', [[max3, 3.5],[uq3, 3.5]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); \/\/Create Label for graph 3 var txt = board.create('text', [{#xmin#}+0.5, 4, \"C\"], { fontSize: 20,fixed: true }); \/\/Create variables for graph 4 var min4 ={#info4[1]#}; var lq4 = {#info4[2]#}; var med4 = {#info4[3]#}; var uq4 = {#info4[4]#}; var max4 = {#info4[5]#}; \/\/Create graph 4 var d41 = board.create('line', [[min4, 1],[min4, 2]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d42 = board.create('line', [[max4, 1],[max4, 2]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d43 = board.create('line', [[med4, 1],[med4, 2]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d44 = board.create('line', [[lq4, 1],[lq4, 2]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d45 = board.create('line', [[uq4, 1],[uq4, 2]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d46 = board.create('line', [[uq4, 1],[lq4, 1]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d47 = board.create('line', [[uq4, 2],[lq4, 2]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d48 = board.create('line', [[min4, 1.5],[lq4, 1.5]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d49 = board.create('line', [[max4, 1.5],[uq4, 1.5]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); \/\/Create Label for graph 4 var txt = board.create('text', [{#xmin#}+0.5, 2, \"D\"], { fontSize: 20,fixed: true }); [[\/jsxgraph]] <\/p> <p>Enter the relevant letter for each Stacked Dot Plot:<\/p> <p>\\(D1\\) matches with: [[input:ans1]] [[validation:ans1]] [[feedback:prt1]]<\/p> <p>\\(D2\\) matches with: [[input:ans2]] [[validation:ans2]] [[feedback:prt2]]<\/p> <p>\\(D3\\) matches with: [[input:ans3]] [[validation:ans3]] [[feedback:prt3]]<\/p> <p>\\(D4\\) matches with: [[input:ans4]] [[validation:ans4]] [[feedback:prt4]]<\/p>    <p>Remember how a boxplot is defined.<\/p> <p>The middle of the box is the median line. Half the data are above the median and half are below. Looking at the dotplots we see that some of the distributions are skewed, so the median point is very low or very high. Others are more symmetric, so the boxplot will also be more symmetric.<\/p> <p>Where are the 25% (lower quartile) and 75% (upper quartile) points? Then match these to the boxplots.<\/p> <p>One of the datasets looks \"bimodal\" meaning it has two \"peaks\". How does a boxplot of bimodal data look different from a boxplot of a normally distributed data set?<\/p>   1  0.1  0    2023060500    dat_min: rand(101)+100; dat_max: dat_min+30+rand(21); n: rand(41)+60; bin_width: floor((dat_max-dat_min)\/30); ver_diff: 2; \/* dat1: normal *\/ dat1: makelist(float(quantile_normal(rand(1.0),0,1)),i,1,n); dat1: ((dat1-lmin(dat1))\/(lmax(dat1)-lmin(dat1)))*(dat_max-dat_min)+dat_min; dat1: sort(dat1); dat1: round(dat1); datx1:makelist(1,i,1,n); for i:1 thru n do datx1[i]:bin_width*floor(dat1[i]\/bin_width)+bin_width\/2; \/* info of normal for box plot: [min,lq,med,uq,max] *\/ min1:datx1[1]; lq1:quantile (datx1,1\/4),numer; med1:median(datx1); uq1:quantile (datx1, 3\/4),numer; max1:datx1[n]; info1:[min1,lq1,med1,uq1,max1]; \/* dat2: bimodal (from two disjoint normals) *\/ dat21: makelist(float(quantile_normal(rand(1.0),0,1)),i,1,floor(n\/2)); dat22: makelist(float(quantile_normal(rand(1.0),4,1)),i,1,ceiling(n\/2)); dat2: append(dat21,dat22); dat2: ((dat2-lmin(dat2))\/(lmax(dat2)-lmin(dat2)))*(dat_max-dat_min)+dat_min; dat2: sort(dat2); dat2: round(dat2); datx2:makelist(1,i,1,n); for i:1 thru n do datx2[i]:bin_width*floor(dat2[i]\/bin_width)+bin_width\/2; \/* info of bimodal for box plot: [min,lq,med,uq,max] *\/ min2:datx2[1]; lq2:quantile (datx2,1\/4),numer; med2:median(datx2); uq2:quantile (datx2, 3\/4),numer; max2:datx2[n]; info2:[min2,lq2,med2,uq2,max2]; \/* dat3: gamma right skewed *\/ dat3: makelist(float(quantile_gamma(rand(1.0),2,20)),i,1,n); dat3: ((dat3-lmin(dat3))\/(lmax(dat3)-lmin(dat3)))*(dat_max-dat_min)+dat_min; dat3: sort(dat3); dat3: round(dat3); datx3:makelist(1,i,1,n); for i:1 thru n do datx3[i]:bin_width*floor(dat3[i]\/bin_width)+bin_width\/2; \/* info of right skew for box plot: [min,lq,med,uq,max] *\/ min3:datx3[1]; lq3:quantile (datx3,1\/4),numer; med3:median(datx3); uq3:quantile (datx3, 3\/4),numer; max3:datx3[n]; info3:[min3,lq3,med3,uq3,max3]; \/* dat4: gamma left skewed *\/ dat4: makelist(float(quantile_gamma(rand(1.0),2,20)),i,1,n); dat4: lmax(dat4)-lmin(dat4)+2-dat4; dat4: ((dat4-lmin(dat4))\/(lmax(dat4)-lmin(dat4)))*(dat_max-dat_min)+dat_min; dat4: sort(dat4); dat4: round(dat4); datx4:makelist(1,i,1,n); for i:1 thru n do datx4[i]:bin_width*floor(dat4[i]\/bin_width)+bin_width\/2; \/* info of left skew for box plot: [min,lq,med,uq,max] *\/ min4:datx4[1]; lq4:quantile (datx4,1\/4),numer; med4:median(datx4); uq4:quantile (datx4, 3\/4),numer; max4:datx4[n]; info4:[min4,lq4,med4,uq4,max4]; \/* Randomising the order of the graphs *\/ dumlist1:[1,2,3,4]; randdumlist1:random_permutation(dumlist1); datasetslist:[datx1,datx2,datx3,datx4]; datx1:datasetslist[randdumlist1[1]]; datx2:datasetslist[randdumlist1[2]]; datx3:datasetslist[randdumlist1[3]]; datx4:datasetslist[randdumlist1[4]]; \/* version number for each graph *\/ normalans1:if randdumlist1[1] = 1 then 1 elseif randdumlist1[2]=1 then 2 elseif randdumlist1[3]=1 then 3 else 4; bimodalans1:if randdumlist1[1] = 2 then 1 elseif randdumlist1[2]=2 then 2 elseif randdumlist1[3]=2 then 3 else 4; rightskewans1:if randdumlist1[1] = 3 then 1 elseif randdumlist1[2]=3 then 2 elseif randdumlist1[3]=3 then 3 else 4; leftskewans1:if randdumlist1[1] = 4 then 1 elseif randdumlist1[2]=4 then 2 elseif randdumlist1[3]=4 then 3 else 4; \/* Randomising the order of the graphs *\/ dumlist2:[1,2,3,4]; randdumlist2:random_permutation(dumlist2); infolist:[info1,info2,info3,info4]; info1:infolist[randdumlist2[1]]; info2:infolist[randdumlist2[2]]; info3:infolist[randdumlist2[3]]; info4:infolist[randdumlist2[4]]; \/* version number for each graph *\/ normalans2:if randdumlist2[1] = 1 then 1 elseif randdumlist2[2]=1 then 2 elseif randdumlist2[3]=1 then 3 else 4; bimodalans2:if randdumlist2[1] = 2 then 1 elseif randdumlist2[2]=2 then 2 elseif randdumlist2[3]=2 then 3 else 4; rightskewans2:if randdumlist2[1] = 3 then 1 elseif randdumlist2[2]=3 then 2 elseif randdumlist2[3]=3 then 3 else 4; leftskewans2:if randdumlist2[1] = 4 then 1 elseif randdumlist2[2]=4 then 2 elseif randdumlist2[3]=4 then 3 else 4; \/* Calculate the maximun frequency of each data set *\/ maxfreq1:0; k:1; for i:2 thru n do if datx1[i]=datx1[i-1] then (k:k+1, if maxfreq1 < k then maxfreq1:k) else k:1; maxfreq2:0; k:1; for i:2 thru n do if datx2[i]=datx2[i-1] then (k:k+1, if maxfreq2 < k then maxfreq2:k) else k:1; maxfreq3:0; k:1; for i:2 thru n do if datx3[i]=datx3[i-1] then (k:k+1, if maxfreq3 < k then maxfreq3:k) else k:1; maxfreq4:0; k:1; for i:2 thru n do if datx4[i]=datx4[i-1] then (k:k+1, if maxfreq4 < k then maxfreq4:k) else k:1; \/* Begin generating stacked dot plots *\/ xmin:dat_min-2; xmax:dat_max+2; ymin:-4; ymax: maxfreq1+maxfreq2+maxfreq3+maxfreq4+3*ver_diff+1; \/* Generate y-values for each data set to plot the stacked dots *\/ j:1; daty1:makelist(0,i,1,n); daty1[1]:1+maxfreq2+maxfreq3+maxfreq4+3*ver_diff; for i:2 thru n do if datx1[i]=datx1[i-1] then (j:j+1, daty1[i]:j+maxfreq2+maxfreq3+maxfreq4+3*ver_diff) else (j:1, daty1[i]:j+maxfreq2+maxfreq3+maxfreq4+3*ver_diff); j:1; daty2:makelist(0,i,1,n); daty2[1]:1+maxfreq3+maxfreq4+2*ver_diff; for i:2 thru n do if datx2[i]=datx2[i-1] then (j:j+1, daty2[i]:j+maxfreq3+maxfreq4+2*ver_diff) else (j:1, daty2[i]:j+maxfreq3+maxfreq4+2*ver_diff); j:1; daty3:makelist(0,i,1,n); daty3[1]:1+maxfreq4+ver_diff; for i:2 thru n do if datx3[i]=datx3[i-1] then (j:j+1, daty3[i]:j+maxfreq4+ver_diff) else (j:1, daty3[i]:j+maxfreq4+ver_diff); j:1; daty4:makelist(0,i,1,n); daty4[1]:1; for i:2 thru n do if datx4[i]=datx4[i-1] then (j:j+1, daty4[i]:j) else (j:1, daty4[i]:j); \/* End generating stacked dot plots *\/ ta1_c:if randdumlist1[1]=randdumlist2[1] then \"A\" elseif randdumlist1[1]=randdumlist2[2] then \"B\" elseif randdumlist1[1]=randdumlist2[3] then \"C\" else \"D\"; ta1:[[\"A\",is(ta1_c=\"A\"), \"Boxplot A\"],[\"B\",is(ta1_c=\"B\"), \"Boxplot B\"],[\"C\",is(ta1_c=\"C\"), \"Boxplot C\"],[\"D\",is(ta1_c=\"D\"), \"Boxplot D\"]]; ta2_c:if randdumlist1[2]=randdumlist2[1] then \"A\" elseif randdumlist1[2]=randdumlist2[2] then \"B\" elseif randdumlist1[2]=randdumlist2[3] then \"C\" else \"D\"; ta2:[[\"A\",is(ta2_c=\"A\"), \"Boxplot A\"],[\"B\",is(ta2_c=\"B\"), \"Boxplot B\"],[\"C\",is(ta2_c=\"C\"), \"Boxplot C\"],[\"D\",is(ta2_c=\"D\"), \"Boxplot D\"]]; ta3_c:if randdumlist1[3]=randdumlist2[1] then \"A\" elseif randdumlist1[3]=randdumlist2[2] then \"B\" elseif randdumlist1[3]=randdumlist2[3] then \"C\" else \"D\"; ta3:[[\"A\",is(ta3_c=\"A\"), \"Boxplot A\"],[\"B\",is(ta3_c=\"B\"), \"Boxplot B\"],[\"C\",is(ta3_c=\"C\"), \"Boxplot C\"],[\"D\",is(ta3_c=\"D\"), \"Boxplot D\"]]; ta4_c:if randdumlist1[4]=randdumlist2[1] then \"A\" elseif randdumlist1[4]=randdumlist2[2] then \"B\" elseif randdumlist1[4]=randdumlist2[3] then \"C\" else \"D\"; ta4:[[\"A\",is(ta4_c=\"A\"), \"Boxplot A\"],[\"B\",is(ta4_c=\"B\"), \"Boxplot B\"],[\"C\",is(ta4_c=\"C\"), \"Boxplot C\"],[\"D\",is(ta4_c=\"D\"), \"Boxplot D\"]]       <p>Data size = {@n@}. Answer list: {@[ta1_c,ta2_c,ta3_c,ta4_c]@}<\/p>      1  0  0   <p>Correct answer, well done.<\/p>    <p>Your answer is partially correct.<\/p>    <p>Incorrect answer.<\/p>   .  *10  dot  1  i  cos-1  lang  [  0    ans1  dropdown  ta1  15  1  0   0    1  0  0  0  0     ans2  dropdown  ta2  15  1  0   0    1  0  0  0  0     ans3  dropdown  ta3  15  1  0   0    1  0  0  0  0     ans4  dropdown  ta4  15  1  0   0    1  0  0  0  0     prt1  1.0000000  1  1      0   AlgEquiv  ans1  ta1_c   0  =  1   -1  prt1-1-T     =  0   -1  prt1-1-F        prt2  1.0000000  1  1      0   AlgEquiv  ans2  ta2_c   0  =  1   -1  prt2-1-T     =  0   -1  prt2-1-F        prt3  1.0000000  1  1      0   AlgEquiv  ans3  ta3_c   0  =  1   -1  prt3-1-T     =  0   -1  prt3-1-F        prt4  1.0000000  1  1      0   AlgEquiv  ans4  ta4_c   0  =  1   -1  prt4-1-T     =  0   -1  prt4-1-F       1801006757  768252992  1901898753  1925301602  1316343442  2109495421  1543454398  140518220  1665582679  1030164503  425942596  451148150  1369728296  374485637  1776053810  847030446  271459631  1522679322  1388158991  57289455  553761874  2006693680  335428334  1807555479  336215593  1038662071  2050421240  854347360  616343465  1496310453  819154543  493731052  1451165897  1036523842  471844676  528939971  3402304  1106143636  1576038739  1619350419  1149313236  300087478  1279523893  1539829830  830626927  1041797952  740558512  1062067506  1801148755  1403585311  1909028018  1235618568  1300948314  1667452766  173301734  56555878  440003830  576180509  1952330545  219751550  1478334696  81902505  102107907  1141627915  1728031519  769958447  1657940095  483317018  1327974645  1588417208  1152955789  55023231  1319737195  1012899027  678812362  1651285347  724032048  1334280520  735003663  1445763220  1556214072  1041586978  466667189  1559231113  2116649457  931173427  1401011273  418278936  999781913  350490041  1270066446  1011255394  1970947858  1959094721  1799029378  400906966  1224324728  1647864254  1271249744  1889491786   1  Test case assuming the teacher's input gets full marks.   ans1  first(mcq_correct(ta1))    ans2  first(mcq_correct(ta2))    ans3  first(mcq_correct(ta3))    ans4  first(mcq_correct(ta4))    prt1  1.0000000  0.0000000  prt1-1-T    prt2  1.0000000  0.0000000  prt2-1-T    prt3  1.0000000  0.0000000  prt3-1-T    prt4  1.0000000  0.0000000  prt4-1-T         "
},
{
  "id": "sec-conceptual-understanding-2-1",
  "level": "2",
  "url": "sec-conceptual-understanding.html#sec-conceptual-understanding-2-1",
  "type": "Checkpoint",
  "number": "[STRUCT].0",
  "title": "Edit a boxplot to match a histogram.",
  "body": " Edit a boxplot to match a histogram        Edit a boxplot to match a histogram    <p>Move the qualrtiles and median lines in the box plot so that it is representative of the data displayed in the histogram below.<\/p> [[jsxgraph input-ref-ans1=\"sR1\" input-ref-ans2=\"sR2\" input-ref-ans3=\"sR3\" input-ref-ans4=\"sR4\" input-ref-ans5=\"sR5\" input-ref-ans6=\"sR6\" input-ref-ans7=\"sR7\" input-ref-ans8=\"sR8\"]] function plot_histogram(data, numbars, board) { var numel = data.length; var min_bound = Math.floor(Math.min.apply(Math, data)); var max_bound = Math.ceil(Math.max.apply(Math, data)); var range = max_bound - min_bound; var numbars = Math.abs(Math.ceil(numbars)); if (numbars == 0) { numbars = 1; } var barwidth = range \/ numbars; \/\/var tot = data.reduce((a, b) => a + b, 0); var relfreq = []; for (var b = 0; b < numbars; b++) { var data_in_bar = data.filter(function(d) { if (b == 0) { return (d >= min_bound + b * barwidth) && (d <= min_bound + (b + 1) * barwidth) } else { return (d > min_bound + b * barwidth) && (d <= min_bound + (b + 1) * barwidth) } }); relfreq.push(data_in_bar.length) } var ymax = Math.max.apply(Math, relfreq) \/ barwidth; board.setBoundingBox([min_bound - 0.2 * min_bound, ymax * 1.25, max_bound * 1.2, -(ymax * 0.2)], false); \/\/ create axes var origin = board.create('point', [min_bound - 0.1 * min_bound, 0], { face: '', visible: false, size: 2, name: '', fixed: true }); var y_end = board.create('point', [min_bound - 0.1 * min_bound, ymax * 1.1], { face: '', visible: false, size: 2, name: '', fixed: true }); var x_end = board.create('point', [max_bound * 1.1, 0], { face: '', visible: false, size: 2, name: '', fixed: true }); var x_axis = board.create('segment', [origin, x_end], { strokeColor: 'black', strokeWidth: 1 }); var y_axis = board.create('segment', [origin, y_end], { strokeColor: 'black', strokeWidth: 1 }); var Lx = Math.ceil(range \/ 3); var x_tick_pos = [min_bound, min_bound + Lx, min_bound + 2 * Lx, min_bound + 3 * Lx]; var x_tick_label = [min_bound, min_bound + Lx, min_bound + 2 * Lx, min_bound + 3 * Lx]; x_tick_pos.forEach(function(el, index, arr) { arr[index] = el - 0.9 * min_bound }); var t_x = board.create('ticks', [x_axis, x_tick_pos], { drawLabels: true, labels: x_tick_label, minorTicks: 0, label: { autoPosition: true, offset: [-7.5, -12.5] } }); var Ly = Math.ceil(ymax \/ 3); var y_tick_pos = [0, Ly, 2 * Ly, Math.ceil(ymax)]; var t_y = board.create('ticks', [y_axis, y_tick_pos], { labels: y_tick_pos, drawLabels: true, minorTicks: 0, label: { autoPosition: true, offset: [-25, 0] } }); \/\/plot histogram for (var i = 0; i < numbars; i++) { var p0 = board.create('point', [min_bound + (i) * barwidth, 0], { face: '', visible: false, size: 2, name: '', fixed: true }); var p1 = board.create('point', [min_bound + (i) * barwidth, relfreq[i] \/ barwidth], { face: '', visible: false, size: 2, name: '', fixed: true }); var p2 = board.create('point', [min_bound + (i + 1) * barwidth, 0], { face: '', visible: false, size: 2, name: '', fixed: true }); var p3 = board.create('point', [min_bound + (i + 1) * barwidth, relfreq[i] \/ barwidth], { face: '', visible: false, size: 2, name: '', fixed: true }); board.create('polygon', [p0, p1, p3, p2], { borders: { strokeColor: 'blue' }, fillColor: '' }) } return ymax; } var data = {#dat#}; var numbars = {#numbars#}; var board = JXG.JSXGraph.initBoard(divid, { axis: false, keepaspectratio: false, showCopyright: false, showNavigation: false, pan: {enable: false} }); var maxy = plot_histogram(data, numbars, board); \/\/ Creating box plot \/\/ Define parameters from histogram for box plot var min_x = Math.floor(Math.min.apply(Math, data)); var max_x = Math.ceil(Math.max.apply(Math, data)); var max_y = maxy*1.2; var mid_y = maxy*1.15; var min_y = maxy*1.1; var lq_x = min_x + (max_x - min_x)\/4; var med_x = min_x + (max_x - min_x)\/2; var uq_x = min_x + 3*(max_x - min_x)\/4; \/\/create upper and lower bounds for the box plot var bot_line = board.create('line', [[0, min_y], [1, min_y]], { straightFirst: true, straightLast: true, strokeWidth: 2, visible: false, fixed: true }); var top_line = board.create('line', [[0, max_y], [1, max_y]], { straightFirst: true, straightLast: true, strokeWidth: 2, visible: false, fixed: true }); \/\/ --------------lq vertical and left horizontal lines start var top_lq = board.create('point', [lq_x, max_y], { name: '', visible: false }); var bot_lq = board.create('point', [lq_x, min_y], { name: '', visible: false }); var mid_lq = board.create('point', [lq_x, mid_y], { name: '', visible: false }); var mid_min = board.create('point', [min_x, mid_y], { name: '', visible: false }); var lq_line = board.create('segment', [top_lq, bot_lq], { strokeWidth: 2, visible: true }); var mid_line_left = board.create('segment', [mid_lq, mid_min], { strokeWidth: 2, visible: true, fixed: true }); lq_line.on('drag', function() { bot_lq.moveTo([bot_lq.X(), min_y]); top_lq.moveTo([top_lq.X(), max_y]); mid_lq.moveTo([top_lq.X(), mid_y]); }); \/\/ --------------lq vertical and left horizontal lines end \/\/ --------------med vertical line start var top_med = board.create('point', [med_x, max_y], { name: '', visible: false }); var bot_med = board.create('point', [med_x, min_y], { name: '', visible: false }); var med_line = board.create('segment', [top_med, bot_med], { strokeWidth: 2, visible: true }); med_line.on('drag', function() { bot_med.moveTo([bot_med.X(), min_y]); top_med.moveTo([top_med.X(), max_y]); }); \/\/ --------------med vertical line end \/\/ --------------uq vertical and right horizontal lines start var top_uq = board.create('point', [uq_x, max_y], { name: '', visible: false }); var bot_uq = board.create('point', [uq_x, min_y], { name: '', visible: false }); var uq_line = board.create('segment', [top_uq, bot_uq], { strokeWidth: 2, visible: true }); var mid_uq = board.create('point', [uq_x, mid_y], { name: '', visible: false }); var mid_max = board.create('point', [max_x, mid_y], { name: '', visible: false }); var mid_line_right = board.create('segment', [mid_uq, mid_max], { strokeWidth: 2, visible: true, fixed: true }); uq_line.on('drag', function() { bot_uq.moveTo([bot_uq.X(), min_y]); top_uq.moveTo([top_uq.X(), max_y]); mid_uq.moveTo([top_uq.X(), mid_y]); }); \/\/ --------------uq vertical and right horizontal lines end \/\/ --------------top horizontal line start var top_line = board.create('segment', [top_lq, top_uq], { strokeWidth: 2, visible: true, fixed: true }); top_uq.on('drag', function() { this.moveTo([this.X(), max_y]); top_lq.moveTo([this.X(), max_y]); }); top_lq.on('drag', function() { top_uq.moveTo([this.X(), max_y]); this.moveTo([this.X(), max_y]); }); top_line.on('drag', function() { top_uq.moveTo([top_uq.X(), max_y]); top_lq.moveTo([top_lq.X(), max_y]); }); \/\/ --------------top horizontal line end \/\/ --------------bottom horizontal line start var bot_line = board.create('segment', [bot_lq, bot_uq], { strokeWidth: 2, visible: true, fixed: true }); bot_uq.on('drag', function() { this.moveTo([this.X(), max_y]); bot_lq.moveTo([this.X(), max_y]); }); bot_lq.on('drag', function() { bot_uq.moveTo([this.X(), max_y]); this.moveTo([this.X(), max_y]); }); bot_line.on('drag', function() { bot_uq.moveTo([bot_uq.X(), min_y]); bot_lq.moveTo([bot_lq.X(), mmin_y]); }); \/\/ --------------top horizontal line end \/\/ max and min lines var min_line = board.create('segment', [[min_x,min_y], [min_x,max_y]], { strokeWidth: 2, visible: true, fixed: true }); var max_line = board.create('segment', [[max_x,min_y], [max_x,max_y]], { strokeWidth: 2, visible: true, fixed: true }); \/* Set answers from state of graph *\/ stack_jxg.bind_point(sR1,top_lq); stack_jxg.bind_point(sR2,bot_lq); stack_jxg.bind_point(sR3,top_med); stack_jxg.bind_point(sR4,bot_med); stack_jxg.bind_point(sR5,top_uq); stack_jxg.bind_point(sR6,bot_uq); stack_jxg.bind_point(sR7,mid_lq); stack_jxg.bind_point(sR8,mid_uq); board.unsuspendUpdate(); [[\/jsxgraph]] <p style=\"display:none;\">[[input:ans1]] [[input:ans2]] [[input:ans3]] [[input:ans4]] [[input:ans5]] [[input:ans6]] [[input:ans7]] [[input:ans8]] [[validation:ans1]] [[validation:ans2]] [[validation:ans3]] [[validation:ans4]] [[validation:ans5]] [[validation:ans6]] [[validation:ans7]] [[validation:ans8]]<\/p> <p>[[feedback:prt2]] [[feedback:prt1]] [[feedback:prt3]]<\/p>      1  0.1  0    2025073100    \/* bounds for data *\/ dat_min: rand(101)+100; dat_max: dat_min+30+rand(21); \/* Data size *\/ n: rand(500)+500; \/* Number of bars in histogram *\/ numbars: 30; \/* Selecting Data Type: 1=Normal, 2=Gamma Left, 3=Gamma Right *\/ type: rand([1,2,3]); \/* Define basic data set *\/ dat: if type = 1 then makelist(float(quantile_normal(rand(1.0),0,1)),i,1,n) else makelist(float(quantile_gamma(rand(1.0),2,20)),i,1,n); \/* Set skew if Gamma *\/ dat: if type = 3 then lmax(dat)-lmin(dat)+2-dat else dat; \/* Place data between the bounds *\/ dat: ((dat-lmin(dat))\/(lmax(dat)-lmin(dat)))*(dat_max-dat_min)+dat_min; \/* Range of data *\/ range: dat_max-dat_min; \/* Answers *\/ med: median(dat); lq: quantile(dat,1\/4); uq: quantile(dat,3\/4);       <p>Type = {@type@}, Median = {@med@}, LQ = {@lq@}, UQ = {@uq@}<\/p>      1  0  0   <span style=\"font-size: 1.5em; color:green;\"><i class=\"fa fa-check\"><\/i><\/span> Correct answer, well done.    <span style=\"font-size: 1.5em; color:orange;\"><i class=\"fa fa-adjust\"><\/i><\/span> Your answer is partially correct.    <span style=\"font-size: 1.5em; color:red;\"><i class=\"fa fa-times\"><\/i><\/span> Incorrect answer.   .  *10  dot  1  i  cos-1  lang  [  0    ans1  algebraic  lq  15  1  0   0    0  0  0  0  0     ans2  algebraic  lq  15  1  0   0    0  0  0  0  0     ans3  algebraic  med  15  1  0   0    0  0  0  0  0     ans4  algebraic  med  15  1  0   0    0  0  0  0  0     ans5  algebraic  uq  15  1  0   0    0  0  0  0  0     ans6  algebraic  uq  15  1  0   0    0  0  0  0  0     ans7  algebraic  lq  15  1  0   0    0  0  0  0  0     ans8  algebraic  uq  15  1  0   0    0  0  0  0  0     prt1  1.0000000  1  1   opt_1:0.05*range; opt_2:0.1*range; large_ans:if ans3[1]>=med then 1 else 0; large_ans_text:if ans3[1]>=med then \"large\" else \"small\";    0   NumAbsolute  ans3[1]  med  opt_1  0  =  1   -1  prt1-1-T   Well done, your estimate for the median is close enough.   =  0   1  prt1-1-F       1   NumAbsolute  ans3[1]  med  opt_2  0  +  0.5   -1  prt1-2-T   Your estimate for the median is almost close enough, it's a bit too {@large_ans_text@}.   -  0   2  prt1-2-F   Unfortunately your estimate of the median is not close enough to a correct estimate.     2   AlgEquiv  large_ans  1   0  +  0   -1  prt1-3-T   Your estimate is too large.   -  0   -1  prt1-3-F   Your estimate is too small.      prt2  1.0000000  1  1   opt_1:0.05*range; opt_2:0.1*range; large_ans:if ans1[1]>=lq then 1 else 0; large_ans_text:if ans1[1]>=lq then \"large\" else \"small\";    0   NumAbsolute  ans1[1]  lq  opt_1  0  =  1   -1  prt2-1-T   Well done, your estimate for the lower quartile is close enough.   =  0   1  prt2-1-F       1   NumAbsolute  ans1[1]  lq  opt_2  0  +  0.5   -1  prt2-2-T   Your estimate for the lower quartile is almost close enough, it's a bit too {@large_ans_text@}.   -  0   2  prt2-2-F   Unfortunately your estimate of the lower quartile is not close enough to a correct estimate.     2   AlgEquiv  large_ans  1   0  +  0   -1  prt2-3-T   Your estimate is too large.   -  0   -1  prt2-3-F   Your estimate is too small.      prt3  1.0000000  1  1   opt_1:0.05*range; opt_2:0.1*range; large_ans:if ans5[1]>=uq then 1 else 0; large_ans_text:if ans5[1]>=uq then \"large\" else \"small\";    0   NumAbsolute  ans5[1]  uq  opt_1  0  =  1   -1  prt3-1-T   Well done, your estimate for the upper quartile is close enough.   =  0   1  prt3-1-F       1   NumAbsolute  ans5[1]  uq  opt_2  0  +  0.5   -1  prt3-2-T   Your estimate for the upper quartile is almost close enough, it's a bit too {@large_ans_text@}.   -  0   2  prt3-2-F   Unfortunately your estimate of the upper quartile is not close enough to a correct estimate.     2   AlgEquiv  large_ans  1   0  +  0   -1  prt3-3-T   Your estimate is too large.   -  0   -1  prt3-3-F   Your estimate is too small.     77384836  235567728  1589206665  767841902  1092264646  309265945  970716851  1115168224  2117995222  16411044  1431488676  824330149  1190443805  243149845  2107269049  835664865  1519590387  485579999  152679216  930324489  1935418237  453203050  1327552098  1420484212  458531632  1812056681  594436593  1220322723  1087557332  361407698  651252019  1752621535  1337254718  1398461573  1369267218  193444948  1884462108  1167804306  1647681732  1265122426  1113491355  1610693537  1785573104  2030037368  1187620484  192368422  1636864513  1453794362  202149253  587550808  1370276933  1939551163  2048641242  13384177  1333548865  1389042349  1896602370  548771737  993113194  1984043286  2067058933  270564681  1001345827  707949520  1434884362  1073417388  354622202  1195281229  1225492636  1519547855  291239905  1550307927  1107902666  1025552944  1205263867  1390150655  1438702232  1000667137  1937094549  1450864969  1533160264  1973522587  228822236  532624089  132889023  1250938820  753358693  1897991048  588362107   <\n>  <\n>      "
},
{
  "id": "sec-conceptual-understanding-2-2",
  "level": "2",
  "url": "sec-conceptual-understanding.html#sec-conceptual-understanding-2-2",
  "type": "Checkpoint",
  "number": "[STRUCT].1",
  "title": "Fill ANOVA table for 2-year tomato data.",
  "body": " Fill ANOVA table for 2-year tomato data        Fill ANOVA table for 2-year tomato data    <p>An experiment was conducted for two years to investigate the effect three factors of light, heat and variety, each at two levels, on the yields of tomatoes.<\/p> <p>Here is an incomplete analysis of variance (ANOVA) table for the tomato data for the <b>\\(2\\) years together<\/b>. <\/p> <p>Complete the ANOVA table.<\/p> <p><b>Give the values to \\(1\\) decimal place.<\/b><\/p> <p> <style type=\"text\/css\"> #maintable td.blue {color:#00F;} <\/style> <table> <caption><\/caption> <thead> <tr> <th scope=\"col\" style=\"text-align: center;border: 1px solid black; \" width=\"100\">Term<\/th> <th scope=\"col\" style=\"text-align: center; border: 1px solid black;\" width=\"100\">Df<\/th> <th scope=\"col\" style=\"text-align: center; border: 1px solid black;\" width=\"100\">Sum Sq<\/th> <th scope=\"col\" style=\"text-align: center;border: 1px solid black;\" width=\"100\">Mean Sq<\/th> <th scope=\"col\" style=\"text-align: center; border: 1px solid black;\" width=\"100\">F Value<\/th> <\/tr> <\/thead> <tbody> <tr> <td style=\"text-align: center;border: 1px solid black; \">Light<\/td> <td style=\"text-align: center;border: 1px solid black; \">{@light_df@}<\/td> <td style=\"text-align: center;border: 1px solid black; \">{@light_ss@}<\/td> <td style=\"text-align: center;border: 1px solid black; \">[[input:ans4]] [[validation:ans4]] [[feedback:prt4]]<\/td> <td style=\"text-align: center;border: 1px solid black; \">[[input:ans8]] [[validation:ans8]] [[feedback:prt8]]<\/td> <\/tr> <tr> <td style=\"text-align: center;border: 1px solid black; \">Heat<\/td> <td style=\"text-align: center;border: 1px solid black; \">{@heat_df@}<\/td> <td style=\"text-align: center;border: 1px solid black; \">{@heat_ss@}<\/td> <td style=\"text-align: center;border: 1px solid black; \">[[input:ans5]] [[validation:ans5]] [[feedback:prt5]]<\/td> <td style=\"text-align: center;border: 1px solid black; \">[[input:ans9]] [[validation:ans9]] [[feedback:prt9]]<\/td> <\/tr> <tr> <td style=\"text-align: center;border: 1px solid black; \">Variety<\/td> <td style=\"text-align: center;border: 1px solid black; \">[[input:ans1]] [[validation:ans1]] [[feedback:prt1a]]<\/td> <td style=\"text-align: center;border: 1px solid black; \">{@variety_ss@}<\/td> <td style=\"text-align: center;border: 1px solid black; \">[[input:ans6]] [[validation:ans6]] [[feedback:prt6]]<\/td> <td style=\"text-align: center;border: 1px solid black; \">[[input:ans10]] [[validation:ans10]] [[feedback:prt10]]<\/td> <\/tr> <tr> <td style=\"text-align: center;border: 1px solid black; \">Residuals<\/td> <td style=\"text-align: center;border: 1px solid black; \">[[input:ans2]] [[validation:ans2]] [[feedback:prt2]]<\/td> <td style=\"text-align: center;border: 1px solid black; \">[[input:ans3]] [[validation:ans3]] [[feedback:prt3]]<\/td> <td style=\"text-align: center;border: 1px solid black; \">[[input:ans7]] [[validation:ans7]] [[feedback:prt7]]<\/td> <td style=\"text-align: center;border: 1px solid black; \"><\/td> <\/tr> <tr> <td style=\"text-align: center;border: 1px solid black; \">Total<\/td> <td style=\"text-align: center;border: 1px solid black; \">{@total_df@}<\/td> <td style=\"text-align: center;border: 1px solid black; \">{@total_ss@}<\/td> <td style=\"text-align: center;border: 1px solid black; \"><\/td> <td style=\"text-align: center;border: 1px solid black; \"><\/td> <\/tr> <\/tbody> <\/table> <\/p>    <p>The complete ANOVA table is shown below.<\/p> <p>There are a few key points to remember:<\/p> <ul> <li>The residual is the \"left over\" after taking into account the variables. So the residual Df and sum of squares is the difference between the total values and the sum of the variables values.<\/li> <li>The mean sum of squares is simply the sum of squares per Df.<\/li> <li>The F value is the ratio of the mean sum of squares and the residual sum of squares. It allows us to compare the variability explained by a variable compared to the unexplained (residual) variability.<\/li> <\/ul> <p> <table> <caption><\/caption> <thead> <tr> <th scope=\"col\" style=\"text-align: center;border: 1px solid black; \" width=\"100\">Term<\/th> <th scope=\"col\" style=\"text-align: center; border: 1px solid black;\" width=\"100\">Df<\/th> <th scope=\"col\" style=\"text-align: center; border: 1px solid black;\" width=\"100\">Sum Sq<\/th> <th scope=\"col\" style=\"text-align: center;border: 1px solid black;\" width=\"100\">Mean Sq<\/th> <th scope=\"col\" style=\"text-align: center; border: 1px solid black;\" width=\"100\">F Value<\/th> <\/tr> <\/thead> <tbody> <tr> <td style=\"text-align: center;border: 1px solid black; \">Light<\/td> <td class=\"blue\" style=\"text-align: center;border: 1px solid black; \">{@light_df@}<\/td> <td style=\"text-align: center;border: 1px solid black; \">{@light_ss@}<\/td> <td style=\"color:#00F; text-align: center;border: 1px solid black; \">{@ta4@}<\/td> <td style=\"color:#00F; text-align: center;border: 1px solid black; \">{@ta8@}<\/td> <\/tr> <tr> <td style=\"text-align: center;border: 1px solid black; \">Heat<\/td> <td style=\"text-align: center;border: 1px solid black; \">{@heat_df@}<\/td> <td style=\"text-align: center;border: 1px solid black; \">{@heat_ss@}<\/td> <td style=\"color:#00F; text-align: center;border: 1px solid black; \">{@ta5@}<\/td> <td style=\"color:#00F; text-align: center;border: 1px solid black; \">{@ta9@}<\/td> <\/tr> <tr> <td style=\"text-align: center;border: 1px solid black; \">Variety<\/td> <td style=\"color:#00F; text-align: center;border: 1px solid black; \">{@ta1@}<\/td> <td style=\"text-align: center;border: 1px solid black; \">{@variety_ss@}<\/td> <td style=\"color:#00F; text-align: center;border: 1px solid black; \">{@ta6@}<\/td> <td style=\"color:#00F; text-align: center;border: 1px solid black; \">{@ta10@}<\/td> <\/tr> <tr> <td style=\"text-align: center;border: 1px solid black; \">Residuals<\/td> <td style=\"color:#00F; text-align: center;border: 1px solid black; \">{@ta2@}<\/td> <td style=\"color:#00F; text-align: center;border: 1px solid black; \">{@ta3@}<\/td> <td style=\"color:#00F; text-align: center;border: 1px solid black; \">{@ta7@}<\/td> <td style=\"text-align: center;border: 1px solid black; \"><\/td> <\/tr> <tr> <td style=\"text-align: center;border: 1px solid black; \">Total<\/td> <td style=\"text-align: center;border: 1px solid black; \">{@total_df@}<\/td> <td style=\"text-align: center;border: 1px solid black; \">{@total_ss@}<\/td> <td style=\"text-align: center;border: 1px solid black; \"><\/td> <td style=\"text-align: center;border: 1px solid black; \"><\/td> <\/tr> <\/tbody> <\/table> <\/p>   1  0.1  0    2025073100    dp(x, n) := float(round((x+10^(-8))*10^n)\/10^n); light_df:1 ; heat_df: 1; variety_df: 1; total_df: 23; resid_df: total_df-heat_df-light_df-variety_df; light_ss: dp(float((rand(10)\/10)+(rand(6)+5)),1); heat_ss: dp(float((rand(10)\/10)+(rand(10)+40)),1); variety_ss: dp(float((rand(10)\/10)+(rand(6)+3)+light_ss),1); resid_ss: dp(float((rand(10)\/10)+(rand(20)+95)),1); total_ss: dp(light_ss+heat_ss+variety_ss+resid_ss,1); light_ms: dp(light_ss\/light_df,1); heat_ms: dp(heat_ss\/heat_df,1); variety_ms: dp(variety_ss\/variety_df,1); resid_ms: dp(resid_ss\/resid_df,1); light_f: dp(light_ms\/resid_ms,1); heat_f: dp(heat_ms\/resid_ms,1); variety_f: dp(variety_ms\/resid_ms,1); ta1:variety_df; ta2:resid_df; ta3:resid_ss; ta4:light_ms; ta5:heat_ms; ta6:variety_ms; ta7:resid_ms; ta8:light_f; ta9:heat_f; ta10:variety_f;       <p>This question note was 1. This is marginally better, but someone should fix this.<\/p> {@ta1@} {@ta2@} {@ta3@} {@ta4@} {@ta5@} {@ta6@} {@ta7@} {@ta8@} {@ta9@} {@ta10@}      1  0  0   <span style=\"font-size: 1.5em; color:green;\"><i class=\"fa fa-check\"><\/i><\/span> Well done.    <span style=\"font-size: 1.5em; color:orange;\"><i class=\"fa fa-adjust\"><\/i><\/span> Your answer is partially correct.    <span style=\"font-size: 1.5em; color:red;\"><i class=\"fa fa-times\"><\/i><\/span> Incorrect answer.   .  *10  dot  1  i  cos-1  lang  [  0    ans1  numerical  ta1  5  1  0   0    0  0  0  0  0  maxdp:1    ans10  numerical  ta10  5  1  0   0    0  0  0  0  0  maxdp:1    ans2  numerical  ta2  5  1  0   0    0  0  0  0  0  maxdp:1    ans3  numerical  ta3  5  1  0   0    0  0  0  0  0  maxdp:1    ans4  numerical  ta4  5  1  0   0    0  0  0  0  0  maxdp:1    ans5  numerical  ta5  5  1  0   0    0  0  0  0  0  maxdp:1    ans6  numerical  ta6  5  1  0   0    0  0  0  0  0  maxdp:1    ans7  numerical  ta7  5  1  0   0    0  0  0  0  0  maxdp:1    ans8  numerical  ta8  5  1  0   0    0  0  0  0  0  maxdp:1    ans9  numerical  ta9  5  1  0   0    0  0  0  0  0  maxdp:1    prt10  1.0000000  1  1   s_ta10: dp(ans6\/ans7,1);    0   AlgEquiv  ans10  s_ta10   0  =  1   -1  prt10-1-T   Correct F value based on your mean sum of squares and residual sum of squares.   =  0   1  prt10-1-F       1   AlgEquiv  ans10  ta10   0  +  1   -1  prt10-2-T   Hmm, how did this happen? Your F value is correct, but your mean sum of squares or residual sum of squares is not. Did you make a typing mistake? Anyway you still get some marks :)   -  0   -1  prt10-2-F   The F value is the ratio of the mean sum of squares over the residual sum of squares.      prt1a  1.0000000  1  1      0   AlgEquiv  ans1  ta1   0  =  1   -1  prt2-1-T     =  0   -1  prt2-1-F   In the tomato data there are two varieties, hence there is \\(1\\) i.e. \\((n-1)\\) degrees of freedom.      prt2  1.0000000  1  1   s_ta2: total_df-light_df-heat_df-ans1    0   AlgEquiv  ans2  s_ta2   0  =  1   -1  prt2-1-T   Correct residual Df based on the Df values of light, heat and variety in your table.   =  0   1  prt2-1-F       1   AlgEquiv  ans2  ta2   0  +  1   -1  prt2-2-T   Hmm, how did this happen? Your residual Df is correct, but your variety Df is not. Did you make a typing mistake? Anyway you still get some marks :)   -  0   -1  prt2-2-F   Residual is the \"left over\" from the variables. So the residual degrees of freedom is the total degree of freedom of the data minus the degrees of freedoms of the variables.      prt3  1.0000000  1  1      0   AlgEquiv  ans3  ta3   0  =  1   -1  prt3-1-T     =  0   -1  prt3-1-F   Like the degrees of freedom, the residual sum of squares is the total sum of squares minus the sums of squares of the variables.      prt4  1.0000000  1  1      0   AlgEquiv  ans4  ta4   0  =  1   -1  prt4-1-T     =  0   -1  prt4-1-F   Mean sum of squares is the sum of squares per degree of freedom.      prt5  1.0000000  1  1      0   AlgEquiv  ans5  ta5   0  =  1   -1  prt5-1-T     =  0   -1  prt5-1-F   Mean sum of squares is the sum of squares per degree of freedom.      prt6  1.0000000  1  1   s_ta6: dp(variety_ss\/ans1,1);    0   AlgEquiv  ans6  s_ta6   0  =  1   -1  prt6-1-T   Correct mean square value based on your sum of squares and Df.   =  0   1  prt6-1-F       1   AlgEquiv  ans6  ta6   0  +  1   -1  prt6-2-T   Hmm, how did this happen? Your mean sum of squares is correct, but your Df is not. Did you make a typing mistake? Anyway you still get some marks :)   -  0   -1  prt6-2-F   Mean sum of squares is the sum of squares per degree of freedom.      prt7  1.0000000  1  1   s_ta7: dp(ans3\/ans2,1);    0   AlgEquiv  ans7  s_ta7   0  =  1   -1  prt7-1-T   Correct residual mean square value based on your residual sum of squares and Df.   =  0   1  prt7-1-F       1   AlgEquiv  ans7  ta7   0  +  1   -1  prt7-2-T   Hmm, how did this happen? Your mean sum of squares is correct, but your sum of squares or Df is not. Did you make a typing mistake? Anyway you still get some marks :)   -  0   -1  prt7-2-F   Mean sum of squares is the sum of squares per degree of freedom.      prt8  1.0000000  1  1   s_ta8: dp(ans4\/ans7,1);    0   AlgEquiv  ans8  s_ta8   0  =  1   -1  prt8-1-T   Correct F value based on your mean sum of squares and residual sum of squares.   =  0   1  prt8-1-F       1   AlgEquiv  ans8  ta8   0  +  1   -1  prt8-2-T   Hmm, how did this happen? Your F value is correct, but your mean ss is not. Did you make a typing mistake? Anyway you still get some marks :)   -  0   -1  prt8-2-F   The F value is the ratio of the mean sum of squares over the residual sum of squares.      prt9  1.0000000  1  1   s_ta9: dp(ans5\/ans7,1);    0   AlgEquiv  ans9  s_ta9   0  =  1   -1  prt9-1-T   Correct F value based on your mean sum of squares and residual sum of squares.   =  0   1  prt9-1-F       1   AlgEquiv  ans9  ta9   0  +  0   -1  prt9-2-T   Hmm, how did this happen? Your F value is correct, but your mean sum of squares or residual sum of squares is not. Did you make a typing mistake? Anyway you still get some marks :)   -  0   -1  prt9-2-F   The F value is the ratio of the mean sum of squares over the residual sum of squares.     2084736791  419774382  1951587842  1155796730  555237110  662068959  863426754  772871690  957528482  1643677683  2263400  1290080932  77179216  1649034504  105007370  217508555   1  Test case assuming the teacher's input gets full marks.   ans1  ta1    ans10  ta10    ans2  ta2    ans3  ta3    ans4  ta4    ans5  ta5    ans6  ta6    ans7  ta7    ans8  ta8    ans9  ta9    prt10  1.0000000  0.0000000  prt10-1-T    prt1a  1.0000000  0.0000000  prt2-1-T    prt2  1.0000000  0.0000000  prt2-1-T    prt3  1.0000000  0.0000000  prt3-1-T    prt4  1.0000000  0.0000000  prt4-1-T    prt5  1.0000000  0.0000000  prt5-1-T    prt6  1.0000000  0.0000000  prt6-1-T    prt7  1.0000000  0.0000000  prt7-1-T    prt8  1.0000000  0.0000000  prt8-1-T    prt9  1.0000000  0.0000000  prt9-1-T       "
},
{
  "id": "sec-conceptual-understanding-2-3",
  "level": "2",
  "url": "sec-conceptual-understanding.html#sec-conceptual-understanding-2-3",
  "type": "Checkpoint",
  "number": "[STRUCT].2",
  "title": "Fill ANOVA table for a millet experiment.",
  "body": " Fill ANOVA table for a millet experiment        Fill ANOVA table for a millet experiment    <p>An experiment is conducted on {@plots@} plots to understand the effect of several factors on the yield of millet.<\/p> <p>The factors are: {@variety@} varieties of millet, {@weeding@} types of weeding and {@fert@} different levels of fertiliser.<\/p> <p>Complete the ANOVA table for the experiment.<\/p> <p><b>Give the values to \\(1\\) decimal place.<\/b><\/p> <p> <style type=\"text\/css\"> #maintable td.blue {color:#00F;} <\/style> <table> <caption><\/caption> <thead> <tr> <th scope=\"col\" style=\"text-align: center;border: 1px solid black; \" width=\"100\">Term<\/th> <th scope=\"col\" style=\"text-align: center; border: 1px solid black;\" width=\"100\">Df<\/th> <th scope=\"col\" style=\"text-align: center; border: 1px solid black;\" width=\"100\">Sum Sq<\/th> <th scope=\"col\" style=\"text-align: center;border: 1px solid black;\" width=\"100\">Mean Sq<\/th> <th scope=\"col\" style=\"text-align: center; border: 1px solid black;\" width=\"100\">F Value<\/th> <\/tr> <\/thead> <tbody> <tr> <td style=\"text-align: center;border: 1px solid black; \">Variety<\/td> <td style=\"text-align: center;border: 1px solid black; \">[[input:ans_variety_df]] [[validation:ans_variety_df]] [[feedback:prt1_variety_df]]<\/td> <td style=\"text-align: center;border: 1px solid black; \">{@variety_ss@}<\/td> <td style=\"text-align: center;border: 1px solid black; \">[[input:ans_variety_ms]] [[validation:ans_variety_ms]] [[feedback:prt_variety_ms]]<\/td> <td style=\"text-align: center;border: 1px solid black; \">[[input:ans_variety_f]] [[validation:ans_variety_f]] [[feedback:prt_variety_f]]<\/td> <\/tr> <tr> <td style=\"text-align: center;border: 1px solid black; \">Weeding<\/td> <td style=\"text-align: center;border: 1px solid black; \">[[input:ans_weeding_df]] [[validation:ans_weeding_df]] [[feedback:prt_weeding_df]]<\/td> <td style=\"text-align: center;border: 1px solid black; \">{@weeding_ss@}<\/td> <td style=\"text-align: center;border: 1px solid black; \">[[input:ans_weeding_ms]] [[validation:ans_weeding_ms]] [[feedback:prt_weeding_ms]]<\/td> <td style=\"text-align: center;border: 1px solid black; \">[[input:ans_weeding_f]] [[validation:ans_weeding_f]] [[feedback:prt_weeding_f]]<\/td> <\/tr> <tr> <td style=\"text-align: center;border: 1px solid black; \">Fertiliser<\/td> <td style=\"text-align: center;border: 1px solid black; \">[[input:ans_fert_df]] [[validation:ans_fert_df]] [[feedback:prt_fert_df]]<\/td> <td style=\"text-align: center;border: 1px solid black; \">{@fert_ss@}<\/td> <td style=\"text-align: center;border: 1px solid black; \">[[input:ans_fert_ms]] [[validation:ans_fert_ms]] [[feedback:prt_fert_ms]]<\/td> <td style=\"text-align: center;border: 1px solid black; \">[[input:ans_fert_f]] [[validation:ans_fert_f]] [[feedback:prt_fert_f]]<\/td> <\/tr> <tr> <td style=\"text-align: center;border: 1px solid black; \">Residuals<\/td> <td style=\"text-align: center;border: 1px solid black; \">[[input:ans_resid_df]] [[validation:ans_resid_df]] [[feedback:prt_resid_df]]<\/td> <td style=\"text-align: center;border: 1px solid black; \">[[input:ans_resid_ss]] [[validation:ans_resid_ss]] [[feedback:prt_resid_ss]]<\/td> <td style=\"text-align: center;border: 1px solid black; \">[[input:ans_resid_ms]] [[validation:ans_resid_ms]] [[feedback:prt_resid_ms]]<\/td> <td style=\"text-align: center;border: 1px solid black; \"><\/td> <\/tr> <tr> <td style=\"text-align: center;border: 1px solid black; \">Total<\/td> <td style=\"text-align: center;border: 1px solid black; \">[[input:ans_total_df]] [[validation:ans_total_df]] [[feedback:prt1_total_df]]<\/td> <td style=\"text-align: center;border: 1px solid black; \">{@total_ss@}<\/td> <td style=\"text-align: center;border: 1px solid black; \"><\/td> <td style=\"text-align: center;border: 1px solid black; \"><\/td> <\/tr> <\/tbody> <\/table> <\/p>    <p>The complete ANOVA table is shown below.<\/p> <p>There are a few key points to remember:<\/p> <ul> <li>The residual is the \"left over\" after taking into account the variables. So the residual Df and sum of squares is the difference between the total values and the sum of the variables values.<\/li> <li>The mean sum of squares is simply the sum of squares per Df.<\/li> <li>The F value is the ratio of the mean sum of squares and the residual sum of squares. It allows us to compare the variability explained by a variable compared to the unexplained (residual) variability.<\/li> <\/ul> <p> <table> <caption><\/caption> <thead> <tr> <th scope=\"col\" style=\"text-align: center;border: 1px solid black; \" width=\"100\">Term<\/th> <th scope=\"col\" style=\"text-align: center; border: 1px solid black;\" width=\"100\">Df<\/th> <th scope=\"col\" style=\"text-align: center; border: 1px solid black;\" width=\"100\">Sum Sq<\/th> <th scope=\"col\" style=\"text-align: center;border: 1px solid black;\" width=\"100\">Mean Sq<\/th> <th scope=\"col\" style=\"text-align: center; border: 1px solid black;\" width=\"100\">F Value<\/th> <\/tr> <\/thead> <tbody> <tr> <td style=\"text-align: center;border: 1px solid black; \">Variety<\/td> <td style=\"color:#00F; text-align: center;border: 1px solid black; \">{@variety_df@}<\/td> <td style=\"text-align: center;border: 1px solid black; \">{@variety_ss@}<\/td> <td style=\"color:#00F; text-align: center;border: 1px solid black; \">{@variety_ms@}<\/td> <td style=\"color:#00F; text-align: center;border: 1px solid black; \">{@variety_f@}<\/td> <\/tr> <tr> <td style=\"text-align: center;border: 1px solid black; \">Weeding<\/td> <td style=\"color:#00F; text-align: center;border: 1px solid black; \">{@weeding_df@}<\/td> <td style=\"text-align: center;border: 1px solid black; \">{@weeding_ss@}<\/td> <td style=\"color:#00F; text-align: center;border: 1px solid black; \">{@weeding_ms@}<\/td> <td style=\"color:#00F; text-align: center;border: 1px solid black; \">{@weeding_f@}<\/td> <\/tr> <tr> <td style=\"text-align: center;border: 1px solid black; \">Fertiliser<\/td> <td style=\"color:#00F; text-align: center;border: 1px solid black; \">{@fert_df@}<\/td> <td style=\"text-align: center;border: 1px solid black; \">{@fert_ss@}<\/td> <td style=\"color:#00F; text-align: center;border: 1px solid black; \">{@fert_ms@}<\/td> <td style=\"color:#00F; text-align: center;border: 1px solid black; \">{@fert_f@}<\/td> <\/tr> <tr> <td style=\"text-align: center;border: 1px solid black; \">Residuals<\/td> <td style=\"color:#00F; text-align: center;border: 1px solid black; \">{@resid_df@}<\/td> <td style=\"color:#00F; text-align: center;border: 1px solid black; \">{@resid_ss@}<\/td> <td style=\"color:#00F; text-align: center;border: 1px solid black; \">{@resid_ms@}<\/td> <td style=\"text-align: center;border: 1px solid black; \"><\/td> <\/tr> <tr> <td style=\"text-align: center;border: 1px solid black; \">Total<\/td> <td style=\"color:#00F; text-align: center;border: 1px solid black; \">{@total_df@}<\/td> <td style=\"text-align: center;border: 1px solid black; \">{@total_ss@}<\/td> <td style=\"text-align: center;border: 1px solid black; \"><\/td> <td style=\"text-align: center;border: 1px solid black; \"><\/td> <\/tr> <\/tbody> <\/table> <\/p>   1  0.1  0    2025073100    dp(x, n) := float(round((x+10^(-8))*10^n)\/10^n); plots: 30+rand(10); variety: 4+rand(3); weeding: 2+rand(2); fert: 3+rand(2); variety_df:variety-1; weeding_df: weeding-1; fert_df: fert-1; total_df: plots-1; resid_df: total_df-weeding_df-variety_df-fert_df; variety_ss: dp(float((rand(10)\/10)+(rand(10)+20)),1); weeding_ss: dp(float((rand(10)\/10)+(rand(10)+10)),1); fert_ss: dp(float((rand(10)\/10)+rand(6)+40),1); resid_ss: dp(float((rand(10)\/10)+(rand(20)+65)),1); total_ss: dp(variety_ss+weeding_ss+fert_ss+resid_ss,1); variety_ms: dp(variety_ss\/variety_df,1); weeding_ms: dp(weeding_ss\/weeding_df,1); fert_ms: dp(fert_ss\/fert_df,1); resid_ms: dp(resid_ss\/resid_df,1); variety_f: dp(variety_ms\/resid_ms,1); weeding_f: dp(weeding_ms\/resid_ms,1); fert_f: dp(fert_ms\/resid_ms,1); ta1:fert_df; ta2:resid_df; ta3:resid_ss; ta4:variety_ms; ta5:weeding_ms; ta6:fert_ms; ta7:resid_ms; ta8:variety_f; ta9:weeding_f; ta10:fert_f; ta11: variety_df; ta12: weeding_df; ta13: total_df;       <p>This question note was 1. This is marginally better, but someone should fix this.<\/p> {@ta1@} {@ta2@} {@ta3@} {@ta4@} {@ta5@} {@ta6@} {@ta7@} {@ta8@} {@ta9@} {@ta10@} {@ta11@} {@ta12@} {@ta13@}      1  0  0   <span style=\"font-size: 1.5em; color:green;\"><i class=\"fa fa-check\"><\/i><\/span> Well done.    <span style=\"font-size: 1.5em; color:orange;\"><i class=\"fa fa-adjust\"><\/i><\/span> Your answer is partially correct.    <span style=\"font-size: 1.5em; color:red;\"><i class=\"fa fa-times\"><\/i><\/span> Incorrect answer.   .  *10  dot  1  i  cos-1  lang  [  0    ans_fert_df  numerical  ta1  5  1  0   0    0  0  0  0  0  maxdp:1    ans_fert_f  numerical  ta10  5  1  0   0    0  0  0  0  0  maxdp:1    ans_fert_ms  numerical  ta6  5  1  0   0    0  0  0  0  0  maxdp:1    ans_resid_df  numerical  ta2  5  1  0   0    0  0  0  0  0  maxdp:1    ans_resid_ms  numerical  ta7  5  1  0   0    0  0  0  0  0  maxdp:1    ans_resid_ss  numerical  ta3  5  1  0   0    0  0  0  0  0  maxdp:1    ans_total_df  numerical  ta13  5  1  0   0    0  0  0  0  0     ans_variety_df  numerical  ta11  5  1  0   0    0  0  0  0  0     ans_variety_f  numerical  ta8  5  1  0   0    0  0  0  0  0  maxdp:1    ans_variety_ms  numerical  ta4  5  1  0   0    0  0  0  0  0  maxdp:1    ans_weeding_df  numerical  ta12  5  1  0   0    0  0  0  0  0     ans_weeding_f  numerical  ta9  5  1  0   0    0  0  0  0  0  maxdp:1    ans_weeding_ms  numerical  ta5  5  1  0   0    0  0  0  0  0  maxdp:1    prt_fert_df  1.0000000  1  1      0   AlgEquiv  ans_fert_df  ta1   0  =  1   -1  prt2-1-T     =  0   -1  prt2-1-F   There are {@fert@} levels of fertiliser, hence there are {@ta1@} i.e. \\((n-1)\\) degrees of freedom.      prt_fert_f  1.0000000  1  1   s_ta10: dp(ans_fert_ms\/ans_resid_ms,1);    0   NumAbsolute  ans_fert_f  s_ta10  0.1  0  =  1   -1  prt10-1-T   Correct F value based on your mean sum of squares and residual sum of squares.   =  0   1  prt10-1-F       1   NumAbsolute  ans_fert_f  ta10  0.1  0  +  1   -1  prt10-2-T   Hmm, how did this happen? Your F value is correct, but your mean sum of squares or residual sum of squares is not. Did you make a typing mistake? Anyway you still get some marks :)   -  0   -1  prt10-2-F   The F value is the ratio of the mean sum of squares over the residual sum of squares.      prt_fert_ms  1.0000000  1  1   s_ta6: dp(fert_ss\/ans_fert_df,1);    0   AlgEquiv  ans_fert_ms  s_ta6   0  =  1   -1  prt6-1-T   Correct mean square value based on your sum of squares and Df.   =  0   1  prt6-1-F   {@fert_ss@} {@ans_fert_df@}     1   AlgEquiv  ans_fert_ms  ta6   0  +  1   -1  prt6-2-T   Hmm, how did this happen? Your mean sum of squares is correct, but your Df is not. Did you make a typing mistake? Anyway you still get some marks :)   -  0   -1  prt6-2-F   Mean sum of squares is the sum of squares per degree of freedom.      prt_resid_df  1.0000000  1  1   s_ta2: ans_total_df-ans_variety_df-ans_weeding_df-ans_fert_df    0   AlgEquiv  ans_resid_df  s_ta2   0  =  1   -1  prt2-1-T   Correct residual Df based on the total and factor Df values in your table.   =  0   1  prt2-1-F       1   AlgEquiv  ans_resid_df  ta2   0  +  1   -1  prt2-2-T   Hmm, how did this happen? Your residual Df is correct, but some of your other Df values are not. Did you make a typing mistake? Anyway you still get some marks :)   -  0   -1  prt2-2-F   Residual is the \"left over\" from the variables. So the residual degrees of freedom is the total degree of freedom of the data minus the degrees of freedoms of the factors.      prt_resid_ms  1.0000000  1  1   s_ta7: dp(ans_resid_ss\/ans_resid_df,1);    0   NumAbsolute  ans_resid_ms  s_ta7  0.1  0  =  1   -1  prt7-1-T   Correct residual mean square value based on your residual sum of squares and Df.   =  0   1  prt7-1-F       1   NumAbsolute  ans_resid_ms  ta7  0.1  0  +  1   -1  prt7-2-T   Hmm, how did this happen? Your mean sum of squares is correct, but your sum of squares or Df is not. Did you make a typing mistake? Anyway you still get some marks :)   -  0   -1  prt7-2-F   Mean sum of squares is the sum of squares per degree of freedom.      prt_resid_ss  1.0000000  1  1      0   AlgEquiv  ans_resid_ss  ta3   0  =  1   -1  prt3-1-T     =  0   -1  prt3-1-F   Like the degrees of freedom, the residual sum of squares is the total sum of squares minus the sums of squares of the variables.      prt_variety_f  1.0000000  1  1   s_ta8: dp(ans_variety_ms\/ans_resid_ms,1);    0   NumAbsolute  ans_variety_f  s_ta8  0.1  0  =  1   -1  prt8-1-T   Correct F value based on your mean sum of squares and residual sum of squares.   =  0   1  prt8-1-F       1   NumAbsolute  ans_variety_f  ta8  0.1  0  +  1   -1  prt8-2-T   Hmm, how did this happen? Your F value is correct, but your mean ss is not. Did you make a typing mistake? Anyway you still get some marks :)   -  0   -1  prt8-2-F   The F value is the ratio of the mean sum of squares over the residual sum of squares.      prt_variety_ms  1.0000000  1  1   s_ta4: dp(variety_ss\/ans_variety_df,1);    0   AlgEquiv  ans_variety_ms  s_ta4   0  =  1   -1  prt4-1-T   Correct mean square value based on your sum of squares and Df.   =  0   1  prt4-1-F       1   AlgEquiv  ans_variety_ms  ta4   0  +  1   -1  prt4-2-T   Hmm, how did this happen? Your mean sum of squares is correct, but your Df is not. Did you make a typing mistake? Anyway you still get some marks :)   -  0   -1  prt4-2-F   Mean sum of squares is the sum of squares per degree of freedom.      prt_weeding_df  1.0000000  1  1      0   AlgEquiv  ans_weeding_df  ta12   0  =  1   -1  prt12-1-T     =  0   -1  prt12-1-F   There are {@weeding@} levels of weeding, hence there are {@ta12@} i.e. \\((n-1)\\) degrees of freedom.      prt_weeding_f  1.0000000  1  1   s_ta9: dp(ans_weeding_ms\/ans_resid_ms,1);    0   NumAbsolute  ans_weeding_f  s_ta9  0.1  0  =  1   -1  prt9-1-T   Correct F value based on your mean sum of squares and residual sum of squares.   =  0   1  prt9-1-F       1   AlgEquiv  ans_weeding_f  ta9   0  +  1   -1  prt9-2-T   Hmm, how did this happen? Your F value is correct, but your mean sum of squares or residual sum of squares is not. Did you make a typing mistake? Anyway you still get some marks :)   -  0   -1  prt9-2-F   The F value is the ratio of the mean sum of squares over the residual sum of squares.      prt_weeding_ms  1.0000000  1  1   s_ta5: dp(weeding_ss\/ans_weeding_df,1);    0   AlgEquiv  ans_weeding_ms  s_ta5   0  =  1   -1  prt5-1-T   Correct mean square value based on your sum of squares and Df.   =  0   1  prt5-1-F       1   AlgEquiv  ans_weeding_ms  ta5   0  +  1   -1  prt_weeding_ms-2-T   Hmm, how did this happen? Your mean mean square is correct, but your Df is not. Did you make a typing mistake? Anyway you still get some marks :)   -  0   -1  prt_weeding_ms-2-F   Mean sum of squares is the sum of squares per degree of freedom.      prt1_total_df  1.0000000  1  1      0   AlgEquiv  ans_total_df  ta13   0  =  1   -1  prt13-1-T     =  0   -1  prt13-1-F   The total degrees of freedom is the number of observations minus \\(1\\), so {@total_df@}.      prt1_variety_df  1.0000000  1  1      0   AlgEquiv  ans_variety_df  ta11   0  =  1   -1  prt11-1-T     =  0   -1  prt11-1-F   There are {@variety@} different varieties, hence there are {@ta11@} i.e. \\((n-1)\\) degrees of freedom.     408042425  1844761798  1192345098  1960516951  1781511457  802855958  286416426  714241569  2043431606  876461352  1540175555  521137151  92500197  500830597  1694534167   1  Test case assuming the teacher's input gets full marks.   ans_fert_df  ta1    ans_fert_f  ta10    ans_fert_ms  ta6    ans_resid_df  ta2    ans_resid_ms  ta7    ans_resid_ss  ta3    ans_total_df  ta13    ans_variety_df  ta11    ans_variety_f  ta8    ans_variety_ms  ta4    ans_weeding_df  ta12    ans_weeding_f  ta9    ans_weeding_ms  ta5    prt_fert_df  1.0000000  0.0000000  prt2-1-T    prt_fert_f  1.0000000  0.0000000  prt10-1-T    prt_fert_ms  1.0000000  0.0000000  prt6-1-T    prt_resid_df  1.0000000  0.0000000  prt2-1-T    prt_resid_ms  1.0000000  0.0000000  prt7-1-T    prt_resid_ss  1.0000000  0.0000000  prt3-1-T    prt_variety_f  1.0000000  0.0000000  prt8-1-T    prt_variety_ms  1.0000000  0.0000000  prt4-1-T    prt_weeding_df  1.0000000  0.0000000  prt12-1-T    prt_weeding_f  1.0000000  0.0000000  prt9-1-T    prt_weeding_ms  1.0000000  0.0000000  prt5-1-T    prt1_total_df  1.0000000  0.0000000  prt13-1-T    prt1_variety_df  1.0000000  0.0000000  prt11-1-T       "
},
{
  "id": "sec-conceptual-understanding-2-4",
  "level": "2",
  "url": "sec-conceptual-understanding.html#sec-conceptual-understanding-2-4",
  "type": "Checkpoint",
  "number": "[STRUCT].3",
  "title": "Interpret and match dotplots to respective boxplots.",
  "body": " Interpret and match dotplots to respective boxplots        Interpret and match dotplots to respective boxplots    <p>Below are stacked Dot Plots and Box Plots for four different sets of data.<\/p> <p>Which box plot matches with each dot plot?<\/p> <p>Dot plots:<\/p> <p>[[jsxgraph]] \/\/ Create empty list of points var p = []; \/\/ Create board var board = JXG.JSXGraph.initBoard(divid, { boundingbox: [{#xmin#}, {#ymax#}, {#xmax#}, {#ymin#}], keepaspectratio: false, showCopyright: false, axis:true, pan:{enabled:false} }); \/\/Create points of Data Set 4 var lx4 = {#datx4#}; var ly4 = {#daty4#}; var i = 0; for (i = 0; i <= lx4.length - 1; i++) { p[i] = board.create('point', [lx4[i], ly4[i]], { face: 'x', name: '', size: 2, fixed:true }); } \/\/Create Label for Data 4 var txt = board.create('text', [{#xmin#}+1, {#maxfreq4+ver_diff-3#}, \"D4\"], { fontSize: 20,fixed: true }); \/\/Create divisor between V3 and V4 var div1 = board.create('line', [ [{#xmin#},{#maxfreq4+ver_diff+0.5#}], [{#xmax#},{#maxfreq4+ver_diff+0.5#}] ], { straightFirst: false, straightLast: false, strokeWidth: 1, dash:2 }); \/\/Create divisor between V2 and V3 var div2 = board.create('line', [ [{#xmin#},{#maxfreq4+maxfreq3+2*ver_diff+0.5#}], [{#xmax#},{#maxfreq4+maxfreq3+2*ver_diff+0.5#}] ], { straightFirst: false, straightLast: false, strokeWidth: 1, dash:2 }); \/\/Create divisor between V1 and V2 var div3 = board.create('line', [ [{#xmin#},{#maxfreq4+maxfreq3+maxfreq2+3*ver_diff+0.5#}], [{#xmax#},{#maxfreq4+maxfreq3+maxfreq2+3*ver_diff+0.5#}] ], { straightFirst: false, straightLast: false, strokeWidth: 1, dash:2 }); \/\/Create points of Data Set 3 var lx3 = {#datx3#}; var ly3 = {#daty3#}; var i = 0; for (i = 0; i <= lx3.length - 1; i++) { p[i] = board.create('point', [lx3[i], ly3[i]], { face: 'x', name: '', size: 2, fixed:true }); } \/\/Create Label for Data 3 var txt = board.create('text', [{#xmin#}+1, {#maxfreq3+maxfreq4+2*ver_diff-3#}, \"D3\"], { fontSize: 20,fixed: true }); \/\/Create points of Data Set 2 var lx2 = {#datx2#}; var ly2 = {#daty2#}; var i = 0; for (i = 0; i <= lx2.length - 1; i++) { p[i] = board.create('point', [lx2[i], ly2[i]], { face: 'x', name: '', size: 2, fixed:true }); } \/\/Create Label for Data 2 var txt = board.create('text', [{#xmin#}+1, {#maxfreq2+maxfreq3+maxfreq4+3*ver_diff-3#}, \"D2\"], { fontSize: 20,fixed: true }); \/\/Create points of Data Set 1 var lx1 = {#datx1#}; var ly1 = {#daty1#}; var i = 0; for (i = 0; i <= lx1.length - 1; i++) { p[i] = board.create('point', [lx1[i], ly1[i]], { face: 'x', name: '', size: 2, fixed:true }); } \/\/Create Label for Data 1 var txt = board.create('text', [{#xmin#}+1, {#maxfreq1+maxfreq2+maxfreq3+maxfreq4+4*ver_diff-3#}, \"D1\"], { fontSize: 20,fixed: true }); [[\/jsxgraph]]<\/p> <p>Box Plots:<\/p> <p> [[jsxgraph]] \/\/ Create board var board = JXG.JSXGraph.initBoard(divid, { boundingbox: [{#xmin#}, 10, {#xmax#}, -1], keepaspectratio: false, showCopyright: false, axis:true, pan:{enabled:false} }); \/\/Create variables for graph 1 var min1 ={#info1[1]#}; var lq1 = {#info1[2]#}; var med1 = {#info1[3]#}; var uq1 = {#info1[4]#}; var max1 = {#info1[5]#}; \/\/Create graph 1 var d11 = board.create('line', [[min1, 7],[min1, 8]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d12 = board.create('line', [[max1, 7],[max1, 8]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d13 = board.create('line', [[med1, 7],[med1, 8]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d14 = board.create('line', [[lq1, 7],[lq1, 8]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d15 = board.create('line', [[uq1, 7],[uq1, 8]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d16 = board.create('line', [[uq1, 7],[lq1, 7]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d17 = board.create('line', [[uq1, 8],[lq1, 8]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d18 = board.create('line', [[min1, 7.5],[lq1, 7.5]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d19 = board.create('line', [[max1, 7.5],[uq1, 7.5]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); \/\/Create Label for graph 1 var txt = board.create('text', [{#xmin#}+0.5, 8, \"A\"], { fontSize: 20,fixed: true }); \/\/Create variables for graph 2 var min2 ={#info2[1]#}; var lq2 = {#info2[2]#}; var med2 = {#info2[3]#}; var uq2 = {#info2[4]#}; var max2 = {#info2[5]#}; \/\/Create graph 2 var d21 = board.create('line', [[min2, 5],[min2, 6]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d22 = board.create('line', [[max2, 5],[max2, 6]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d23 = board.create('line', [[med2, 5],[med2, 6]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d24 = board.create('line', [[lq2, 5],[lq2, 6]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d25 = board.create('line', [[uq2, 5],[uq2, 6]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d26 = board.create('line', [[uq2, 5],[lq2, 5]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d27 = board.create('line', [[uq2, 6],[lq2, 6]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d28 = board.create('line', [[min2, 5.5],[lq2, 5.5]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d29 = board.create('line', [[max2, 5.5],[uq2, 5.5]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); \/\/Create Label for graph 2 var txt = board.create('text', [{#xmin#}+0.5, 6, \"B\"], { fontSize: 20,fixed: true }); \/\/Create variables for graph 3 var min3 ={#info3[1]#}; var lq3 = {#info3[2]#}; var med3 = {#info3[3]#}; var uq3 = {#info3[4]#}; var max3 = {#info3[5]#}; \/\/Create graph 3 var d31 = board.create('line', [[min3, 3],[min3, 4]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d32 = board.create('line', [[max3, 3],[max3, 4]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d33 = board.create('line', [[med3, 3],[med3, 4]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d34 = board.create('line', [[lq3, 3],[lq3, 4]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d35 = board.create('line', [[uq3, 3],[uq3, 4]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d36 = board.create('line', [[uq3, 3],[lq3, 3]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d37 = board.create('line', [[uq3, 4],[lq3, 4]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d38 = board.create('line', [[min3, 3.5],[lq3, 3.5]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d39 = board.create('line', [[max3, 3.5],[uq3, 3.5]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); \/\/Create Label for graph 3 var txt = board.create('text', [{#xmin#}+0.5, 4, \"C\"], { fontSize: 20,fixed: true }); \/\/Create variables for graph 4 var min4 ={#info4[1]#}; var lq4 = {#info4[2]#}; var med4 = {#info4[3]#}; var uq4 = {#info4[4]#}; var max4 = {#info4[5]#}; \/\/Create graph 4 var d41 = board.create('line', [[min4, 1],[min4, 2]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d42 = board.create('line', [[max4, 1],[max4, 2]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d43 = board.create('line', [[med4, 1],[med4, 2]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d44 = board.create('line', [[lq4, 1],[lq4, 2]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d45 = board.create('line', [[uq4, 1],[uq4, 2]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d46 = board.create('line', [[uq4, 1],[lq4, 1]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d47 = board.create('line', [[uq4, 2],[lq4, 2]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d48 = board.create('line', [[min4, 1.5],[lq4, 1.5]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); var d49 = board.create('line', [[max4, 1.5],[uq4, 1.5]], {straightFirst: false,straightLast: false,strokeWidth: 2,fixed:true}); \/\/Create Label for graph 4 var txt = board.create('text', [{#xmin#}+0.5, 2, \"D\"], { fontSize: 20,fixed: true }); [[\/jsxgraph]] <\/p> <p>Enter the relevant letter for each Stacked Dot Plot:<\/p> <p>\\(D1\\) matches with: [[input:ans1]] [[validation:ans1]] [[feedback:prt1]]<\/p> <p>\\(D2\\) matches with: [[input:ans2]] [[validation:ans2]] [[feedback:prt2]]<\/p> <p>\\(D3\\) matches with: [[input:ans3]] [[validation:ans3]] [[feedback:prt3]]<\/p> <p>\\(D4\\) matches with: [[input:ans4]] [[validation:ans4]] [[feedback:prt4]]<\/p>    <p>Remember how a boxplot is defined.<\/p> <p>The middle of the box is the median line. Half the data are above the median and half are below. Looking at the dotplots we see that some of the distributions are skewed, so the median point is very low or very high. Others are more symmetric, so the boxplot will also be more symmetric.<\/p> <p>Where are the 25% (lower quartile) and 75% (upper quartile) points? Then match these to the boxplots.<\/p> <p>One of the datasets looks \"bimodal\" meaning it has two \"peaks\". How does a boxplot of bimodal data look different from a boxplot of a normally distributed data set?<\/p>   1  0.1  0    2023060500    dat_min: rand(101)+100; dat_max: dat_min+30+rand(21); n: rand(41)+60; bin_width: floor((dat_max-dat_min)\/30); ver_diff: 2; \/* dat1: normal *\/ dat1: makelist(float(quantile_normal(rand(1.0),0,1)),i,1,n); dat1: ((dat1-lmin(dat1))\/(lmax(dat1)-lmin(dat1)))*(dat_max-dat_min)+dat_min; dat1: sort(dat1); dat1: round(dat1); datx1:makelist(1,i,1,n); for i:1 thru n do datx1[i]:bin_width*floor(dat1[i]\/bin_width)+bin_width\/2; \/* info of normal for box plot: [min,lq,med,uq,max] *\/ min1:datx1[1]; lq1:quantile (datx1,1\/4),numer; med1:median(datx1); uq1:quantile (datx1, 3\/4),numer; max1:datx1[n]; info1:[min1,lq1,med1,uq1,max1]; \/* dat2: bimodal (from two disjoint normals) *\/ dat21: makelist(float(quantile_normal(rand(1.0),0,1)),i,1,floor(n\/2)); dat22: makelist(float(quantile_normal(rand(1.0),4,1)),i,1,ceiling(n\/2)); dat2: append(dat21,dat22); dat2: ((dat2-lmin(dat2))\/(lmax(dat2)-lmin(dat2)))*(dat_max-dat_min)+dat_min; dat2: sort(dat2); dat2: round(dat2); datx2:makelist(1,i,1,n); for i:1 thru n do datx2[i]:bin_width*floor(dat2[i]\/bin_width)+bin_width\/2; \/* info of bimodal for box plot: [min,lq,med,uq,max] *\/ min2:datx2[1]; lq2:quantile (datx2,1\/4),numer; med2:median(datx2); uq2:quantile (datx2, 3\/4),numer; max2:datx2[n]; info2:[min2,lq2,med2,uq2,max2]; \/* dat3: gamma right skewed *\/ dat3: makelist(float(quantile_gamma(rand(1.0),2,20)),i,1,n); dat3: ((dat3-lmin(dat3))\/(lmax(dat3)-lmin(dat3)))*(dat_max-dat_min)+dat_min; dat3: sort(dat3); dat3: round(dat3); datx3:makelist(1,i,1,n); for i:1 thru n do datx3[i]:bin_width*floor(dat3[i]\/bin_width)+bin_width\/2; \/* info of right skew for box plot: [min,lq,med,uq,max] *\/ min3:datx3[1]; lq3:quantile (datx3,1\/4),numer; med3:median(datx3); uq3:quantile (datx3, 3\/4),numer; max3:datx3[n]; info3:[min3,lq3,med3,uq3,max3]; \/* dat4: gamma left skewed *\/ dat4: makelist(float(quantile_gamma(rand(1.0),2,20)),i,1,n); dat4: lmax(dat4)-lmin(dat4)+2-dat4; dat4: ((dat4-lmin(dat4))\/(lmax(dat4)-lmin(dat4)))*(dat_max-dat_min)+dat_min; dat4: sort(dat4); dat4: round(dat4); datx4:makelist(1,i,1,n); for i:1 thru n do datx4[i]:bin_width*floor(dat4[i]\/bin_width)+bin_width\/2; \/* info of left skew for box plot: [min,lq,med,uq,max] *\/ min4:datx4[1]; lq4:quantile (datx4,1\/4),numer; med4:median(datx4); uq4:quantile (datx4, 3\/4),numer; max4:datx4[n]; info4:[min4,lq4,med4,uq4,max4]; \/* Randomising the order of the graphs *\/ dumlist1:[1,2,3,4]; randdumlist1:random_permutation(dumlist1); datasetslist:[datx1,datx2,datx3,datx4]; datx1:datasetslist[randdumlist1[1]]; datx2:datasetslist[randdumlist1[2]]; datx3:datasetslist[randdumlist1[3]]; datx4:datasetslist[randdumlist1[4]]; \/* version number for each graph *\/ normalans1:if randdumlist1[1] = 1 then 1 elseif randdumlist1[2]=1 then 2 elseif randdumlist1[3]=1 then 3 else 4; bimodalans1:if randdumlist1[1] = 2 then 1 elseif randdumlist1[2]=2 then 2 elseif randdumlist1[3]=2 then 3 else 4; rightskewans1:if randdumlist1[1] = 3 then 1 elseif randdumlist1[2]=3 then 2 elseif randdumlist1[3]=3 then 3 else 4; leftskewans1:if randdumlist1[1] = 4 then 1 elseif randdumlist1[2]=4 then 2 elseif randdumlist1[3]=4 then 3 else 4; \/* Randomising the order of the graphs *\/ dumlist2:[1,2,3,4]; randdumlist2:random_permutation(dumlist2); infolist:[info1,info2,info3,info4]; info1:infolist[randdumlist2[1]]; info2:infolist[randdumlist2[2]]; info3:infolist[randdumlist2[3]]; info4:infolist[randdumlist2[4]]; \/* version number for each graph *\/ normalans2:if randdumlist2[1] = 1 then 1 elseif randdumlist2[2]=1 then 2 elseif randdumlist2[3]=1 then 3 else 4; bimodalans2:if randdumlist2[1] = 2 then 1 elseif randdumlist2[2]=2 then 2 elseif randdumlist2[3]=2 then 3 else 4; rightskewans2:if randdumlist2[1] = 3 then 1 elseif randdumlist2[2]=3 then 2 elseif randdumlist2[3]=3 then 3 else 4; leftskewans2:if randdumlist2[1] = 4 then 1 elseif randdumlist2[2]=4 then 2 elseif randdumlist2[3]=4 then 3 else 4; \/* Calculate the maximun frequency of each data set *\/ maxfreq1:0; k:1; for i:2 thru n do if datx1[i]=datx1[i-1] then (k:k+1, if maxfreq1 < k then maxfreq1:k) else k:1; maxfreq2:0; k:1; for i:2 thru n do if datx2[i]=datx2[i-1] then (k:k+1, if maxfreq2 < k then maxfreq2:k) else k:1; maxfreq3:0; k:1; for i:2 thru n do if datx3[i]=datx3[i-1] then (k:k+1, if maxfreq3 < k then maxfreq3:k) else k:1; maxfreq4:0; k:1; for i:2 thru n do if datx4[i]=datx4[i-1] then (k:k+1, if maxfreq4 < k then maxfreq4:k) else k:1; \/* Begin generating stacked dot plots *\/ xmin:dat_min-2; xmax:dat_max+2; ymin:-4; ymax: maxfreq1+maxfreq2+maxfreq3+maxfreq4+3*ver_diff+1; \/* Generate y-values for each data set to plot the stacked dots *\/ j:1; daty1:makelist(0,i,1,n); daty1[1]:1+maxfreq2+maxfreq3+maxfreq4+3*ver_diff; for i:2 thru n do if datx1[i]=datx1[i-1] then (j:j+1, daty1[i]:j+maxfreq2+maxfreq3+maxfreq4+3*ver_diff) else (j:1, daty1[i]:j+maxfreq2+maxfreq3+maxfreq4+3*ver_diff); j:1; daty2:makelist(0,i,1,n); daty2[1]:1+maxfreq3+maxfreq4+2*ver_diff; for i:2 thru n do if datx2[i]=datx2[i-1] then (j:j+1, daty2[i]:j+maxfreq3+maxfreq4+2*ver_diff) else (j:1, daty2[i]:j+maxfreq3+maxfreq4+2*ver_diff); j:1; daty3:makelist(0,i,1,n); daty3[1]:1+maxfreq4+ver_diff; for i:2 thru n do if datx3[i]=datx3[i-1] then (j:j+1, daty3[i]:j+maxfreq4+ver_diff) else (j:1, daty3[i]:j+maxfreq4+ver_diff); j:1; daty4:makelist(0,i,1,n); daty4[1]:1; for i:2 thru n do if datx4[i]=datx4[i-1] then (j:j+1, daty4[i]:j) else (j:1, daty4[i]:j); \/* End generating stacked dot plots *\/ ta1_c:if randdumlist1[1]=randdumlist2[1] then \"A\" elseif randdumlist1[1]=randdumlist2[2] then \"B\" elseif randdumlist1[1]=randdumlist2[3] then \"C\" else \"D\"; ta1:[[\"A\",is(ta1_c=\"A\"), \"Boxplot A\"],[\"B\",is(ta1_c=\"B\"), \"Boxplot B\"],[\"C\",is(ta1_c=\"C\"), \"Boxplot C\"],[\"D\",is(ta1_c=\"D\"), \"Boxplot D\"]]; ta2_c:if randdumlist1[2]=randdumlist2[1] then \"A\" elseif randdumlist1[2]=randdumlist2[2] then \"B\" elseif randdumlist1[2]=randdumlist2[3] then \"C\" else \"D\"; ta2:[[\"A\",is(ta2_c=\"A\"), \"Boxplot A\"],[\"B\",is(ta2_c=\"B\"), \"Boxplot B\"],[\"C\",is(ta2_c=\"C\"), \"Boxplot C\"],[\"D\",is(ta2_c=\"D\"), \"Boxplot D\"]]; ta3_c:if randdumlist1[3]=randdumlist2[1] then \"A\" elseif randdumlist1[3]=randdumlist2[2] then \"B\" elseif randdumlist1[3]=randdumlist2[3] then \"C\" else \"D\"; ta3:[[\"A\",is(ta3_c=\"A\"), \"Boxplot A\"],[\"B\",is(ta3_c=\"B\"), \"Boxplot B\"],[\"C\",is(ta3_c=\"C\"), \"Boxplot C\"],[\"D\",is(ta3_c=\"D\"), \"Boxplot D\"]]; ta4_c:if randdumlist1[4]=randdumlist2[1] then \"A\" elseif randdumlist1[4]=randdumlist2[2] then \"B\" elseif randdumlist1[4]=randdumlist2[3] then \"C\" else \"D\"; ta4:[[\"A\",is(ta4_c=\"A\"), \"Boxplot A\"],[\"B\",is(ta4_c=\"B\"), \"Boxplot B\"],[\"C\",is(ta4_c=\"C\"), \"Boxplot C\"],[\"D\",is(ta4_c=\"D\"), \"Boxplot D\"]]       <p>Data size = {@n@}. Answer list: {@[ta1_c,ta2_c,ta3_c,ta4_c]@}<\/p>      1  0  0   <p>Correct answer, well done.<\/p>    <p>Your answer is partially correct.<\/p>    <p>Incorrect answer.<\/p>   .  *10  dot  1  i  cos-1  lang  [  0    ans1  dropdown  ta1  15  1  0   0    1  0  0  0  0     ans2  dropdown  ta2  15  1  0   0    1  0  0  0  0     ans3  dropdown  ta3  15  1  0   0    1  0  0  0  0     ans4  dropdown  ta4  15  1  0   0    1  0  0  0  0     prt1  1.0000000  1  1      0   AlgEquiv  ans1  ta1_c   0  =  1   -1  prt1-1-T     =  0   -1  prt1-1-F        prt2  1.0000000  1  1      0   AlgEquiv  ans2  ta2_c   0  =  1   -1  prt2-1-T     =  0   -1  prt2-1-F        prt3  1.0000000  1  1      0   AlgEquiv  ans3  ta3_c   0  =  1   -1  prt3-1-T     =  0   -1  prt3-1-F        prt4  1.0000000  1  1      0   AlgEquiv  ans4  ta4_c   0  =  1   -1  prt4-1-T     =  0   -1  prt4-1-F       1801006757  768252992  1901898753  1925301602  1316343442  2109495421  1543454398  140518220  1665582679  1030164503  425942596  451148150  1369728296  374485637  1776053810  847030446  271459631  1522679322  1388158991  57289455  553761874  2006693680  335428334  1807555479  336215593  1038662071  2050421240  854347360  616343465  1496310453  819154543  493731052  1451165897  1036523842  471844676  528939971  3402304  1106143636  1576038739  1619350419  1149313236  300087478  1279523893  1539829830  830626927  1041797952  740558512  1062067506  1801148755  1403585311  1909028018  1235618568  1300948314  1667452766  173301734  56555878  440003830  576180509  1952330545  219751550  1478334696  81902505  102107907  1141627915  1728031519  769958447  1657940095  483317018  1327974645  1588417208  1152955789  55023231  1319737195  1012899027  678812362  1651285347  724032048  1334280520  735003663  1445763220  1556214072  1041586978  466667189  1559231113  2116649457  931173427  1401011273  418278936  999781913  350490041  1270066446  1011255394  1970947858  1959094721  1799029378  400906966  1224324728  1647864254  1271249744  1889491786   1  Test case assuming the teacher's input gets full marks.   ans1  first(mcq_correct(ta1))    ans2  first(mcq_correct(ta2))    ans3  first(mcq_correct(ta3))    ans4  first(mcq_correct(ta4))    prt1  1.0000000  0.0000000  prt1-1-T    prt2  1.0000000  0.0000000  prt2-1-T    prt3  1.0000000  0.0000000  prt3-1-T    prt4  1.0000000  0.0000000  prt4-1-T       "
},
{
  "id": "sec-applied-comprehension",
  "level": "1",
  "url": "sec-applied-comprehension.html",
  "type": "Section",
  "number": "1.2",
  "title": "Applied Comprehension",
  "body": " Applied Comprehension    Estimate standard deviation        Estimate standard deviation    <p>The following diagram shows the height in cm of {@ds1@} adults in a village.<\/p> <p> [[jsxgraph]] \/\/ Create empty list of points var p = []; \/\/ Create board var board = JXG.JSXGraph.initBoard(divid, { boundingbox: [{#xmin#}, {#ymax#}, {#xmax#}, {#ymin#}], keepaspectratio: false, showCopyright: false, axis:true, pan:{enabled:false} }); \/\/Create points of Data Set 1 var lx1 = {#dorx1#}; var ly1 = {#dory#}; var i = 0; for (i = 0; i <= lx1.length - 1; i++) { p[i] = board.create('point', [lx1[i], ly1[i]], { face: 'x', name: '', size: 2, fixed:true }); } [[\/jsxgraph]] <\/p> <p>Estimate the standard deviation of heights [[input:ans1]]cm [[validation:ans1]]<\/p>    Use the following as a guide. An interval that is 2s wide usually covers about the middle two thirds of the crosses (i.e. x̅ ± s). An interval that is 4s wide usually covers about the middle 95% of the crosses (i.e. x̅ ± 2s). The range of the data is usually between 5s and 6s (i.e. x̅ ± 2.5s to x̅ ± 3s). In this case the mean is about {@mean_real@} and you should be able to estimate the standard deviation close to the real value of {@mr1@}. <p>Click here to learn more on how estimate standard deviation <a href=\"https:\/\/ecampus.idems.international\/mod\/resource\/view.php?id=13393\" download=\"\">\"Estimating Standard deviation\".<\/a><\/p><p><\/p>   1  0.1  0    2025073100    mean1:rand(101)+100; aa:rand([-1,0,1]); sd1:rand(5)+5; bb:rand([1\/3,1\/2,1,2,3]); ds1:rand(41)+60; dun1:makelist(round(float(quantile_normal(rand(1.0),mean1,sd1))),i,1,ds1); dorx1:sort(dun1); m1:float(std(dorx1)); mr1:dispdp(m1,1); mean_real: round(mean(dorx1)); maxfreq1:0; k:1; for i:2 thru ds1 do if dorx1[i]=dorx1[i-1] then (k:k+1, if maxfreq1 < k then maxfreq1:k) else k:1; xmin:dorx1[1]-2; xmax:dorx1[ds1]+2+(dorx1[ds1]-dorx1[1])\/1.5; ymin:-2; ymax:if maxfreq1+2<15 then 15 else maxfreq1+2; j:1; dory:makelist(0,i,1,ds1); dory[1]:1; for i:2 thru ds1 do if dorx1[i]=dorx1[i-1] then (j:j+1, dory[i]:j) else (j:1, dory[i]:j);    [[feedback:prt1]]    mean = {@mean1@} sd = {@sd1@}      1  0  0   <span style=\"font-size: 1.5em; color:green;\"><i class=\"fa fa-check\"><\/i><\/span> Correct answer, well done.    <span style=\"font-size: 1.5em; color:orange;\"><i class=\"fa fa-adjust\"><\/i><\/span> Your answer is partially correct.    <span style=\"font-size: 1.5em; color:red;\"><i class=\"fa fa-times\"><\/i><\/span> Incorrect answer.   .  *10  dot  1  i  cos-1  lang  [  0    ans1  numerical  mr1  8  1  0   0    0  0  0  0  0     prt1  1.0000000  1  1      0   NumRelative  ans1  m1  0.1  0  =  1   -1  prt1-1-T   Well done you are within 10% of the actual standard deviation!   =  0  0.1  1  prt1-1-F       1   NumRelative  ans1  m1  0.25  0  +  0.5   -1  prt1-2-T   Well done that is quite close! You are within 25% of the actual standard deviation. With practice you should be able to estimate to within 10% of the standard deviation, why don't you have another go.   -  0   -1  prt1-2-F   Not close enough! You should be able to estimate to within 25% of the standard deviation, why don't you have another go.     750076029  446160850  1892374070  2038073284  1263306952  1834225363  71100161  150651908  208727463  1872513520  922251234  1521000575  1146896948  1418421722  1852836895  1692796730  755010582  1263532427  801291460  643940405   1    ans1  mr1    prt1  1.0000000  0.0000000  prt1-1-T         Place the estimated value of mean and median in stacked dotplot        Place the estimated value of mean and median in stacked dotplot    <p>The precipitation in {@ds1@} Eastern African cities in August was measured and the results were grouped in intervals of 6mm. The results are displayed in the graph below. Estimate 'by eye' the values of the mean and median precipitation. Give your answer by dragging the two vertical lines corresponding to the mean and median to the estimated position.<\/p> <p> [[jsxgraph input-ref-ans1=\"sR1\" input-ref-ans2=\"sR2\" input-ref-ans3=\"sR3\" input-ref-ans4=\"sR4\"]] JXG.Options.text.useMathJax = true; \/\/ Create empty list of points var p = []; \/\/ Create board var board = JXG.JSXGraph.initBoard(divid, { boundingbox: [{#xmin#}, {#ymax#}, {#xmax#}, {#ymin#}], keepaspectratio: false, showCopyright: false, axis:true, pan:{enabled:false} }); \/\/ Create points for the Data Set var lx1 = {#dorx1#}; var ly1 = {#dory#}; var i = 0; for (i = 0; i <= lx1.length - 1; i++) { p[i] = board.create('point', [lx1[i], ly1[i]], { face: 'x', name: '', size: 2, fixed:true }); } \/\/ Create hidden point for the mean var qm1 = board.create('point', [5,0], { name: \"C\", size: 2, visible: false }); \/\/ Line for the mean var qm11 = board.create('point', [5,5], { name: \"C\", size: 2, visible: false }); var m1 = board.create('line', [qm1, qm11], { straightFirst: true, straightLast: true, strokeWidth: 2, strokeColor: '#21a34c' }); var lblm1 = board.create('text', [function() {return qm1.X()+1},{#ymax-1#},'mean'], { fontSize: 15, color: '#21a34c' }); \/\/ Create hidden point for the median var qm2 = board.create('point', [{#xmax#}-20,0], { name: \"C\", size: 2, visible: false }); \/\/ Line for the median var qm21 = board.create('point', [{#xmax#}-20,5], { name: \"C\", size: 2, visible: false }); var m2 = board.create('line', [qm2,qm21], { straightFirst: true, straightLast: true, strokeWidth: 2, strokeColor: '#901B77' }); var lblm2 = board.create('text', [function() {return qm2.X()+1},{#ymax-2#},'median'], { fontSize: 15, color: '#901B77' }); \/* Set answers from state of graph *\/ stack_jxg.bind_point(sR1,qm1); stack_jxg.bind_point(sR3,qm11); stack_jxg.bind_point(sR2,qm2); stack_jxg.bind_point(sR4,qm21); board.unsuspendUpdate(); [[\/jsxgraph]] <\/p> <p>[[feedback:prt3]]<\/p> <p style=\"display:none;\">[[input:ans1]] [[validation:ans1]] <\/p> <p>[[feedback:prt1]]<\/p> <p style=\"display:none;\">[[input:ans2]] [[validation:ans2]]<\/p> <p style=\"display:none;\">[[input:ans3]] [[validation:ans3]]<\/p> <p style=\"display:none;\">[[input:ans4]] [[validation:ans4]]<\/p> <p>[[feedback:prt2]]<\/p>      1  0.1  0    2025073100    \/* Parameters for the distribution *\/ mean1:rand(30)+30; sd1:(rand(0.3)+0.5)*mean1; ds1:rand(50)+50; bb:(sd1^2\/mean1); aa:(mean1^2\/sd1^2); \/* Create the data using with a left skew *\/ dunx:makelist(round(float(quantile_gamma(rand(1.0),aa,bb))),i,1,ds1); dorx:sort(dunx); \/* Group data on intervals of length 6 *\/ dorx1:makelist(1,i,1,ds1); for i:1 thru ds1 do dorx1[i]:6*floor(dorx[i]\/6)+3; \/* Calculate the actual mean of the grouped data *\/ m1:float(mean(dorx1)); mr1:round(m1) \/* Calculate the actual median of the grouped data *\/ m2:float(median(dorx1)); mr2:round(m2) \/* Finding bounds for the graph *\/ \/* Calculating the maximum frequency to determine the max y-value *\/ maxfreq1:0; k:1; for i:2 thru ds1 do if dorx1[i]=dorx1[i-1] then (k:k+1, if maxfreq1 < k then maxfreq1:k) else k:1; \/* Define max y-value. Set it to a minimum of 20 so that points are not squashed together *\/ ymax:if maxfreq1+2<20 then 20 else maxfreq1+2; \/* Define the min y-value and the max and min x-values *\/ xmax:dorx1[ds1]+2;\/*+(dorx[ds1]-dorx[1])\/1.5 can be added to create empty space on the right to make it visible on mobile phones *\/ xmin:if dorx1[1]-10<0 then dorx1[1]-10 else -10; ymin:-2; \/* Find the y-coordinate for each point *\/ j:1; dory:makelist(0,i,1,ds1); dory[1]:1; for i:2 thru ds1 do if dorx1[i]=dorx1[i-1] then (j:j+1, dory[i]:j) else (j:1, dory[i]:j);       <p>Mean = \"rand(30)+30\" = {@mean1@}, SD = \"(rand(0.3)+0.5)*Mean\" = {@sd1@}<\/p> <p>Data Size = \"rand(50)+50\" = {@ds1@}<\/p> <p>Gamma Parameters [a,b] = [{@aa@},{@bb@}]<\/p>      1  0  0   <span style=\"font-size: 1.5em; color:green;\"><i class=\"fa fa-check\"><\/i><\/span> Correct answer, well done.    <span style=\"font-size: 1.5em; color:orange;\"><i class=\"fa fa-adjust\"><\/i><\/span> Your answer is partially correct.    <span style=\"font-size: 1.5em; color:red;\"><i class=\"fa fa-times\"><\/i><\/span> Incorrect answer.   .  *10  dot  1  i  cos-1  lang  [  0    ans1  algebraic  [m1, 1]  15  1  0   0    0  0  0  0  0     ans2  algebraic  [m2, 1]  15  1  0   0    0  0  0  0  0     ans3  algebraic  [m1, 2]  15  1  0   0    0  0  0  0  0     ans4  algebraic  [m2, 2]  15  1  0   0    0  0  0  0  0     prt1  1.0000000  1  1      0   NumRelative  ans1[1]  m1  0.1  0  =  1   -1  prt1-1-T   Your answer for the mean is close enough. The actual value is {@mr1@} mm.   =  0   1  prt1-1-F       1   NumRelative  ans1[1]  m1  0.2  0  +  0.5   -1  prt1-2-T   Your answer for the mean is almost close enough. The actual value is {@mr1@} mm, with practice you should be able to estimate the mean to within 10%.   -  0   -1  prt1-2-F   You are a bit too far from the actual mean value of {@mr1@} mm. Your estimate of the mean is more than 20% away, with practice you should be able to do better.      prt2  1.0000000  1  1      0   NumRelative  ans2[1]  m2  0.1  0  =  1   -1  prt2-1-T   Your answer for the median is close enough. The actual value is {@mr2@} mm.   =  0   1  prt2-1-F       1   NumRelative  ans2[1]  m2  0.2  0  +  0.5   -1  prt2-2-T   Your answer for the medain is almost close enough. The actual value is {@mr2@} mm, with practice you should be able to estimate the median to within 10%.   -  0   -1  prt2-2-F   You are a bit too far from the actual median value of {@mr2@} mm. Your estimate of the median is more than 20% away, with practice you should be able to do better.      prt3  1.0000000  1  1   correct_rel_pos:if m1>m2 then (if ans1[1]>ans2[1] then 1 else 0) else (if ans1[1]<ans2[1] then 1 else 0);    0   AlgEquiv  correct_rel_pos  1   0  =  1   -1  prt3-1-T   <p>Well done you have correctly reflected the skewness in the data by your relative positioning of the mean and median. A quick reminder is that outliers affect the mean but not the median.<\/p>   =  0   -1  prt3-1-F   <p>Your relative positioning of the mean and median do not reflect the skewness in the data. Remember that outliers affect the mean but not the median, hence with skew data the mean is 'pulled' out towards the extreme values while the median is not affected by individual extreme values.<\/p>     1180180573  897215019  1947941280  231250545  1127514141  1588005898  254115884  46394728  1922285942  1774773390  135245803  1762319639  258514681  133230507  76854659  1705835802  544875161  21686271  1529701231  1971182280   1  Test case assuming the teacher's input gets full marks.   ans1  [m1, 1]    ans2  [m2, 1]    ans3  [m1, 2]    ans4  [m2, 2]    prt1  1.0000000  0.0000000  prt1-1-T    prt2  1.0000000  0.0000000  prt2-1-T    prt3  1.0000000  0.0000000  prt3-1-T     <\n>  <\n>  <\n>  <\n>        Model Comparison        Model Comparison    <p>This question is based on research by Dr. Francis Torgbor in his MPhil Thesis.<\/p> <p>The thesis looks to create a useful guide in preparation of the effect of rainfall patterns in Ghana. Understanding and modelling rainfall patterns is important. To understand and model the patterns, we need to account for the variability - there is a large variability in rainfall, and this variability can have serious implications on various aspects such as food production and livelihoods. In an attempt to attain a model that describes the pattern for the chance of rain, multiple models were found and then compared to find the “best” model. We will look at two of these models, and call them Model A and Model B.<\/p> <p>The difference between Model A and B is about whether interactions should be included. That is, in Model B, the Markov component corresponding to the dependence of the rainfall on previous days interacts with the seasonality. In Model A, there is no interaction.<\/p> <p>This illustrative scenario compares the performance of Model A with Model B.<\/p> <p>An Analysis of Deviance table can be performed to look at the fit of generalised linear models (GLMs). In brief, deviance is a measure of the difference between the actual values and the fitted model. Like in an ANOVA, an Analysis of Deviance gives a residual deviance - this is the variability that is not accounted for in the model. Therefore, a smaller residual deviance is preferable when fitting a model.<\/p> <br> <table> <tbody><tr> <td width=\"180px\" style=\"padding:5px\"><b>Model A:<\/b><\/td> <td width=\"100px\"><\/td> <td width=\"100px\"><\/td> <td width=\"50px\"><\/td> <td width=\"180px\" style=\"padding:5px\"><b>Model B:<\/b><\/td> <td width=\"100px\"><\/td> <td width=\"100px\"><\/td> <\/tr> <tr> <td style=\"border: 1px solid black; border-collapse: collapse; padding:5px\"><b>Source of Deviation<\/b><\/td> <td style=\"border: 1px solid black; border-collapse: collapse; padding:5px\"><b>DF<\/b><\/td> <td style=\"border: 1px solid black; border-collapse: collapse; padding:5px\"><b>Deviance<\/b><\/td> <td><\/td> <td style=\"border: 1px solid black; border-collapse: collapse; padding:5px\"><b>Source of Deviation<\/b><\/td> <td style=\"border: 1px solid black; border-collapse: collapse; padding:5px\"><b>DF<\/b><\/td> <td style=\"border: 1px solid black; border-collapse: collapse; padding:5px\"><b>Deviance<\/b><\/td> <\/tr> <tr> <td style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">Accounted for<\/td> <td style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">{@modA_df_accounted@}<\/td> <td style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">{@modA_dev_accounted@}<\/td> <td><\/td> <td style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">Accounted for<\/td> <td style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">{@modB_df_accounted@}<\/td> <td style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">{@modB_dev_accounted@}<\/td> <\/tr> <tr> <td style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">Residual<\/td> <td style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">{@modA_df_residual@}<\/td> <td style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">{@modA_dev_residual@}<\/td> <td><\/td> <td style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">Residual<\/td> <td style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">{@modB_df_residual@}<\/td> <td style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">{@modB_dev_residual@}<\/td> <\/tr> <tr> <td style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">Total<\/td> <td style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">{@modA_df_total@}<\/td> <td style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">{@modA_dev_total@}<\/td> <td><\/td> <td style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">Total<\/td> <td style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">{@modB_df_total@}<\/td> <td style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">{@modB_dev_total@}<\/td> <\/tr> <\/tbody><\/table> <br> <p>1. Which is the correct model?<\/p> <p>[[input:ans1]] [[validation:ans1]]<\/p> <p>[[feedback:prt1]]<\/p> <br> <p>2. Given the information you have, which model accounts for more variability out of A and B?<\/p> <p>[[input:ans2]] [[validation:ans2]]<\/p> <p>[[feedback:prt2]]<\/p> <br> <p>3. We now use the Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC) to compare these models. In both cases, a model with a lower AIC or BIC value is said to perform better.<\/p> <table> <tbody><tr> <td width=\"100px\" style=\"border: 1px solid black; border-collapse: collapse; padding:5px\"><b>Model<\/b><\/td> <td width=\"100px\" style=\"border: 1px solid black; border-collapse: collapse; padding:5px\"><b>Parameters<\/b><\/td> <td width=\"100px\" style=\"border: 1px solid black; border-collapse: collapse; padding:5px\"><b>AIC<\/b><\/td> <td width=\"100px\" style=\"border: 1px solid black; border-collapse: collapse; padding:5px\"><b>BIC<\/b><\/td> <\/tr> <tr> <td width=\"100px\" style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">A<\/td> <td width=\"100px\" style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">{@modA_param@}<\/td> <td width=\"100px\" style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">{@modA_AIC@}<\/td> <td width=\"100px\" style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">{@modA_BIC@}<\/td> <\/tr> <tr> <td width=\"100px\" style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">B<\/td> <td width=\"100px\" style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">{@modB_param@}<\/td> <td width=\"100px\" style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">{@modB_AIC@}<\/td> <td width=\"100px\" style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">{@modB_BIC@}<\/td> <\/tr> <\/tbody><\/table> <br> <p>Which model performs better out of A and B?<\/p> <p>[[input:ans3]] [[validation:ans3]]<\/p> <p>[[feedback:prt3]]<\/p>      1  0.1  0    2025073100    modA_df_accounted: 7; modA_dev_accounted: 3417; modA_df_residual: 16771; modA_dev_residual: 13015; modA_df_total: modA_df_accounted+modA_df_residual; modA_dev_total: modA_dev_accounted+modA_dev_residual; modB_df_accounted: 19; modB_dev_accounted: 3521; modB_df_residual: 16759; modB_dev_residual: 12911; modB_df_total: modB_df_accounted+modB_df_residual; modB_dev_total: modB_dev_accounted+modB_dev_residual; modA_param: 8; modA_AIC: 13031; modA_BIC: 13092; modB_param: 20; modB_AIC: 12951; modB_BIC: 13106; m_ans1: [ [\"A\", false], [\"B\", false], [\"Neither\", true] ]; m_ans2: [ [\"A\", false], [\"B\", true], [\"It depends\", false] ]; m_ans3: [ [\"A\", false], [\"B\", false], [\"It depends\", true] ];          <p id=\"author\">Dan Kelly<\/p> <p id=\"concept\">https:\/\/docs.google.com\/document\/d\/1SCVlmN0RPhDBou73SBHXyo6eZdo0PWDsFmgj1H2Jly8\/edit<\/p> <p id=\"reviewer\"><\/p> <p id=\"description\"><\/p>   1  0  0   <span style=\"font-size: 1.5em; color:green;\"><i class=\"fa fa-check\"><\/i><\/span> Correct answer, well done.    <span style=\"font-size: 1.5em; color:orange;\"><i class=\"fa fa-adjust\"><\/i><\/span> Your answer is partially correct.    <span style=\"font-size: 1.5em; color:red;\"><i class=\"fa fa-times\"><\/i><\/span> Incorrect answer.   .  *10  none  1  i  cos-1  lang  [  0    ans1  dropdown  m_ans1  15  1  0   0    1  0  0  0  0     ans2  dropdown  m_ans2  15  1  0   0    1  0  0  0  0     ans3  dropdown  m_ans3  15  1  0   0    1  0  0  0  0     prt1  1.0000000  1  1      0  check correct answer  AlgEquiv  ans1  \"Neither\"   0  =  1   -1  prt1-1-T   <p>Great! We asked for the <b>correct<\/b> model. But, no model is correct. <br>Let’s rephrase.<\/p>   =  0   -1  prt1-1-F   <p>Nice try! But, we asked for the <b>correct<\/b> model. However, no model is correct. <br>Let’s rephrase.<\/p>      prt2  1.0000000  1  1      0  check correct answer  AlgEquiv  ans2  \"B\"   0  =  1   -1  prt2-1-T   <p>The residual deviance is <b>smaller<\/b> in model B than in model A, so model B accounts for more variability than A.<\/p>   =  0   1  prt2-1-F       1  feedback for incorrect answers  AlgEquiv  ans2  \"A\"   0  +  0   -1  prt2-2-T   <p>Not quite, we want the model with the <b>smallest<\/b> residual deviance. <br>We can see that model B has a smaller residual deviance than model A. This means that more variability is accounted for in model B.<\/p>   -  0   -1  prt2-2-F   <p>Not quite, the deviance is a measure of variability, and here the residual deviance is <b>smaller<\/b> in model B than in model A. <br>Hence, Model B accounts for more variability than A.<\/p>      prt3  1.0000000  1  1      0  check correct answer  AlgEquiv  ans3  \"It depends\"   0  =  1   -1  prt3-1-T   <p>Which measure is the one to use here depends on your research question: <br>Is it better to account for more variability, or to account for variability more efficiently? This is the difference between AIC and BIC. <\/p> <br> <p>We have two different model comparisons, AIC and BIC. These categorise models differently because they are prioritising different things.<\/p> <p>We shouldn’t always use one comparison method over the other, but rather use the approach that makes more sense in the context: This comes back to the objectives on what is the best approach to compare models. Whether it is good or not, is whether it is useful for your research objectives.<\/p> <p>In this particular case, the author states that “In this context, a suitable model is being regarded as the model that explains more variability but with less complexity.”<\/p> <p>In other words, they favour BIC over AIC, so, in their context, they prefer Model A over B.<\/p> <p>While the statistical model is important for publication, the choice of model often makes little difference in terms of interpretation.<\/p><em> For more information, if you are interested:<br><\/em>Some model comparison metrics define a better model as one that accounts for more variability, this is like seen with AIC. In this instance, Model B outperforms Model A. Some model comparison metrics define a better model as one that accounts for variability efficiently, that is, with fewer parameters. This is like seen with the second method using BIC. BIC penalises more complexity in a model (that is, models with more parameters - including interactions) more than AIC. Hence, the BIC suggests that Model A outperforms Model B.   =  0   1  prt3-1-F       1  feedback for incorrect answers  AlgEquiv  ans3  \"A\"   0  +  0   -1  prt3-2-T   <p>That could be correct but it depends on the research question. Is it more important to account for more variability or to account for variability more efficiently? <br>The smaller AIC value suggests that Model B outperforms A. But, the smaller BIC value suggests that Model A outperforms B. <br>Whether we want to use AIC or BIC is unknown here <b>since the research objectives have not been stated in the question<\/b>.<\/p><p><br><\/p><p><\/p><p>We have two different model comparisons, AIC and BIC. These categorise models differently because they are prioritising different things.<\/p><p>We shouldn’t always use one comparison method over the other, but rather use the approach that makes more sense in the context: This comes back to the objectives on what is the best approach to compare models. Whether it is good or not, is whether it is useful for your research objectives.<\/p><p>In this particular case, the author states that “In this context, a suitable model is being regarded as the model that explains more variability but with less complexity.”<\/p><p>In other words, they favour BIC over AIC, so, in their context, they prefer Model A over B.<\/p><p>While the statistical model is important for publication, the choice of model often makes little difference in terms of interpretation.<\/p><em>For more information, if you are interested:<br><\/em>Some model comparison metrics define a better model as one that accounts for more variability, this is like seen with AIC. In this instance, Model B outperforms Model A. Some model comparison metrics define a better model as one that accounts for variability efficiently, that is, with fewer parameters. This is like seen with the second method using BIC. BIC penalises more complexity in a model (that is, models with more parameters - including interactions) more than AIC. Hence, the BIC suggests that Model A outperforms Model B.<br><p><\/p>   -  0   -1  prt3-2-F   <p>That could be correct but it depends on the research question. Is it more important to account for more variability or to account for variability more efficiently? <br>The smaller AIC value suggests that Model B outperforms A. But, the smaller BIC value suggests that Model A outperforms B. <br>Whether we want to use AIC or BIC is unknown here <b>since the research objectives have not been stated in the question<\/b>.<\/p><p><br><\/p><p><\/p><p>We have two different model comparisons, AIC and BIC. These categorise models differently because they are prioritising different things.<\/p><p>We shouldn’t always use one comparison method over the other, but rather use the approach that makes more sense in the context: This comes back to the objectives on what is the best approach to compare models. Whether it is good or not, is whether it is useful for your research objectives.<\/p><p>In this particular case, the author states that “In this context, a suitable model is being regarded as the model that explains more variability but with less complexity.”<\/p><p>In other words, they favour BIC over AIC, so, in their context, they prefer Model A over B.<\/p><p>While the statistical model is important for publication, the choice of model often makes little difference in terms of interpretation.<\/p><em>For more information, if you are interested:<br><\/em>Some model comparison metrics define a better model as one that accounts for more variability, this is like seen with AIC. In this instance, Model B outperforms Model A. Some model comparison metrics define a better model as one that accounts for variability efficiently, that is, with fewer parameters. This is like seen with the second method using BIC. BIC penalises more complexity in a model (that is, models with more parameters - including interactions) more than AIC. Hence, the BIC suggests that Model A outperforms Model B.<br><p><\/p>      1  Test case assuming the teacher's input gets full marks.   ans1  first(mcq_correct(m_ans1))    ans2  first(mcq_correct(m_ans2))    ans3  first(mcq_correct(m_ans3))    prt1  1.0000000  0.0000000  prt1-1-T    prt2  1.0000000  0.0000000  prt2-1-T    prt3  1.0000000  0.0000000  prt3-1-T         Estimate mean & median        Estimate mean & median    <p>The precipitation in {@ds1@} Eastern African cities in August was measured and the results were grouped in intervals of 6mm. The results are displayed in the graph below.<\/p> <p>Estimate the the mean and median precipitation.<\/p> <p> [[jsxgraph]] \/\/ Create empty list of points var p = []; \/\/ Create board var board = JXG.JSXGraph.initBoard(divid, { boundingbox: [{#xmin#}, {#ymax#}, {#xmax#}, {#ymin#}], keepaspectratio: false, showCopyright: false, axis:true, pan:{enabled:false} }); \/\/Create points of Data Set 1 var lx1 = {#dorx1#}; var ly1 = {#dory#}; var i = 0; for (i = 0; i <= lx1.length - 1; i++) { p[i] = board.create('point', [lx1[i], ly1[i]], { face: 'x', name: '', size: 2, fixed:true }); } [[\/jsxgraph]] <\/p> <p>Mean = [[input:ans1]] [[validation:ans1]] [[feedback:prt1]]<\/p> <p>Median = [[input:ans2]] [[validation:ans2]] [[feedback:prt2]]<\/p>    <h3>Worked Solutiuon<\/h3> <p>Click here to learn more on how estimate standard deviation <a href=\"https:\/\/ecampus.idems.international\/mod\/resource\/view.php?id=13393\" download=\"\">\"Estimating Standard deviation\".<\/a><\/p><p><\/p>   1  0.1  0    2025073100    mean1:rand(30)+30; sd1:(rand(0.3)+0.5)*mean1; ds1:rand(50)+50; bb:(sd1^2\/mean1); aa:(mean1^2\/sd1^2); dunx:makelist(round(float(quantile_gamma(rand(1.0),aa,bb))),i,1,ds1); dorx:sort(dunx); dorx1:makelist(1,i,1,ds1); for i:1 thru ds1 do dorx1[i]:6*floor(dorx[i]\/6)+3; m1:float(mean(dorx1)); mr1:round(m1) m2:float(median(dorx1)); mr2:round(m2) maxfreq1:0; k:1; for i:2 thru ds1 do if dorx1[i]=dorx1[i-1] then (k:k+1, if maxfreq1 < k then maxfreq1:k) else k:1; xmin:dorx1[1]-2; xmax:dorx1[ds1]+2+(dorx[ds1]-dorx[1])\/1.5; ymin:-2; ymax:if maxfreq1+2<20 then 20 else maxfreq1+2; j:1; dory:makelist(0,i,1,ds1); dory[1]:1; for i:2 thru ds1 do if dorx1[i]=dorx1[i-1] then (j:j+1, dory[i]:j) else (j:1, dory[i]:j);       Mean: {@mean1@} SD: {@sd1@}      1  0  0   <span style=\"font-size: 1.5em; color:green;\"><i class=\"fa fa-check\"><\/i><\/span> Correct answer, well done.    <span style=\"font-size: 1.5em; color:orange;\"><i class=\"fa fa-adjust\"><\/i><\/span> Your answer is partially correct.    <span style=\"font-size: 1.5em; color:red;\"><i class=\"fa fa-times\"><\/i><\/span> Incorrect answer.   .  *10  dot  1  i  cos-1  lang  [  0    ans1  algebraic  dispdp(m1,1)  8  1  0   0    0  0  0  0  0     ans2  algebraic  m2  8  1  0   0    0  0  0  0  0     prt1  1.0000000  1  1      0   NumRelative  ans1  m1  0.1  0  =  1   -1  prt1-1-T   Your answer is close enough. The actual value is {@mr1@} mm.   =  0   1  prt1-1-F       1   NumRelative  ans1  m1  0.2  0  +  0.5   -1  prt1-2-T   Your answer is almost close enough. The actual value is {@mr1@} mm, with practice you should be able to estimate the mean to within 10%.   -  0   -1  prt1-2-F   You are a bit too far from the actual value of {@mr1@} mm. Your estimate of the mean is more than 20% away, with practice you should be able to do better.      prt2  1.0000000  1  1      0   NumRelative  ans2  m2  0.1  1  =  1   -1  prt2-1-T   Your answer is close enough. The actual value is {@mr2@} mm.   =  0   1  prt2-1-F       1   NumRelative  ans2  m2  0.2  1  =  0   -1  prt2-2-T   Your answer is almost close enough. The actual value is {@mr2@} mm, with practice you should be able to estimate the median to within 10%.   -  0   2  prt2-2-F   You are a bit too far from the actual value of {@mr2@} mm. Your estimate of the median is more than 20% away, with practice you should be able to do better.     2   GT  ans1  ans2   1  =  0   -1  prt2-3-T     -  0.5   -1  prt2-3-F   <br> Your relative positioning of the mean and median do not reflect the skewness in the data. Remember that outliers affect the mean but not the median, hence with skew data the mean is 'pulled' out towards the extreme values while the median is not affected by individual extreme values.     1441463446  605340425  1804567825  1889294779  2020113376  58359995  1845046867  549914397  1549604271  1334665909  130928925  792429314  1761512339  77013594  1258296241  437971548  898922840  2058296704  595358975  781255664   1  Test case assuming the teacher's input gets full marks.   ans1  dispdp(m1,1)    ans2  m2    prt1  1.0000000  0.0000000  prt1-1-T    prt2  1.0000000  0.0000000  prt2-1-T         "
},
{
  "id": "sec-applied-comprehension-2-1",
  "level": "2",
  "url": "sec-applied-comprehension.html#sec-applied-comprehension-2-1",
  "type": "Checkpoint",
  "number": "[STRUCT].0",
  "title": "Estimate standard deviation.",
  "body": " Estimate standard deviation        Estimate standard deviation    <p>The following diagram shows the height in cm of {@ds1@} adults in a village.<\/p> <p> [[jsxgraph]] \/\/ Create empty list of points var p = []; \/\/ Create board var board = JXG.JSXGraph.initBoard(divid, { boundingbox: [{#xmin#}, {#ymax#}, {#xmax#}, {#ymin#}], keepaspectratio: false, showCopyright: false, axis:true, pan:{enabled:false} }); \/\/Create points of Data Set 1 var lx1 = {#dorx1#}; var ly1 = {#dory#}; var i = 0; for (i = 0; i <= lx1.length - 1; i++) { p[i] = board.create('point', [lx1[i], ly1[i]], { face: 'x', name: '', size: 2, fixed:true }); } [[\/jsxgraph]] <\/p> <p>Estimate the standard deviation of heights [[input:ans1]]cm [[validation:ans1]]<\/p>    Use the following as a guide. An interval that is 2s wide usually covers about the middle two thirds of the crosses (i.e. x̅ ± s). An interval that is 4s wide usually covers about the middle 95% of the crosses (i.e. x̅ ± 2s). The range of the data is usually between 5s and 6s (i.e. x̅ ± 2.5s to x̅ ± 3s). In this case the mean is about {@mean_real@} and you should be able to estimate the standard deviation close to the real value of {@mr1@}. <p>Click here to learn more on how estimate standard deviation <a href=\"https:\/\/ecampus.idems.international\/mod\/resource\/view.php?id=13393\" download=\"\">\"Estimating Standard deviation\".<\/a><\/p><p><\/p>   1  0.1  0    2025073100    mean1:rand(101)+100; aa:rand([-1,0,1]); sd1:rand(5)+5; bb:rand([1\/3,1\/2,1,2,3]); ds1:rand(41)+60; dun1:makelist(round(float(quantile_normal(rand(1.0),mean1,sd1))),i,1,ds1); dorx1:sort(dun1); m1:float(std(dorx1)); mr1:dispdp(m1,1); mean_real: round(mean(dorx1)); maxfreq1:0; k:1; for i:2 thru ds1 do if dorx1[i]=dorx1[i-1] then (k:k+1, if maxfreq1 < k then maxfreq1:k) else k:1; xmin:dorx1[1]-2; xmax:dorx1[ds1]+2+(dorx1[ds1]-dorx1[1])\/1.5; ymin:-2; ymax:if maxfreq1+2<15 then 15 else maxfreq1+2; j:1; dory:makelist(0,i,1,ds1); dory[1]:1; for i:2 thru ds1 do if dorx1[i]=dorx1[i-1] then (j:j+1, dory[i]:j) else (j:1, dory[i]:j);    [[feedback:prt1]]    mean = {@mean1@} sd = {@sd1@}      1  0  0   <span style=\"font-size: 1.5em; color:green;\"><i class=\"fa fa-check\"><\/i><\/span> Correct answer, well done.    <span style=\"font-size: 1.5em; color:orange;\"><i class=\"fa fa-adjust\"><\/i><\/span> Your answer is partially correct.    <span style=\"font-size: 1.5em; color:red;\"><i class=\"fa fa-times\"><\/i><\/span> Incorrect answer.   .  *10  dot  1  i  cos-1  lang  [  0    ans1  numerical  mr1  8  1  0   0    0  0  0  0  0     prt1  1.0000000  1  1      0   NumRelative  ans1  m1  0.1  0  =  1   -1  prt1-1-T   Well done you are within 10% of the actual standard deviation!   =  0  0.1  1  prt1-1-F       1   NumRelative  ans1  m1  0.25  0  +  0.5   -1  prt1-2-T   Well done that is quite close! You are within 25% of the actual standard deviation. With practice you should be able to estimate to within 10% of the standard deviation, why don't you have another go.   -  0   -1  prt1-2-F   Not close enough! You should be able to estimate to within 25% of the standard deviation, why don't you have another go.     750076029  446160850  1892374070  2038073284  1263306952  1834225363  71100161  150651908  208727463  1872513520  922251234  1521000575  1146896948  1418421722  1852836895  1692796730  755010582  1263532427  801291460  643940405   1    ans1  mr1    prt1  1.0000000  0.0000000  prt1-1-T       "
},
{
  "id": "sec-applied-comprehension-2-2",
  "level": "2",
  "url": "sec-applied-comprehension.html#sec-applied-comprehension-2-2",
  "type": "Checkpoint",
  "number": "[STRUCT].1",
  "title": "Place the estimated value of mean and median in stacked dotplot.",
  "body": " Place the estimated value of mean and median in stacked dotplot        Place the estimated value of mean and median in stacked dotplot    <p>The precipitation in {@ds1@} Eastern African cities in August was measured and the results were grouped in intervals of 6mm. The results are displayed in the graph below. Estimate 'by eye' the values of the mean and median precipitation. Give your answer by dragging the two vertical lines corresponding to the mean and median to the estimated position.<\/p> <p> [[jsxgraph input-ref-ans1=\"sR1\" input-ref-ans2=\"sR2\" input-ref-ans3=\"sR3\" input-ref-ans4=\"sR4\"]] JXG.Options.text.useMathJax = true; \/\/ Create empty list of points var p = []; \/\/ Create board var board = JXG.JSXGraph.initBoard(divid, { boundingbox: [{#xmin#}, {#ymax#}, {#xmax#}, {#ymin#}], keepaspectratio: false, showCopyright: false, axis:true, pan:{enabled:false} }); \/\/ Create points for the Data Set var lx1 = {#dorx1#}; var ly1 = {#dory#}; var i = 0; for (i = 0; i <= lx1.length - 1; i++) { p[i] = board.create('point', [lx1[i], ly1[i]], { face: 'x', name: '', size: 2, fixed:true }); } \/\/ Create hidden point for the mean var qm1 = board.create('point', [5,0], { name: \"C\", size: 2, visible: false }); \/\/ Line for the mean var qm11 = board.create('point', [5,5], { name: \"C\", size: 2, visible: false }); var m1 = board.create('line', [qm1, qm11], { straightFirst: true, straightLast: true, strokeWidth: 2, strokeColor: '#21a34c' }); var lblm1 = board.create('text', [function() {return qm1.X()+1},{#ymax-1#},'mean'], { fontSize: 15, color: '#21a34c' }); \/\/ Create hidden point for the median var qm2 = board.create('point', [{#xmax#}-20,0], { name: \"C\", size: 2, visible: false }); \/\/ Line for the median var qm21 = board.create('point', [{#xmax#}-20,5], { name: \"C\", size: 2, visible: false }); var m2 = board.create('line', [qm2,qm21], { straightFirst: true, straightLast: true, strokeWidth: 2, strokeColor: '#901B77' }); var lblm2 = board.create('text', [function() {return qm2.X()+1},{#ymax-2#},'median'], { fontSize: 15, color: '#901B77' }); \/* Set answers from state of graph *\/ stack_jxg.bind_point(sR1,qm1); stack_jxg.bind_point(sR3,qm11); stack_jxg.bind_point(sR2,qm2); stack_jxg.bind_point(sR4,qm21); board.unsuspendUpdate(); [[\/jsxgraph]] <\/p> <p>[[feedback:prt3]]<\/p> <p style=\"display:none;\">[[input:ans1]] [[validation:ans1]] <\/p> <p>[[feedback:prt1]]<\/p> <p style=\"display:none;\">[[input:ans2]] [[validation:ans2]]<\/p> <p style=\"display:none;\">[[input:ans3]] [[validation:ans3]]<\/p> <p style=\"display:none;\">[[input:ans4]] [[validation:ans4]]<\/p> <p>[[feedback:prt2]]<\/p>      1  0.1  0    2025073100    \/* Parameters for the distribution *\/ mean1:rand(30)+30; sd1:(rand(0.3)+0.5)*mean1; ds1:rand(50)+50; bb:(sd1^2\/mean1); aa:(mean1^2\/sd1^2); \/* Create the data using with a left skew *\/ dunx:makelist(round(float(quantile_gamma(rand(1.0),aa,bb))),i,1,ds1); dorx:sort(dunx); \/* Group data on intervals of length 6 *\/ dorx1:makelist(1,i,1,ds1); for i:1 thru ds1 do dorx1[i]:6*floor(dorx[i]\/6)+3; \/* Calculate the actual mean of the grouped data *\/ m1:float(mean(dorx1)); mr1:round(m1) \/* Calculate the actual median of the grouped data *\/ m2:float(median(dorx1)); mr2:round(m2) \/* Finding bounds for the graph *\/ \/* Calculating the maximum frequency to determine the max y-value *\/ maxfreq1:0; k:1; for i:2 thru ds1 do if dorx1[i]=dorx1[i-1] then (k:k+1, if maxfreq1 < k then maxfreq1:k) else k:1; \/* Define max y-value. Set it to a minimum of 20 so that points are not squashed together *\/ ymax:if maxfreq1+2<20 then 20 else maxfreq1+2; \/* Define the min y-value and the max and min x-values *\/ xmax:dorx1[ds1]+2;\/*+(dorx[ds1]-dorx[1])\/1.5 can be added to create empty space on the right to make it visible on mobile phones *\/ xmin:if dorx1[1]-10<0 then dorx1[1]-10 else -10; ymin:-2; \/* Find the y-coordinate for each point *\/ j:1; dory:makelist(0,i,1,ds1); dory[1]:1; for i:2 thru ds1 do if dorx1[i]=dorx1[i-1] then (j:j+1, dory[i]:j) else (j:1, dory[i]:j);       <p>Mean = \"rand(30)+30\" = {@mean1@}, SD = \"(rand(0.3)+0.5)*Mean\" = {@sd1@}<\/p> <p>Data Size = \"rand(50)+50\" = {@ds1@}<\/p> <p>Gamma Parameters [a,b] = [{@aa@},{@bb@}]<\/p>      1  0  0   <span style=\"font-size: 1.5em; color:green;\"><i class=\"fa fa-check\"><\/i><\/span> Correct answer, well done.    <span style=\"font-size: 1.5em; color:orange;\"><i class=\"fa fa-adjust\"><\/i><\/span> Your answer is partially correct.    <span style=\"font-size: 1.5em; color:red;\"><i class=\"fa fa-times\"><\/i><\/span> Incorrect answer.   .  *10  dot  1  i  cos-1  lang  [  0    ans1  algebraic  [m1, 1]  15  1  0   0    0  0  0  0  0     ans2  algebraic  [m2, 1]  15  1  0   0    0  0  0  0  0     ans3  algebraic  [m1, 2]  15  1  0   0    0  0  0  0  0     ans4  algebraic  [m2, 2]  15  1  0   0    0  0  0  0  0     prt1  1.0000000  1  1      0   NumRelative  ans1[1]  m1  0.1  0  =  1   -1  prt1-1-T   Your answer for the mean is close enough. The actual value is {@mr1@} mm.   =  0   1  prt1-1-F       1   NumRelative  ans1[1]  m1  0.2  0  +  0.5   -1  prt1-2-T   Your answer for the mean is almost close enough. The actual value is {@mr1@} mm, with practice you should be able to estimate the mean to within 10%.   -  0   -1  prt1-2-F   You are a bit too far from the actual mean value of {@mr1@} mm. Your estimate of the mean is more than 20% away, with practice you should be able to do better.      prt2  1.0000000  1  1      0   NumRelative  ans2[1]  m2  0.1  0  =  1   -1  prt2-1-T   Your answer for the median is close enough. The actual value is {@mr2@} mm.   =  0   1  prt2-1-F       1   NumRelative  ans2[1]  m2  0.2  0  +  0.5   -1  prt2-2-T   Your answer for the medain is almost close enough. The actual value is {@mr2@} mm, with practice you should be able to estimate the median to within 10%.   -  0   -1  prt2-2-F   You are a bit too far from the actual median value of {@mr2@} mm. Your estimate of the median is more than 20% away, with practice you should be able to do better.      prt3  1.0000000  1  1   correct_rel_pos:if m1>m2 then (if ans1[1]>ans2[1] then 1 else 0) else (if ans1[1]<ans2[1] then 1 else 0);    0   AlgEquiv  correct_rel_pos  1   0  =  1   -1  prt3-1-T   <p>Well done you have correctly reflected the skewness in the data by your relative positioning of the mean and median. A quick reminder is that outliers affect the mean but not the median.<\/p>   =  0   -1  prt3-1-F   <p>Your relative positioning of the mean and median do not reflect the skewness in the data. Remember that outliers affect the mean but not the median, hence with skew data the mean is 'pulled' out towards the extreme values while the median is not affected by individual extreme values.<\/p>     1180180573  897215019  1947941280  231250545  1127514141  1588005898  254115884  46394728  1922285942  1774773390  135245803  1762319639  258514681  133230507  76854659  1705835802  544875161  21686271  1529701231  1971182280   1  Test case assuming the teacher's input gets full marks.   ans1  [m1, 1]    ans2  [m2, 1]    ans3  [m1, 2]    ans4  [m2, 2]    prt1  1.0000000  0.0000000  prt1-1-T    prt2  1.0000000  0.0000000  prt2-1-T    prt3  1.0000000  0.0000000  prt3-1-T     <\n>  <\n>  <\n>  <\n>      "
},
{
  "id": "sec-applied-comprehension-2-3",
  "level": "2",
  "url": "sec-applied-comprehension.html#sec-applied-comprehension-2-3",
  "type": "Checkpoint",
  "number": "[STRUCT].2",
  "title": "Model Comparison.",
  "body": " Model Comparison        Model Comparison    <p>This question is based on research by Dr. Francis Torgbor in his MPhil Thesis.<\/p> <p>The thesis looks to create a useful guide in preparation of the effect of rainfall patterns in Ghana. Understanding and modelling rainfall patterns is important. To understand and model the patterns, we need to account for the variability - there is a large variability in rainfall, and this variability can have serious implications on various aspects such as food production and livelihoods. In an attempt to attain a model that describes the pattern for the chance of rain, multiple models were found and then compared to find the “best” model. We will look at two of these models, and call them Model A and Model B.<\/p> <p>The difference between Model A and B is about whether interactions should be included. That is, in Model B, the Markov component corresponding to the dependence of the rainfall on previous days interacts with the seasonality. In Model A, there is no interaction.<\/p> <p>This illustrative scenario compares the performance of Model A with Model B.<\/p> <p>An Analysis of Deviance table can be performed to look at the fit of generalised linear models (GLMs). In brief, deviance is a measure of the difference between the actual values and the fitted model. Like in an ANOVA, an Analysis of Deviance gives a residual deviance - this is the variability that is not accounted for in the model. Therefore, a smaller residual deviance is preferable when fitting a model.<\/p> <br> <table> <tbody><tr> <td width=\"180px\" style=\"padding:5px\"><b>Model A:<\/b><\/td> <td width=\"100px\"><\/td> <td width=\"100px\"><\/td> <td width=\"50px\"><\/td> <td width=\"180px\" style=\"padding:5px\"><b>Model B:<\/b><\/td> <td width=\"100px\"><\/td> <td width=\"100px\"><\/td> <\/tr> <tr> <td style=\"border: 1px solid black; border-collapse: collapse; padding:5px\"><b>Source of Deviation<\/b><\/td> <td style=\"border: 1px solid black; border-collapse: collapse; padding:5px\"><b>DF<\/b><\/td> <td style=\"border: 1px solid black; border-collapse: collapse; padding:5px\"><b>Deviance<\/b><\/td> <td><\/td> <td style=\"border: 1px solid black; border-collapse: collapse; padding:5px\"><b>Source of Deviation<\/b><\/td> <td style=\"border: 1px solid black; border-collapse: collapse; padding:5px\"><b>DF<\/b><\/td> <td style=\"border: 1px solid black; border-collapse: collapse; padding:5px\"><b>Deviance<\/b><\/td> <\/tr> <tr> <td style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">Accounted for<\/td> <td style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">{@modA_df_accounted@}<\/td> <td style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">{@modA_dev_accounted@}<\/td> <td><\/td> <td style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">Accounted for<\/td> <td style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">{@modB_df_accounted@}<\/td> <td style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">{@modB_dev_accounted@}<\/td> <\/tr> <tr> <td style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">Residual<\/td> <td style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">{@modA_df_residual@}<\/td> <td style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">{@modA_dev_residual@}<\/td> <td><\/td> <td style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">Residual<\/td> <td style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">{@modB_df_residual@}<\/td> <td style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">{@modB_dev_residual@}<\/td> <\/tr> <tr> <td style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">Total<\/td> <td style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">{@modA_df_total@}<\/td> <td style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">{@modA_dev_total@}<\/td> <td><\/td> <td style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">Total<\/td> <td style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">{@modB_df_total@}<\/td> <td style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">{@modB_dev_total@}<\/td> <\/tr> <\/tbody><\/table> <br> <p>1. Which is the correct model?<\/p> <p>[[input:ans1]] [[validation:ans1]]<\/p> <p>[[feedback:prt1]]<\/p> <br> <p>2. Given the information you have, which model accounts for more variability out of A and B?<\/p> <p>[[input:ans2]] [[validation:ans2]]<\/p> <p>[[feedback:prt2]]<\/p> <br> <p>3. We now use the Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC) to compare these models. In both cases, a model with a lower AIC or BIC value is said to perform better.<\/p> <table> <tbody><tr> <td width=\"100px\" style=\"border: 1px solid black; border-collapse: collapse; padding:5px\"><b>Model<\/b><\/td> <td width=\"100px\" style=\"border: 1px solid black; border-collapse: collapse; padding:5px\"><b>Parameters<\/b><\/td> <td width=\"100px\" style=\"border: 1px solid black; border-collapse: collapse; padding:5px\"><b>AIC<\/b><\/td> <td width=\"100px\" style=\"border: 1px solid black; border-collapse: collapse; padding:5px\"><b>BIC<\/b><\/td> <\/tr> <tr> <td width=\"100px\" style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">A<\/td> <td width=\"100px\" style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">{@modA_param@}<\/td> <td width=\"100px\" style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">{@modA_AIC@}<\/td> <td width=\"100px\" style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">{@modA_BIC@}<\/td> <\/tr> <tr> <td width=\"100px\" style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">B<\/td> <td width=\"100px\" style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">{@modB_param@}<\/td> <td width=\"100px\" style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">{@modB_AIC@}<\/td> <td width=\"100px\" style=\"border: 1px solid black; border-collapse: collapse; padding:5px\">{@modB_BIC@}<\/td> <\/tr> <\/tbody><\/table> <br> <p>Which model performs better out of A and B?<\/p> <p>[[input:ans3]] [[validation:ans3]]<\/p> <p>[[feedback:prt3]]<\/p>      1  0.1  0    2025073100    modA_df_accounted: 7; modA_dev_accounted: 3417; modA_df_residual: 16771; modA_dev_residual: 13015; modA_df_total: modA_df_accounted+modA_df_residual; modA_dev_total: modA_dev_accounted+modA_dev_residual; modB_df_accounted: 19; modB_dev_accounted: 3521; modB_df_residual: 16759; modB_dev_residual: 12911; modB_df_total: modB_df_accounted+modB_df_residual; modB_dev_total: modB_dev_accounted+modB_dev_residual; modA_param: 8; modA_AIC: 13031; modA_BIC: 13092; modB_param: 20; modB_AIC: 12951; modB_BIC: 13106; m_ans1: [ [\"A\", false], [\"B\", false], [\"Neither\", true] ]; m_ans2: [ [\"A\", false], [\"B\", true], [\"It depends\", false] ]; m_ans3: [ [\"A\", false], [\"B\", false], [\"It depends\", true] ];          <p id=\"author\">Dan Kelly<\/p> <p id=\"concept\">https:\/\/docs.google.com\/document\/d\/1SCVlmN0RPhDBou73SBHXyo6eZdo0PWDsFmgj1H2Jly8\/edit<\/p> <p id=\"reviewer\"><\/p> <p id=\"description\"><\/p>   1  0  0   <span style=\"font-size: 1.5em; color:green;\"><i class=\"fa fa-check\"><\/i><\/span> Correct answer, well done.    <span style=\"font-size: 1.5em; color:orange;\"><i class=\"fa fa-adjust\"><\/i><\/span> Your answer is partially correct.    <span style=\"font-size: 1.5em; color:red;\"><i class=\"fa fa-times\"><\/i><\/span> Incorrect answer.   .  *10  none  1  i  cos-1  lang  [  0    ans1  dropdown  m_ans1  15  1  0   0    1  0  0  0  0     ans2  dropdown  m_ans2  15  1  0   0    1  0  0  0  0     ans3  dropdown  m_ans3  15  1  0   0    1  0  0  0  0     prt1  1.0000000  1  1      0  check correct answer  AlgEquiv  ans1  \"Neither\"   0  =  1   -1  prt1-1-T   <p>Great! We asked for the <b>correct<\/b> model. But, no model is correct. <br>Let’s rephrase.<\/p>   =  0   -1  prt1-1-F   <p>Nice try! But, we asked for the <b>correct<\/b> model. However, no model is correct. <br>Let’s rephrase.<\/p>      prt2  1.0000000  1  1      0  check correct answer  AlgEquiv  ans2  \"B\"   0  =  1   -1  prt2-1-T   <p>The residual deviance is <b>smaller<\/b> in model B than in model A, so model B accounts for more variability than A.<\/p>   =  0   1  prt2-1-F       1  feedback for incorrect answers  AlgEquiv  ans2  \"A\"   0  +  0   -1  prt2-2-T   <p>Not quite, we want the model with the <b>smallest<\/b> residual deviance. <br>We can see that model B has a smaller residual deviance than model A. This means that more variability is accounted for in model B.<\/p>   -  0   -1  prt2-2-F   <p>Not quite, the deviance is a measure of variability, and here the residual deviance is <b>smaller<\/b> in model B than in model A. <br>Hence, Model B accounts for more variability than A.<\/p>      prt3  1.0000000  1  1      0  check correct answer  AlgEquiv  ans3  \"It depends\"   0  =  1   -1  prt3-1-T   <p>Which measure is the one to use here depends on your research question: <br>Is it better to account for more variability, or to account for variability more efficiently? This is the difference between AIC and BIC. <\/p> <br> <p>We have two different model comparisons, AIC and BIC. These categorise models differently because they are prioritising different things.<\/p> <p>We shouldn’t always use one comparison method over the other, but rather use the approach that makes more sense in the context: This comes back to the objectives on what is the best approach to compare models. Whether it is good or not, is whether it is useful for your research objectives.<\/p> <p>In this particular case, the author states that “In this context, a suitable model is being regarded as the model that explains more variability but with less complexity.”<\/p> <p>In other words, they favour BIC over AIC, so, in their context, they prefer Model A over B.<\/p> <p>While the statistical model is important for publication, the choice of model often makes little difference in terms of interpretation.<\/p><em> For more information, if you are interested:<br><\/em>Some model comparison metrics define a better model as one that accounts for more variability, this is like seen with AIC. In this instance, Model B outperforms Model A. Some model comparison metrics define a better model as one that accounts for variability efficiently, that is, with fewer parameters. This is like seen with the second method using BIC. BIC penalises more complexity in a model (that is, models with more parameters - including interactions) more than AIC. Hence, the BIC suggests that Model A outperforms Model B.   =  0   1  prt3-1-F       1  feedback for incorrect answers  AlgEquiv  ans3  \"A\"   0  +  0   -1  prt3-2-T   <p>That could be correct but it depends on the research question. Is it more important to account for more variability or to account for variability more efficiently? <br>The smaller AIC value suggests that Model B outperforms A. But, the smaller BIC value suggests that Model A outperforms B. <br>Whether we want to use AIC or BIC is unknown here <b>since the research objectives have not been stated in the question<\/b>.<\/p><p><br><\/p><p><\/p><p>We have two different model comparisons, AIC and BIC. These categorise models differently because they are prioritising different things.<\/p><p>We shouldn’t always use one comparison method over the other, but rather use the approach that makes more sense in the context: This comes back to the objectives on what is the best approach to compare models. Whether it is good or not, is whether it is useful for your research objectives.<\/p><p>In this particular case, the author states that “In this context, a suitable model is being regarded as the model that explains more variability but with less complexity.”<\/p><p>In other words, they favour BIC over AIC, so, in their context, they prefer Model A over B.<\/p><p>While the statistical model is important for publication, the choice of model often makes little difference in terms of interpretation.<\/p><em>For more information, if you are interested:<br><\/em>Some model comparison metrics define a better model as one that accounts for more variability, this is like seen with AIC. In this instance, Model B outperforms Model A. Some model comparison metrics define a better model as one that accounts for variability efficiently, that is, with fewer parameters. This is like seen with the second method using BIC. BIC penalises more complexity in a model (that is, models with more parameters - including interactions) more than AIC. Hence, the BIC suggests that Model A outperforms Model B.<br><p><\/p>   -  0   -1  prt3-2-F   <p>That could be correct but it depends on the research question. Is it more important to account for more variability or to account for variability more efficiently? <br>The smaller AIC value suggests that Model B outperforms A. But, the smaller BIC value suggests that Model A outperforms B. <br>Whether we want to use AIC or BIC is unknown here <b>since the research objectives have not been stated in the question<\/b>.<\/p><p><br><\/p><p><\/p><p>We have two different model comparisons, AIC and BIC. These categorise models differently because they are prioritising different things.<\/p><p>We shouldn’t always use one comparison method over the other, but rather use the approach that makes more sense in the context: This comes back to the objectives on what is the best approach to compare models. Whether it is good or not, is whether it is useful for your research objectives.<\/p><p>In this particular case, the author states that “In this context, a suitable model is being regarded as the model that explains more variability but with less complexity.”<\/p><p>In other words, they favour BIC over AIC, so, in their context, they prefer Model A over B.<\/p><p>While the statistical model is important for publication, the choice of model often makes little difference in terms of interpretation.<\/p><em>For more information, if you are interested:<br><\/em>Some model comparison metrics define a better model as one that accounts for more variability, this is like seen with AIC. In this instance, Model B outperforms Model A. Some model comparison metrics define a better model as one that accounts for variability efficiently, that is, with fewer parameters. This is like seen with the second method using BIC. BIC penalises more complexity in a model (that is, models with more parameters - including interactions) more than AIC. Hence, the BIC suggests that Model A outperforms Model B.<br><p><\/p>      1  Test case assuming the teacher's input gets full marks.   ans1  first(mcq_correct(m_ans1))    ans2  first(mcq_correct(m_ans2))    ans3  first(mcq_correct(m_ans3))    prt1  1.0000000  0.0000000  prt1-1-T    prt2  1.0000000  0.0000000  prt2-1-T    prt3  1.0000000  0.0000000  prt3-1-T       "
},
{
  "id": "sec-applied-comprehension-2-4",
  "level": "2",
  "url": "sec-applied-comprehension.html#sec-applied-comprehension-2-4",
  "type": "Checkpoint",
  "number": "[STRUCT].3",
  "title": "Estimate mean &amp; median.",
  "body": " Estimate mean & median        Estimate mean & median    <p>The precipitation in {@ds1@} Eastern African cities in August was measured and the results were grouped in intervals of 6mm. The results are displayed in the graph below.<\/p> <p>Estimate the the mean and median precipitation.<\/p> <p> [[jsxgraph]] \/\/ Create empty list of points var p = []; \/\/ Create board var board = JXG.JSXGraph.initBoard(divid, { boundingbox: [{#xmin#}, {#ymax#}, {#xmax#}, {#ymin#}], keepaspectratio: false, showCopyright: false, axis:true, pan:{enabled:false} }); \/\/Create points of Data Set 1 var lx1 = {#dorx1#}; var ly1 = {#dory#}; var i = 0; for (i = 0; i <= lx1.length - 1; i++) { p[i] = board.create('point', [lx1[i], ly1[i]], { face: 'x', name: '', size: 2, fixed:true }); } [[\/jsxgraph]] <\/p> <p>Mean = [[input:ans1]] [[validation:ans1]] [[feedback:prt1]]<\/p> <p>Median = [[input:ans2]] [[validation:ans2]] [[feedback:prt2]]<\/p>    <h3>Worked Solutiuon<\/h3> <p>Click here to learn more on how estimate standard deviation <a href=\"https:\/\/ecampus.idems.international\/mod\/resource\/view.php?id=13393\" download=\"\">\"Estimating Standard deviation\".<\/a><\/p><p><\/p>   1  0.1  0    2025073100    mean1:rand(30)+30; sd1:(rand(0.3)+0.5)*mean1; ds1:rand(50)+50; bb:(sd1^2\/mean1); aa:(mean1^2\/sd1^2); dunx:makelist(round(float(quantile_gamma(rand(1.0),aa,bb))),i,1,ds1); dorx:sort(dunx); dorx1:makelist(1,i,1,ds1); for i:1 thru ds1 do dorx1[i]:6*floor(dorx[i]\/6)+3; m1:float(mean(dorx1)); mr1:round(m1) m2:float(median(dorx1)); mr2:round(m2) maxfreq1:0; k:1; for i:2 thru ds1 do if dorx1[i]=dorx1[i-1] then (k:k+1, if maxfreq1 < k then maxfreq1:k) else k:1; xmin:dorx1[1]-2; xmax:dorx1[ds1]+2+(dorx[ds1]-dorx[1])\/1.5; ymin:-2; ymax:if maxfreq1+2<20 then 20 else maxfreq1+2; j:1; dory:makelist(0,i,1,ds1); dory[1]:1; for i:2 thru ds1 do if dorx1[i]=dorx1[i-1] then (j:j+1, dory[i]:j) else (j:1, dory[i]:j);       Mean: {@mean1@} SD: {@sd1@}      1  0  0   <span style=\"font-size: 1.5em; color:green;\"><i class=\"fa fa-check\"><\/i><\/span> Correct answer, well done.    <span style=\"font-size: 1.5em; color:orange;\"><i class=\"fa fa-adjust\"><\/i><\/span> Your answer is partially correct.    <span style=\"font-size: 1.5em; color:red;\"><i class=\"fa fa-times\"><\/i><\/span> Incorrect answer.   .  *10  dot  1  i  cos-1  lang  [  0    ans1  algebraic  dispdp(m1,1)  8  1  0   0    0  0  0  0  0     ans2  algebraic  m2  8  1  0   0    0  0  0  0  0     prt1  1.0000000  1  1      0   NumRelative  ans1  m1  0.1  0  =  1   -1  prt1-1-T   Your answer is close enough. The actual value is {@mr1@} mm.   =  0   1  prt1-1-F       1   NumRelative  ans1  m1  0.2  0  +  0.5   -1  prt1-2-T   Your answer is almost close enough. The actual value is {@mr1@} mm, with practice you should be able to estimate the mean to within 10%.   -  0   -1  prt1-2-F   You are a bit too far from the actual value of {@mr1@} mm. Your estimate of the mean is more than 20% away, with practice you should be able to do better.      prt2  1.0000000  1  1      0   NumRelative  ans2  m2  0.1  1  =  1   -1  prt2-1-T   Your answer is close enough. The actual value is {@mr2@} mm.   =  0   1  prt2-1-F       1   NumRelative  ans2  m2  0.2  1  =  0   -1  prt2-2-T   Your answer is almost close enough. The actual value is {@mr2@} mm, with practice you should be able to estimate the median to within 10%.   -  0   2  prt2-2-F   You are a bit too far from the actual value of {@mr2@} mm. Your estimate of the median is more than 20% away, with practice you should be able to do better.     2   GT  ans1  ans2   1  =  0   -1  prt2-3-T     -  0.5   -1  prt2-3-F   <br> Your relative positioning of the mean and median do not reflect the skewness in the data. Remember that outliers affect the mean but not the median, hence with skew data the mean is 'pulled' out towards the extreme values while the median is not affected by individual extreme values.     1441463446  605340425  1804567825  1889294779  2020113376  58359995  1845046867  549914397  1549604271  1334665909  130928925  792429314  1761512339  77013594  1258296241  437971548  898922840  2058296704  595358975  781255664   1  Test case assuming the teacher's input gets full marks.   ans1  dispdp(m1,1)    ans2  m2    prt1  1.0000000  0.0000000  prt1-1-T    prt2  1.0000000  0.0000000  prt2-1-T       "
},
{
  "id": "sec-technical-skills",
  "level": "1",
  "url": "sec-technical-skills.html",
  "type": "Section",
  "number": "1.3",
  "title": "Technical Skills",
  "body": " Technical Skills    Pivot Table (Proportion)        Pivot Table (Proportion)    <p>A survey was performed between farms to determine their planting preferences. Three variables are given in this survey:<\/p> <ol> <li>Sex of the farmer - male or female<\/li> <li>Village of the farmer - north or south<\/li> <li>Variety of the crop - A or B<\/li> <\/ol> <p>The task is to use the data below to answer the following questions <strong>using pivot tables<\/strong> to investigate the data.<\/p> <p><a href=\"[[textdownload name=\"data.csv\"]]{@stack_csv_formatter(data,factor_names)@}[[\/textdownload]]\">Download Data<\/a><\/p> <br> <p>Note: Leave your answer in fraction form<\/p> <p>1. What's the proportion of {@if quest_exp=\"Male\" then \"male farmers\" else if quest_exp=\"Female\" then \"female farmers\" else if quest_exp=\"North\" then \"farmers from the north village\" else if quest_exp=\"South\" then \"farmers from the south village\"@} who are planting Variety {@quest_var@}?<\/p> <p>[[input:ans1]] [[validation:ans1]]<\/p> <p>[[feedback:prt1]]<\/p> <p>2. Of those who planted Variety {@quest_var@}, what proportion of the farmers are {@if quest_exp=\"Male\" then \"male\" else if quest_exp=\"Female\" then \"female\" else if quest_exp=\"North\" then \"from the north village\" else if quest_exp=\"South\" then \"from the south village\"@}.<\/p> <p>[[input:ans2]] [[validation:ans2]]<\/p> <p>[[feedback:prt2]]<\/p> <p>3. What's the proportion of individuals who are {@if quest_exp=\"Male\" then \"male\" else if quest_exp=\"Female\" then \"female\" else if quest_exp=\"North\" then \"from the north village\" else if quest_exp=\"South\" then \"from the south village\"@} and planting Variety {@quest_var@}<\/p> <p>[[input:ans3]] [[validation:ans3]]<\/p> <p>[[feedback:prt3]]<\/p>      1  0.1  0    2025073100    \/* ------------- INFORMATION FROM QUESTION AUTHORS *\/ varietyA_prob: (rand(7)+2)\/10; factor_info: [ [\"Sex\", [ [\"Male\", 0.4], [\"Female\", 0.6] ]], [\"Village\", [ [\"North\", 0.2], [\"South\", 0.8] ]], [\"Variety\", [ [\"A\", varietyA_prob], [\"B\", 1-varietyA_prob] ]] ]; \/* Dataset dimensions *\/ number_rows: rand_with_step(91,99,1); \/* ------------- END AUTHOR INFO *\/ \/* ------------- DATA SET GENERATION *\/ column_data: []; \/* Useful variables *\/ number_factors: length(factor_info); factor_names: makelist(factor_info[i][1], i, 1, number_factors); \/* Generate data for each factor *\/ for factor in factor_info do block( \/* Generate probability ranges for each value *\/ number_options: length(factor[2]), option_values: makelist(factor[2][i][1], i, 1, number_options), option_probabilities: makelist(factor[2][i][2], i, 1, number_options), factor_data: [], \/* Generate randomised correct values *\/ \/* Assign each option in the list a interval in [0,1] of length equal to the associated probability *\/ value_prob_ranges: makelist( [sum(option_probabilities[j], j, 1, i-1), sum(option_probabilities[j], j, 1, i)], i, 1, number_options ), \/* Randomise choice of option by generating a number in [0,1] and determining in which interval it falls *\/ for i: 1 thru number_rows step 1 do block( rn: rand(1.0), for j: 1 thru number_options step 1 do block( if value_prob_ranges[j][1] <= rn and rn < value_prob_ranges[j][2] then factor_data: append(factor_data, [option_values[j]]) ) ), \/* Append data for each factor to the dataset *\/ column_data: append(column_data, [factor_data]) ); \/* Rotate the data to be given in rows rather than columns of each factor, also add header row *\/ data: makelist(makelist(column_data[j][i], j, 1, number_factors), i, 1, number_rows); data_set: append( [factor_names], data ); \/* ------------- END OF DATA SET GENERATION *\/ \/* ------------- QUESTION VARIABLES *\/ \/* Is the question generally about the sex or village of those surveyed? *\/ quest_form: rand([\"sex\", \"village\"]); quest_index: if quest_form=\"sex\" then 1 else if quest_form=\"village\" then 2; \/* Is the question about the men or women (eq. North or South village)? *\/ quest_exp: if quest_form=\"sex\" then rand([\"Male\", \"Female\"]) else if quest_form=\"village\" then rand([\"North\", \"South\"]); \/* Is the question about variety A or B of the crop? *\/ quest_var: rand([\"A\", \"B\"]); \/* Sublists containing only quest_exp, quest_var or both *\/ quest_exp_only: sublist(data_set, lambda([x], is(x[quest_index]=quest_exp))); quest_var_only: sublist(data_set, lambda([x], is(x[3]=quest_var))); quest_exp_and_var: sublist(quest_exp_only, lambda([x], is(x[3]=quest_var))); \/* Number of entries containing only quest_exp, quest_var or both *\/ no_quest_exp_only: length(quest_exp_only); no_quest_var_only: length(quest_var_only); no_quest_exp_and_var: length(quest_exp_and_var); \/* question 1 - what is the probability of \"quest_exp\" participants who are planting variety \"quest_var\"? *\/ ta_1: no_quest_exp_and_var\/no_quest_exp_only; \/* question 2 - of those who planted \"quest_var\", how many are \"quest_exp\"? *\/ ta_2: no_quest_exp_and_var\/no_quest_var_only; \/* question 3 - what proportion are \"quest_exp\" and planting \"quest_var\"? *\/ ta_3: no_quest_exp_and_var\/number_rows; \/* ------------- END OF QUESTION VARIABLES *\/       <p>1. Proportion of {@quest_exp@} farmers planting Variety {@quest_var@}<\/p> <p>{@ta_1@}<\/p> <p>2. Of those planting Variety {@quest_var@}, what proportion are {@quest_exp@}<\/p> <p>{@ta_2@}<\/p> <p>3. Proportion of individuals who are {@quest_exp@} and planting Variety {@quest_var@}<\/p> <p>{@ta_3@}<\/p>    <p id=\"author\">Dan Kelly<\/p> <p id=\"concept\">https:\/\/docs.google.com\/document\/d\/1yPGZysLZE1r3R_oom4SQiMknF64FzULcWvQMBF1uBsk\/edit#heading=h.wvpxq8elfr9z<\/p> <p id=\"reviewer\"><\/p> <p id=\"description\"><\/p>   1  0  0   <span style=\"font-size: 1.5em; color:green;\"><i class=\"fa fa-check\"><\/i><\/span> Correct answer, well done.    <span style=\"font-size: 1.5em; color:orange;\"><i class=\"fa fa-adjust\"><\/i><\/span> Your answer is partially correct.    <span style=\"font-size: 1.5em; color:red;\"><i class=\"fa fa-times\"><\/i><\/span> Incorrect answer.   .  *10  none  1  i  cos-1  lang  [  0    ans1  algebraic  ta_1  15  1  0   0   %  0  0  0  1  3     ans2  algebraic  ta_2  15  1  0   0    1  0  0  1  3     ans3  algebraic  ta_3  15  1  0   0    1  0  0  1  3     prt1  1.0000000  1  1   \/* wrong denominator *\/ node2_error: no_quest_exp_and_var\/number_rows; node3_error: no_quest_exp_and_var\/no_quest_var_only; \/* wrong numerator *\/ node4_error: no_quest_var_only\/number_rows; node5_error: no_quest_exp_only\/number_rows; \/* other mistake *\/ node6_error: no_quest_exp_only\/no_quest_var_only; \/*answer as rounded percentage?*\/ simp:false; rounded_percentage_check:if denom(ans1)=100 then 1 else 0; simp:true;    0  check correct answer  AlgEquiv  ans1  ta_1   0  =  1   -1  prt1-1-T   <p>The question is essentially asking for the fraction of {@if quest_exp=\"Male\" then \"male farmers\" else if quest_exp=\"Female\" then \"female farmers\" else if quest_exp=\"North\" then \"farmers from the north village\" else if quest_exp=\"South\" then \"farmers from the south village\"@} who engage in planting variety {@quest_var@}<\/p> <p>We find the proportion of {@if quest_exp=\"Male\" then \"male farmers\" else if quest_exp=\"Female\" then \"female farmers\" else if quest_exp=\"North\" then \"farmers from the north village\" else if quest_exp=\"South\" then \"farmers from the south village\"@} planting variety {@quest_var@} by dividing their number by the the number of rows in the data set \\(=\\displaystyle \\frac{{@no_quest_exp_and_var@}}{{@no_quest_exp_only@}}\\) <\/p>   =  0   6  prt1-1-F       1  wrong denominator  AlgEquiv  ans1  node2_error   0  =  0   -1  prt1-2-T   <p>It appears that the numerator of your proportion is correct, so you are looking at the right group of individuals. <br>However, we want to look at this <b>out of<\/b> the farmers who are {@if quest_exp=\"Male\" then \"male\" else if quest_exp=\"Female\" then \"female\" else if quest_exp=\"North\" then \"from the north village\" else if quest_exp=\"South\" then \"from the south village\"@}.<\/p>   -  0   2  prt1-2-F       2  wrong denominator  AlgEquiv  ans1  node3_error   0  +  0   -1  prt1-3-T   <p>It appears that the numerator of your proportion is correct, so you are looking at the right group of individuals. <br>However, we want to look at this <b>out of<\/b> the farmers who are {@if quest_exp=\"Male\" then \"male\" else if quest_exp=\"Female\" then \"female\" else if quest_exp=\"North\" then \"from the north village\" else if quest_exp=\"South\" then \"from the south village\"@}.<\/p>   -  0   3  prt1-3-F       3  wrong numerator  AlgEquiv  ans1  node4_error   0  +  0   -1  prt1-4-T   <p>It appears that the numerator of your proportion is not quite correct. <br>We want to look at for individuals who are both {@if quest_exp=\"Male\" then \"male\" else if quest_exp=\"Female\" then \"female\" else if quest_exp=\"North\" then \"from the north village\" else if quest_exp=\"South\" then \"from the south village\"@} <b>and<\/b> use variety {@quest_var@}.<\/p>   -  0   4  prt1-4-F       4  wrong numerator  AlgEquiv  ans1  node5_error   0  +  0   -1  prt1-5-T   <p>It appears that the numerator of your proportion is not quite correct. <br>We want to look at for individuals who are both {@if quest_exp=\"Male\" then \"male\" else if quest_exp=\"Female\" then \"female\" else if quest_exp=\"North\" then \"from the north village\" else if quest_exp=\"South\" then \"from the south village\"@} <b>and<\/b> use variety {@quest_var@}.<\/p>   -  0   5  prt1-5-F       5  other mistake  AlgEquiv  ans1  node6_error   0  +  0   -1  prt1-6-T   <p>Not quite. Have a think about the pivot table. We want to have a 2x2 table with {@quest_form@} by variety.<\/p>   -  0   -1  prt1-6-F       6  Classify cases where answer is rounded percentage  AlgEquiv  rounded_percentage_check  1   0  +  0   7  prt1-7-T     -  0   1  prt1-7-F       7  exact percentage  AlgEquiv  100*ans1  decimalplaces(float(ta_1)*100,0)   1  +  0.9   -1  prt1-8-T   <p>You gave your answer correctly as a rounded percentage. However, you were asked for the proportion.<\/p>   -  0   8  prt1-8-F       8  close percentage  NumAbsolute  100*ans1  decimalplaces(float(ta_1)*100,0)  1  1  +  0.5   -1  prt1-9-T   <p>It appears that you gave your answer as a rounded percentage while you were asked for the proportion. Additionally, and the rounding is not quite right.<\/p>   -  0   9  prt1-9-F   <p>It appears that you attempted to give your answer as a rounded percentage while you were asked for the proportion. <br>Therefore the denominator of your fraction should be the number of rows in the dataset.<\/p>     9  checks for decimalplaces  AlgEquiv  ans1  float(ta_1)   0  =  0.25   -1  prt1-10-T     -  0   -1  prt1-10-F        prt2  1.0000000  1  1   \/* wrong denominator *\/ node2_error: no_quest_exp_and_var\/number_rows; node3_error: no_quest_exp_and_var\/no_quest_exp_only; \/* wrong numerator *\/ node4_error: no_quest_var_only\/number_rows; node5_error: no_quest_exp_only\/number_rows; \/* other mistake *\/ node6_error: no_quest_var_only\/no_quest_exp_only; \/*answer as rounded percentage?*\/ simp:false; rounded_percentage_check:if denom(ans2)=100 then 1 else 0; simp:true;    0  check correct answer  AlgEquiv  ans2  ta_2   0  =  1   -1  prt2-1-T     =  0   6  prt2-1-F       1  wrong denominator  AlgEquiv  ans2  node2_error   0  +  0   -1  prt2-2-T   <p>It appears that the numerator of your proportion is correct, so you are looking at the right group of individuals. However, we want to look at this <b>out of<\/b> the farmers who planted variety {@quest_var@}.<\/p>   -  0   2  prt2-2-F       2  wrong denominator  AlgEquiv  ans2  node3_error   0  +  0   -1  prt2-3-T   <p>It appears that the numerator of your proportion is correct, so you are looking at the right group of individuals. However, we want to look at this <b>out of<\/b> the farmers who planted variety {@quest_var@}.<\/p>   -  0   3  prt2-3-F       3  wrong numerator  AlgEquiv  ans2  node4_error   0  +  0   -1  prt2-4-T   <p>It appears that the numerator of your proportion is not quite correct. We want to look at for individuals who are both {@if quest_exp=\"Male\" then \"male\" else if quest_exp=\"Female\" then \"female\" else if quest_exp=\"North\" then \"from the north village\" else if quest_exp=\"South\" then \"from the south village\"@} <b>and<\/b> use variety {@quest_var@}.<\/p>   -  0   4  prt2-4-F       4  wrong numerator  AlgEquiv  ans2  node5_error   0  +  0   -1  prt2-5-T   <p>It appears that the numerator of your proportion is not quite correct. We want to look at for individuals who are both {@if quest_exp=\"Male\" then \"male\" else if quest_exp=\"Female\" then \"female\" else if quest_exp=\"North\" then \"from the north village\" else if quest_exp=\"South\" then \"from the south village\"@} <b>and<\/b> use variety {@quest_var@}.<\/p>   -  0   5  prt2-5-F       5  other mistake  AlgEquiv  ans2  node6_error   0  +  0   -1  prt2-6-T   <p>Not quite. Have a think about the pivot table. We want to have a 2x2 table with {@quest_form@} by variety.<\/p>   -  0   -1  prt2-6-F       6  Classify cases where answer is rounded percentage  AlgEquiv  rounded_percentage_check  1   0  +  0   7  prt2-7-T     -  0   1  prt2-7-F       7  exact percentage  AlgEquiv  100*ans2  decimalplaces(float(ta_2)*100,0)   1  +  0.9   -1  prt2-8-T   <p>You gave your answer correctly as a rounded percentage. However, you were asked for the proportion.<\/p>   -  0   8  prt2-8-F       8  close percentage  NumAbsolute  100*ans2  decimalplaces(float(ta_2)*100,0)  1  1  +  0.5   -1  prt2-9-T   <p>It appears that you gave your answer as a rounded percentage while you were asked for the proportion. Additionally, and the rounding is not quite right.<\/p>   -  0   -1  prt2-9-F   <p>It appears that you attempted to give your answer as a rounded percentage while you were asked for the proportion. <br>Therefore the denominator of your fraction should be the number of rows in the dataset.<\/p>      prt3  1.0000000  1  1   \/* wrong denominator *\/ node2_error: no_quest_exp_and_var\/no_quest_var_only; node3_error: no_quest_exp_and_var\/no_quest_exp_only; \/* wrong numerator *\/ node4_error: no_quest_var_only\/number_rows; node5_error: no_quest_exp_only\/number_rows; \/* other mistakes *\/ node6_error: no_quest_exp_only\/no_quest_var_only; node7_error: no_quest_var_only\/no_quest_exp_only; \/*answer as rounded percentage?*\/ simp:false; rounded_percentage_check:if denom(ans1)=100 then 1 else 0; simp:true;    0  check correct answer  AlgEquiv  ans3  ta_3   0  =  1   -1  prt3-1-T   <p>The question is essentially asking for the fraction of individuals from {@if quest_exp=\"Male\" then \"male\" else if quest_exp=\"Female\" then \"female\" else if quest_exp=\"North\" then \"from the north village\" else if quest_exp=\"South\" then \"from the south village\"@} and planting Variety {@quest_var@} by dividing their number by the number of rows in the data set \\(={@ta_3@}\\) <\/p>   =  0   7  prt3-1-F       1  wrong denominator  AlgEquiv  ans3  node2_error   0  +  0   -1  prt3-2-T   <p>It appears that the numerator of your proportion is correct, so you are looking at the right group of individuals. However, we want to look at this <b>out of<\/b> all the farmers.<\/p>   -  0   2  prt3-2-F       2  wrong denominator  AlgEquiv  ans3  node3_error   0  +  0   -1  prt3-3-T   <p>It appears that the numerator of your proportion is correct, so you are looking at the right group of individuals. However, we want to look at this <b>out of<\/b> all the farmers.<\/p>   -  0   3  prt3-3-F       3  wrong numerator  AlgEquiv  ans3  node4_error   0  +  0   -1  prt3-4-T   <p>It appears that the numerator of your proportion is not quite correct. We want to look at for individuals who are both {@if quest_exp=\"Male\" then \"male\" else if quest_exp=\"Female\" then \"female\" else if quest_exp=\"North\" then \"from the north village\" else if quest_exp=\"South\" then \"from the south village\"@} <b>and<\/b> use variety {@quest_var@}.<\/p>   -  0   4  prt3-4-F       4  wrong numerator  AlgEquiv  ans3  node5_error   0  +  0   -1  prt3-5-T   <p>It appears that the numerator of your proportion is not quite correct. We want to look at for individuals who are both {@if quest_exp=\"Male\" then \"male\" else if quest_exp=\"Female\" then \"female\" else if quest_exp=\"North\" then \"from the north village\" else if quest_exp=\"South\" then \"from the south village\"@} <b>and<\/b> use variety {@quest_var@}.<\/p>   -  0   5  prt3-5-F       5  other mistakes  AlgEquiv  ans3  node6_error   0  +  0   -1  prt3-6-T   <p>Not quite. Have a think about the pivot table. We want to have a 2x2 table with {@quest_form@} by variety.<\/p>   -  0   6  prt3-6-F       6  other mistakes  AlgEquiv  ans3  node7_error   0  +  0   -1  prt3-7-T   <p>Not quite. Have a think about the pivot table. We want to have a 2x2 table with {@quest_form@} by variety.<\/p>   -  0   -1  prt3-7-F       7  Classify cases where answer is rounded percentage  AlgEquiv  rounded_percentage_check  1   0  +  0   8  prt3-8-T     -  0   1  prt3-8-F       8  exact percentage  AlgEquiv  100*ans3  decimalplaces(float(ta_3)*100,0)   1  +  0.9   -1  prt3-9-T   <p>You gave your answer correctly as a rounded percentage. However, you were asked for the proportion.<\/p>   -  0   9  prt3-9-F       9  close percentage  NumAbsolute  100*ans3  decimalplaces(float(ta_3)*100,0)  1  1  +  0.5   -1  prt3-10-T   <p>It appears that you gave your answer as a rounded percentage while you were asked for the proportion. Additionally, and the rounding is not quite right.<\/p>   -  0   -1  prt3-10-F   <p>It appears that you attempted to give your answer as a rounded percentage while you were asked for the proportion. <br>Therefore the denominator of your fraction should be the number of rows in the dataset.<\/p>     1177705686  1869894104  2099431645  1401350002  1309508461  791681937  1911896793  410931084  835612872  691372427  612924321  1701751675  218211428  2040613227  2117694960  2130360777  639571339  61514645  1004453818  1073641119  1251764276  1104149951  2116463331  159293109  861216255  1647883001  2101950508  176076653  658044513  125904139  1199501157  1667670667  2012974973  630993233  1834854489  1662004458  503126214  1330432592  1104541205  167769226   1  Test case assuming the teacher's input gets full marks.   ans1  ta_1    ans2  ta_2    ans3  ta_3    prt1  1.0000000  0.0000000  prt1-1-T    prt2  1.0000000  0.0000000  prt2-1-T    prt3  1.0000000  0.0000000  prt3-1-T         Filtering to Clean        Filtering to Clean    <p>A survey was conducted, involving 100 farmers, wherein they were provided with a questionnaire. The dataset contains information on three key variables resulting from this simulated survey: Age, Variety, and Yield. <\/p> <p><a href=\"[[textdownload name=\"data.csv\"]]{@stack_csv_formatter(data,factor_names)@}[[\/textdownload]]\">Download Data<\/a><\/p> <br> <p>To look at this data, we would like to know if younger or older farmers plant different varieties, and get different yields as a consequence. But to do that, we need to make sure that we are getting the right information. Before we can ask our question, we need to look at the variables. So the purpose of these questions are to check we are ready for analysis. We suggest using filtering techniques to clean the dataset to address the following questions.<\/p> <br> <p>1. What is the mean yield of this data set? <br>Give your answer to the nearest whole number.<\/p> <p>[[input:ans1]] [[validation:ans1]]<\/p> <p>[[feedback:prt1]]<\/p> <br> <p>2. What is the mean age of the farmers in this data set? <br>Give your answer to 2 decimal place.<\/p> <p>[[input:ans2]] [[validation:ans2]]<\/p> <p>[[feedback:prt2]]<\/p> <br> <p>3. How many farmers plant the {@quest3_option@} variety?<\/p> <p>[[input:ans3]] [[validation:ans3]]<\/p> <p>[[feedback:prt3]]<\/p> <br> <p>4. Does the age of the farmer have an effect on the yield?<\/p> <p>[[input:ans4]] [[validation:ans4]]<\/p> <p>[[feedback:prt4]]<\/p>      1  0.1  0    2025073100    \/* ------------- INFORMATION FROM QUESTION AUTHORS *\/ \/* [Factor name, data generation type, data generation info] *\/ \/* Factor name is given as a string *\/ \/* Data generation type is one from the list below. The generation info is given as a list and contains information both for calculating the correct randomized values which the data should take and the possible errors which can occur in the data: For qualitative data, possible errors are given in a list of the actual error value For quantitative data, possible errors are given in a list of formulae which can be applied to the correct values (these formula may of course be simply constant values!) The desired number of errors should also be given, each possible error in the list is then applied with equal probability *\/ \/* 1. \"Option from list\", [ [\"Option 1\", *probability 1*, errors list], [\"Option 2\", *probability 2*, errors list], ..., *number of errors* ] 2. \"Integer in range\", [ *lower bound*, *upper bound*, *mean* (need to add this functionality), error formulae list, *number of errors* ] 3. \"Sequential index\", [ *start value*, error formulae list, *number of errors* ] 4. \"Normal distribution\", [ *mean*, *standard deviation*, error formulae list, *number of errors* ] *\/ factor_info: [ [\"ID\", \"Sequential index\", [1, [], 0] ], [\"Sex\", \"Option from list\", [ [\"Male\", 0.5, [\"M\", \"m\", \"male\", \"man\"]], [\"Female\", 0.5, [\"F\", \"f\", \"female\", \"woman\", \"fem\", \"femelle\"]], rand_with_step(20,40,1) ]], [\"Age\", \"Integer in range\", [18, 65, 30, [2023-x], 1] ], [\"Variety\", \"Option from list\", [ [\"New\", 0.5, [\"N\", \"n\", \"new\", \"Nouveau\", \"nouveau\", \"nouv.\"]], [\"Traditional\", 0.5, [\"T\", \"t\", \"traditional\", \"Traditionnelle\", \"traditionnelle\", \"trad.\"]], rand_with_step(20,40,1) ]], [\"Yield\", \"Normal distribution\", [40000, 10000, [-x], 1] ] ]; \/* Dataset dimensions *\/ number_rows: 100; \/* ------------- END AUTHOR INFO *\/ \/* ------------- DATA SET GENERATION *\/ column_data: []; \/* Useful variables *\/ number_factors: length(factor_info); factor_names: makelist(factor_info[i][1], i, 1, number_factors); row_list: makelist(i, i, 1, number_rows); \/* Generate data for each factor *\/ for factor in factor_info do block( \/* \"Option from list\" factor type *\/ if factor[2] = \"Option from list\" then block( \/* Extract important information *\/ number_options: length(factor[3])-1, option_values: makelist(factor[3][i][1], i, 1, number_options), option_probabilities: makelist(factor[3][i][2], i, 1, number_options), option_errors: makelist(factor[3][i][3], i, 1, number_options), number_errors: last(factor[3]), factor_data: [], \/* Generate randomised correct values *\/ \/* Assign each option in the list a interval in [0,1] of length equal to the associated probability *\/ value_prob_ranges: makelist( [sum(option_probabilities[j], j, 1, i-1), sum(option_probabilities[j], j, 1, i)], i, 1, number_options ), \/* Randomise choice of option by generating a number in [0,1] and determining in which interval it falls *\/ for i: 1 thru number_rows step 1 do block( rn: rand(1.0), for j: 1 thru number_options step 1 do block( if value_prob_ranges[j][1] <= rn and rn < value_prob_ranges[j][2] then factor_data: append(factor_data, [option_values[j]]) ) ), \/* Introduce random errors in random positions *\/ error_rows: sort(rand_selection(row_list, number_errors)), for i: 1 thru number_errors step 1 do block( for j: 1 thru number_options do block( if factor_data[error_rows[i]] = option_values[j] then (factor_data[error_rows[i]]: rand(option_errors[j])) ) ) ) \/* \"Integer in range\" factor type *\/ else if factor[2] = \"Integer in range\" then block( \/* Extract important information *\/ option_errors: factor[3][4], number_errors: factor[3][5], \/* Generate randomised correct values *\/ factor_data: makelist(rand_with_step(factor[3][1], factor[3][2], 1), i, 1, number_rows), \/* Introduce random errors in random positions *\/ error_rows: sort(rand_selection(row_list, number_errors)), for i: 1 thru number_errors step 1 do ( factor_data[error_rows[i]]: ev(rand(option_errors), x=factor_data[error_rows[i]]) ) ) \/* \"Sequential index\" factor type *\/ else if factor[2] = \"Sequential index\" then block( \/* Extract important information *\/ option_errors: factor[3][2], number_errors: factor[3][3], \/* Generate randomised correct values *\/ factor_data: makelist(factor[3][1] - 1 + i, i, 1, number_rows), \/* Introduce random errors in random positions *\/ error_rows: sort(rand_selection(row_list, number_errors)), for i: 1 thru number_errors step 1 do ( factor_data[error_rows[i]]: ev(rand(option_errors), x=factor_data[error_rows[i]]) ) ) \/* \"Normal distribution\" factor type *\/ else if factor[2] = \"Normal distribution\" then block( \/* Extract important information *\/ option_errors: factor[3][3], number_errors: factor[3][4], \/* Generate randomised correct values *\/ factor_data: makelist(ceiling(random_normal(factor[3][1], factor[3][2])), i, 1, number_rows), \/* Introduce random errors in random positions *\/ error_rows: sort(rand_selection(row_list, number_errors)), for i: 1 thru number_errors step 1 do ( factor_data[error_rows[i]]: ev(rand(option_errors), x=factor_data[error_rows[i]]) ) ), \/* Append data for each factor to the dataset *\/ column_data: append(column_data, [factor_data]) ); \/* Rotate the data to be given in rows rather than columns of each factor, also add header row *\/ data: makelist(makelist(column_data[j][i], j, 1, number_factors), i, 1, number_rows); data_set: append([factor_names], data); \/* ------------- OTHER QUESTION VARIABLES *\/ \/* question 1 *\/ yield_list: last(column_data); mean_yield_with_errors: mean(yield_list); mean_yield_ignoring_errors: mean(sublist(yield_list, lambda([x], is(x>0)))); mean_yield_correcting_errors: mean(create_list(abs(x), x, yield_list)); \/* question 2 *\/ age_list: column_data[3]; mean_age_with_errors: mean(age_list); mean_age_ignoring_errors: mean(sublist(age_list, lambda([x], is(x<100)))); mean_age_correcting_errors: mean(create_list(block(if x<100 then return(x) else return(2023-x)), x, age_list)); \/* question 3 *\/ quest3_option: rand({\"new\", \"traditional\"}); variety_list: column_data[4]; \/* Lists of \"correct\" variety labels and \"alternate\"\/\"erroneous\" labels names *\/ corr_names: if quest3_option=\"new\" then [\"New\", \"new\"] else [\"Traditional\", \"traditional\"]; alt_names: if quest3_option=\"new\" then delete(\"new\", factor_info[4][3][1][3]) else delete(\"traditional\", factor_info[4][3][2][3]); \/* Number of instances of each variety label in the data set *\/ corr_names_count: create_list(length(sublist(variety_list, lambda([y], is(y=x)))), x, corr_names); tot_corr_names_count: corr_names_count[1] + corr_names_count[2]; alt_names_count: create_list(length(sublist(variety_list, lambda([y], is(y=x)))), x, alt_names); \/* Different counts the student could achieve taking different subsets of the correct\/alternate labels *\/ number_corr_names: [ \/* Capitalised correct labels only *\/ corr_names_count[1], \/* All correct labels (capitalised and lower case) *\/ tot_corr_names_count ]; number_some_alt_names: append( \/* All correct labels + any individual alternate label*\/ makelist(tot_corr_names_count + x, x, alt_names_count), \/* All correct labels + any one of letter labels, French labels or abbreviated labels *\/ [tot_corr_names_count + alt_names_count[1] + alt_names_count[2], tot_corr_names_count + alt_names_count[3] + alt_names_count[4], tot_corr_names_count + alt_names_count[5]], \/* All correct labels + any two of the above catagories *\/ [tot_corr_names_count + alt_names_count[1] + alt_names_count[2] + alt_names_count[3] + alt_names_count[4], tot_corr_names_count + alt_names_count[1] + alt_names_count[2] + alt_names_count[5], tot_corr_names_count + alt_names_count[3] + alt_names_count[4] + alt_names_count[5]] ); number_all_alt_names: tot_corr_names_count + alt_names_count[1] + alt_names_count[2] + alt_names_count[3] + alt_names_count[4] + alt_names_count[5]; \/* Plotting the age of the farmers against the yield *\/ corr_age_list: create_list(block(if x<100 then return(x) else return(2023-x)), x, age_list); corr_yield_list: create_list(abs(x), x, yield_list); age_yield_plot: makelist([corr_age_list[i], corr_yield_list[i]], i, 1, number_rows);       <p>1. What is the mean yield of this data set? <br>{@float(mean_yield_correcting_errors)@}<\/p> <p>2. What is the mean age of the farmers in this data set? <br>{@float(mean_age_correcting_errors)@}<\/p> <p>3. How many farmers plant the {@quest3_option@} variety? <br>{@number_all_alt_names@}<\/p> <p>4. Does the age of the farmer have an effect on the yield? <br>\"No\"<\/p>    <p id=\"author\">Dan Kelly<\/p> <p id=\"concept\">https:\/\/docs.google.com\/document\/d\/1lzEC4BPdzj3r6J2DFvEc4hBK3BOt6cCz4jrC4c1NWac\/edit?usp=drive_link<\/p> <p id=\"reviewer\"><\/p> <p id=\"description\"><\/p>   1  0  0   <span style=\"font-size: 1.5em; color:green;\"><i class=\"fa fa-check\"><\/i><\/span> Correct answer, well done.    <span style=\"font-size: 1.5em; color:orange;\"><i class=\"fa fa-adjust\"><\/i><\/span> Your answer is partially correct.    <span style=\"font-size: 1.5em; color:red;\"><i class=\"fa fa-times\"><\/i><\/span> Incorrect answer.   .  *10  none  1  i  cos-1  lang  [  0    ans1  algebraic  decimalplaces(mean_yield_correcting_errors,0)  15  1  0   0    0  0  0  1  3     ans2  algebraic  decimalplaces(mean_age_correcting_errors,2)  15  1  0   0    0  0  0  1  3     ans3  algebraic  number_all_alt_names  15  1  0   0    1  0  0  1  3     ans4  dropdown  [[\"Yes\", false], [\"No\", true]]  15  1  0   0    1  0  0  0  0     prt1  1.0000000  1  1      0  Gives mean yield with the errors  NumAbsolute  ans1  mean_yield_with_errors  1  0  =  0   -1  prt1-1-T   <p>Close, but you haven’t properly cleaned the yield variable. Have a look at the options in filtering to try and detect any incorrect values!<\/p>   =  0   -1  prt1-1-F       1  Ignores the erroneous values and gives mean yield  NumAbsolute  ans1  mean_yield_ignoring_errors  1  0  =  1   -1  prt1-2-T   <p>Great! You have successfully cleaned the yield variable. <br>If you can justify removing the incorrect value, then this is great - but in reality it is good practice to double check back with the surveyors, or other members who may know before changing a value. This can include the individual interviewed.<\/p>   -  0   2  prt1-2-F       2  Corrects the erroneous values and gives mean  NumAbsolute  ans1  mean_yield_correcting_errors  1  0  =  1   -1  prt1-3-T   <p>Great! You have successfully cleaned the yield variable. <br>If you can justify making the negative value as positive, then this is great - but in reality it is good practice to double check back with the surveyors, or other members who may know before changing a value. This can include the individual interviewed.<\/p>   -  0   0  prt1-3-F        prt2  1.0000000  1  1      0  Gives mean age with the errors  NumAbsolute  ans2  mean_age_with_errors  0.01  0  =  0   -1  prt2-1-T   <p>Close, but you haven’t properly cleaned the age variable. Have a look at the options in filtering to try and detect any incorrect values!<\/p>   =  0   -1  prt2-1-F       1  Ignores the erroneous values and gives mean yield  NumAbsolute  ans2  mean_age_ignoring_errors  0.01  0  =  1   -1  prt2-2-T   <p>Great! You have successfully cleaned the age variable. <br>It looks like you found that one individual gave a very high value, and set it as NA. If you can justify this, then this is great - but in reality it is good practice to double check back with the surveyors, or other members who may know before changing a value. This can include the individual interviewed; is it possible to follow up in case they gave their birth year not their age?<\/p>   -  0   2  prt2-2-F       2  Corrects the erroneous values and gives mean  NumAbsolute  ans2  mean_age_correcting_errors  0.01  0  =  1   -1  prt2-3-T   <p>Great! You have successfully cleaned the age variable. <br>It looks like you assumed one individual gave their year of birth not their age. If you can justify this, then this is great - but in reality it is good practice to double check back with the surveyors, or other members who may know before changing a value. This can include the individual interviewed.<\/p>   -  0   0  prt2-3-F        prt3  1.0000000  1  1   \/* node 1 *\/ node1_test: if member(ans3, number_corr_names) then 1 else 0; \/* node 2 *\/ node2_test: if member(ans3, number_some_alt_names) then 1 else 0;    0  Gives number without considering error values  AlgEquiv  node1_test  1   0  =  0   -1  prt3-1-T   <p>Close, but you haven’t properly cleaned the variety variable. Have a look at the options in filtering to try and detect any incorrect values.<\/p>   =  0   -1  prt3-1-F       1  Gives number considering some error values  AlgEquiv  node2_test  1   0  =  0.5   -1  prt3-2-T   <p>Close, but you haven’t properly cleaned the variety variable. Have a look at the options in filtering to try and detect any incorrect values.<\/p>   -  0   0  prt3-2-F       2  Gives number considering all error values  AlgEquiv  ans3  number_all_alt_names   0  =  1   -1  prt3-3-T   <p>Great! You have successfully cleaned the variety variable and found the correct number of individuals who plant that variety.<\/p>   -  0   1  prt3-3-F        prt4  1.0000000  1  1      0  Correct answer is \"No\"  AlgEquiv  ans4  \"No\"   0  =  1   -1  prt4-1-T   <p>Correct. In this simulated data, there was no effect. Any observed effect is just due to chance.<\/p> <p>To see this, you can consider a scatter plot of the data, below we have the age of the farmers on the \\(x\\)-axis and the yield on the \\(y\\)-axis.<\/p> <br> <p style=\"margin-left:30px\">{@ plot( [discrete, age_yield_plot], [x,0,70], [xlabel,\"Age\"], [y,0,ceiling(last(sort(corr_yield_list))\/10000)*10000], [ylabel,\"Yield\"], [style, [points, 2]], [point_type, asterisk], [plottags,false] ) @}<\/p>   =  0   -1  prt4-1-F   <p>In this simulated data, there was no effect. Any observed effect is just due to chance.<\/p> <p>To see this, you can consider a scatter plot of the data, below we have the age of the farmers on the \\(x\\)-axis and the yield on the \\(y\\)-axis.<\/p> <br> <p style=\"margin-left:30px\">{@ plot( [discrete, age_yield_plot], [x,0,70], [xlabel,\"Age\"], [y,0,ceiling(last(sort(corr_yield_list))\/10000)*10000], [ylabel,\"Yield\"], [style, [points, 2]], [point_type, asterisk], [plottags,false] ) @}<\/p>     1380901209  222344047  286706238  806083264  1752894148  173097596  1237847435  1380091418  120293376  1025989901  1686933893  1763901196  459626713  770256681  1570466202   1  Test case assuming the teacher's input gets full marks.   ans1  decimalplaces(mean_yield_correcting_errors,0)    ans2  decimalplaces(mean_age_correcting_errors,2)    ans3  number_all_alt_names    ans4  first(mcq_correct([[\"Yes\", false], [\"No\", true]]))    prt1  1.0000000  0.0000000  prt1-3-T    prt2  1.0000000  0.0000000  prt2-3-T    prt3  1.0000000  0.0000000  prt3-3-T    prt4  1.0000000  0.0000000  prt4-1-T         Appending Data   This question uses a fixed external data set, converted to csv using custom Javascript within the STACK question. This is currently not supported in our PreText implementation; thus this question doesn't work here.        Appending Data    <p>Rainfall data were taken in two regions in Ghana: Elamat and Palstond. However, the data has been collected into two data frames: one contains data from 1990-1999, and the other from 2000-2016.<\/p> <p>The former data set contains the station name, the date, year, rainfall (mm), minimum temperature (Celsius), and maximum temperature (Celsius).<\/p> <p>The latter data set contains the station name, date, year, rainfall (cm), minimum temperature (Celsius), and maximum temperature (Celsius), and hours of sunshine.<\/p> <p>The task is to combine the data sets and answer the following questions: <br><em>(Note that this is “made up” data)<\/em><\/p> <p><button onclick=\"exportToCsv1990()\">Download Data: 1990-1999<\/button><\/p> <p><button onclick=\"exportToCsv2000()\">Download Data: 2000-2016<\/button><\/p> <br> <p>1. Which year had the least overall rainfall?<\/p> <p>[[input:ans1]] [[validation:ans1]]<\/p> <br> <p>2. Which region had more rainfall between 1990-2016 (inclusive)?<\/p> <p>[[input:ans2]] [[validation:ans2]]<\/p> <br> <p>3. How much rainfall was there in total across both stations in 2016 in \\(mm\\)?<\/p> <br><em>Give your answer to 2 decimal places.<\/em><\/p> <p>[[input:ans3]] [[validation:ans3]]<\/p> <p>[[feedback:prt1]]<\/p> <script> var Results1990; var Results2000; fetch(\"https:\/\/raw.githubusercontent.com\/IDEMSInternational\/wxmaxima-stack\/main\/data-files\/ghana-1990-1999.txt\") .then(res => res.json()) .then(data => { Results1990 = data; }) fetch(\"https:\/\/raw.githubusercontent.com\/IDEMSInternational\/wxmaxima-stack\/main\/data-files\/ghana-2000-2016.txt\") .then(res => res.json()) .then(data => { Results2000 = data; }) exportToCsv1990 = function(file_name) { var CsvString = \"\"; Results1990.forEach(function(RowItem, RowIndex) { RowItem.forEach(function(ColItem, ColIndex) { CsvString += ColItem; if( ColIndex < RowItem.length - 1){ CsvString += ','; } }); CsvString += \"\\r\\n\"; }); CsvString = \"data:application\/csv,\" + encodeURIComponent(CsvString); var x = document.createElement(\"A\"); x.setAttribute(\"href\", CsvString ); x.setAttribute(\"download\",\"data_set.csv\"); document.body.appendChild(x); x.click(); } exportToCsv2000 = function(file_name) { var CsvString = \"\"; Results2000.forEach(function(RowItem, RowIndex) { RowItem.forEach(function(ColItem, ColIndex) { CsvString += ColItem; if( ColIndex < RowItem.length - 1){ CsvString += ','; } }); CsvString += \"\\r\\n\"; }); CsvString = \"data:application\/csv,\" + encodeURIComponent(CsvString); var x = document.createElement(\"A\"); x.setAttribute(\"href\", CsvString ); x.setAttribute(\"download\",\"data_set.csv\"); document.body.appendChild(x); x.click(); } <\/script>      1  0.1  0    2025073100    ma1: [ [1990, false], [1991, false], [1992, true], [1993, false], [1994, false], [1995, false], [1996, false], [1997, false], [1998, false], [1999, false], [2000, false], [2001, false], [2002, false], [2003, false], [2004, false], [2005, false], [2006, false], [2007, false], [2008, false], [2009, false], [2010, false], [2011, false], [2012, false], [2013, false], [2014, false], [2015, false], [2016, false] ]; ma2: [ [\"Palstond\", false], [\"Elamat\", true], [\"Unknown\", false] ]; ta3: 1869.80;            1  0  0   <span style=\"font-size: 1.5em; color:green;\"><i class=\"fa fa-check\"><\/i><\/span> Correct answer, well done.    <span style=\"font-size: 1.5em; color:orange;\"><i class=\"fa fa-adjust\"><\/i><\/span> Your answer is partially correct.    <span style=\"font-size: 1.5em; color:red;\"><i class=\"fa fa-times\"><\/i><\/span> Incorrect answer.   .  *10  none  1  i  cos-1  lang  [  0    ans1  dropdown  ma1  15  1  0   0    1  0  0  0  0     ans2  dropdown  ma2  15  1  0   0    1  0  0  0  0     ans3  algebraic  ta3  15  1  0   0    0  0  0  1  3     prt1  1.0000000  1  1   \/* node 1: check answers correct *\/ node1_test: if ans1=1992 and ans2=\"Elamat\" and ans3=1869.80 then 1 else 0; \/* node 2: fails to compare the units in each question *\/ node2_test: if ans1=2013 and ans2=\"Palstond\" and ans3=186.98 then 1 else 0; \/* node 3: treats 2000-16 stations as unknown *\/ node3_test: if ans1=1992 and member(ans2, [\"Palstond\", \"Unknown\"]) and ans3=1869.80 then 1 else 0; \/* node 4: disregards the order of the columns *\/ node4_test: if ans1=2013 and ans2=\"Elamat\" and member(ans3, [1869.8, 186.98]) then 1 else 0; \/* node 5: disregards the order of the columns *\/ node5_test: if ans1=1992 and ans2=\"Palstond\" and member(ans3, [17567.7, 175677]) then 1 else 0;    0  check correct answers  AlgEquiv  node1_test  1   1  =  1   -1  prt1-1-T   <p>Great! It appears that when combining the data sets, you have taken into account the different units used! <br>In addition, it seems that you have correctly appended the data sets together. <\/p> <br> <p>There is a worked solution of this problem <a href=\"https:\/\/ecampus.idems.international\/course\/view.php?id=238&amp;section=97\">here<\/a>. <\/p>   =  0   1  prt1-1-F       1  fails to compare the units in each question  AlgEquiv  node2_test  1   1  +  0   -1  prt1-2-T   <p>It appears that when combining the data sets, you have not taken into account the different units used. <br>Have a look at a plot of your rainfall by year. Does anything seem odd here? <br>We mentioned in the initial question that rainfall is measured in cm in one data set and mm in another. <\/p> <br> <p style=\"margin-left:30px\"><img src=\"https:\/\/github.com\/IDEMSInternational\/wxmaxima-stack\/blob\/main\/data-files\/appending-data-1.jpg?raw=true\"><\/p> <br> <p>Try again, but if stuck there is a worked solution of this problem <a href=\"https:\/\/ecampus.idems.international\/course\/view.php?id=238&amp;section=97\">here<\/a>. <\/p>   -  0   2  prt1-2-F       2  treats 2000-16 stations as unknown  AlgEquiv  node3_test  1   1  +  0   -1  prt1-3-T   <p>It appears that when combining the data sets, you have taken into account the different units used, which is great! <br>However, have a look at a plot of your rainfall by year with station included. Does anything seem odd here? <br>All stations from the year 2000 are unknown. Have a look at the station variable name in the two initial data sets. Can you see why this might have happened when combining the data? <\/p> <br> <p style=\"margin-left:30px\"><img src=\"https:\/\/github.com\/IDEMSInternational\/wxmaxima-stack\/blob\/main\/data-files\/appending-data-2.jpg?raw=true\"><\/p> <br> <p>Try again, but if stuck there is a worked solution of this problem <a href=\"https:\/\/ecampus.idems.international\/course\/view.php?id=238&amp;section=97\">here<\/a>. <\/p>   -  0   3  prt1-3-F       3  disregards the order of the columns  AlgEquiv  node4_test  1   0  +  0   -1  prt1-4-T   <p>It appears that when combining the data sets, you have not taken into account the order of the columns. <br>Have a look at the data - the columns are in a different order in the two data sets. <br>We can visualise this further by a plot of rainfall by year <br>We want to put both of the data sheets together. For this we go to Prepare &gt; Data Reshape &gt; Append dialogue in R-Instat. We suggest having a look at the tutorial on merging and appending data in R-Instat. <\/p> <br> <p style=\"margin-left:30px\"><img src=\"https:\/\/github.com\/IDEMSInternational\/wxmaxima-stack\/blob\/main\/data-files\/appending-data-4.jpg?raw=true\"><\/p> <br> <p>Try again, but if stuck there is a worked solution of this problem <a href=\"https:\/\/ecampus.idems.international\/course\/view.php?id=238&amp;section=97\">here<\/a>. <\/p>   -  0   4  prt1-4-F       4  disregards the order of the columns  AlgEquiv  node5_test  1   0  +  0   -1  prt1-5-T   <p>It appears that when combining the data sets, you have not taken into account the order of the columns. <br>Have a look at the data - the columns are in a different order in the two data sets. <br>We can visualise this further by a plot of rainfall by year <br>We want to put both of the data sheets together. For this we go to Prepare &gt; Data Reshape &gt; Append dialogue in R-Instat. We suggest having a look at the tutorial on merging and appending data in R-Instat. <\/p> <br> <p style=\"margin-left:30px\"><img src=\"https:\/\/github.com\/IDEMSInternational\/wxmaxima-stack\/blob\/main\/data-files\/appending-data-3.jpg?raw=true\"><\/p> <p>Try again, but if stuck there is a worked solution of this problem <a href=\"https:\/\/ecampus.idems.international\/course\/view.php?id=238&amp;section=97\">here<\/a>. <\/p>   -  0   -1  prt1-5-F   <p>Not quite - are you looking at the <b>overall rainfall<\/b> for each year? <br>We want to put both of the data sheets together. For this we go to Prepare &gt; Data Reshape &gt; Append dialogue in R-Instat. We suggest having a look at the tutorial on merging and appending data in R-Instat. <\/p> <br> <p>Try again, but if stuck there is a worked solution of this problem <a href=\"https:\/\/ecampus.idems.international\/course\/view.php?id=238&amp;section=97\">here<\/a>. <\/p>      1  Test case assuming the teacher's input gets full marks.   ans1  first(mcq_correct(ma1))    ans2  first(mcq_correct(ma2))    ans3  ta3    prt1  1.0000000  0.0000000  prt1-1-T         Missing Values   This question uses a fixed external data set, converted to csv using custom Javascript within the STACK question. This is currently not supported in our PreText implementation; thus this question doesn't work here.        Missing Values    <p>Let's consider a survey conducted with 100 farms to gather information about their crop habits. Each farm was asked three specific questions regarding Maize, Sorghum, and Millet.<\/p> <ol> <li> Did they grow the crop last year?<\/li> <li>If yes, did the crop succeed enough to be sold?<\/li> <li>If sold, what was their profit?<\/li> <\/ol> <p><button onclick=\"exportToCsv()\">Download Data<\/button><\/p> <br> <p>Use the data provided to determine:<\/p> <p>1. &nbsp; (a) Which crop was the most profitable <strong>on average<\/strong>? <\/p><p style=\"margin-left:24px\">[[input:ans1]] [[validation:ans1]]<\/p> <p style=\"margin-left:24px\">(b) Which one was the least profitable <strong>on average<\/strong>? <\/p><p style=\"margin-left:24px\">[[input:ans2]] [[validation:ans2]]<\/p> <p>[[feedback:prt1]]<\/p> <br> <p>2. What is the mean profit for {@q2_crop@}?<\/p> <p>[[input:ans3]] [[validation:ans3]]<\/p> <p>[[feedback:prt3]]<\/p> <script> var Results; fetch(\"https:\/\/raw.githubusercontent.com\/IDEMSInternational\/wxmaxima-stack\/main\/data-files\/missing_values_1.txt\") .then(res => res.json()) .then(data => { Results = data; }) exportToCsv = function(file_name) { var CsvString = \"\"; Results.forEach(function(RowItem, RowIndex) { RowItem.forEach(function(ColItem, ColIndex) { CsvString += ColItem; if( ColIndex < RowItem.length - 1){ CsvString += ','; } }); CsvString += \"\\r\\n\"; }); CsvString = \"data:application\/csv,\" + encodeURIComponent(CsvString); var x = document.createElement(\"A\"); x.setAttribute(\"href\", CsvString ); x.setAttribute(\"download\",\"data_set.csv\"); document.body.appendChild(x); x.click(); } <\/script>      1  0.1  0    2025073100    ma_1: [[\"Sorghum\", false], [\"Millet\", true], [\"Maize\", false]]; ma_2: [[\"Sorghum\", true], [\"Millet\", false], [\"Maize\", false]]; q2_crop: rand([\"Maize\", \"Sorghum\", \"Millet\"]); ta_3: if q2_crop=\"Maize\" then 78.17708 elseif q2_crop=\"Sorghum\" then 66.15116 elseif q2_crop=\"Millet\" then 90.45833;       <p>Use the data provided to determine:<\/p> <p>1a. Which crop was the most profitable? = Sorghum<\/p> <p>1b. Which one was the least profitable? = Millet<\/p> <p>2. What is the mean profit for {@q2_crop@}? = {@ta_3@}<\/p>    <p id=\"author\">Mary Sayuni<\/p> <p id=\"concept\">https:\/\/docs.google.com\/document\/d\/1rByNEf43H7gNmyYm2Ez_O5pNMIFZPVzd0JTynd9a11M\/edit#heading=h.wvpxq8elfr9z<\/p> <p id=\"reviewer\">Dan Kelly<\/p> <p id=\"description\"><\/p>   1  0  0   <span style=\"font-size: 1.5em; color:green;\"><i class=\"fa fa-check\"><\/i><\/span> Correct answer, well done.    <span style=\"font-size: 1.5em; color:orange;\"><i class=\"fa fa-adjust\"><\/i><\/span> Your answer is partially correct.    <span style=\"font-size: 1.5em; color:red;\"><i class=\"fa fa-times\"><\/i><\/span> Incorrect answer.   .  *10  none  1  i  cos-1  lang  [  0    ans1  dropdown  ma_1  10  1  0   0    1  0  0  0  0     ans2  dropdown  ma_2  10  1  0   0    1  0  0  0  0     ans3  algebraic  ta_3  10  1  0   0    0  0  0  0  0     prt1  1.0000000  1  1   node3_test: if ans1=\"Sorghum\" and ans2=\"Millet\" then 1 else 0; node4_test: if ans1=\"Sorghum\" and ans2=\"Maize\" then 1 else 0; node5_test: if ans1=\"Maize\" and ans2=\"Millet\" then 1 else 0; node6_test: if ans1=\"Maize\" and ans2=\"Sorghum\" then 1 else 0; node7_test: if ans1=\"Millet\" and ans2=\"Maize\" then 1 else 0; node8_test: if ans1=\"Millet\" and ans2=\"Sorghum\" then 1 else 0;    2  gives sorghum and millet  AlgEquiv  node3_test  1  1  0  =  0   -1  prt1-3-T   <p>It appears that all of the missing values have been ignored in this question. However, we are looking at the most profitable crop. There are some crops which were grown which were not sold. Arguably the missing values in the profit columns therefore <b>do<\/b> have a value that we can give them.<\/p> <p>Alternatively, to get this answer it is possible that you have replaced the missing values with a different value, such as the mean. What value have you replaced them with? Does that make sense in this context? The mean, for example, might not make sense here. It is not that the profit is unknown, it is that there was no money made at all.<\/p>   -  0   3  prt1-3-F       3  gives sorghum and maize  AlgEquiv  node4_test  1  1  0  =  0   -1  prt1-4-T   <p>It appears that you have correctly identified to fill in the missing values. However, check the value that you are using to replace the missing values with. Does that make sense in this context? It is not that the profit is unknown, it is that there was no money made at all.<\/p>   -  0   4  prt1-4-F       4  gives maize and millet  AlgEquiv  node5_test  1  1  0  =  0   -1  prt1-5-T   <p>It appears that one of two things has happened here. We recommend looking at the averages not the sum, this is due to a difference in group sizes.<\/p><p>Alternatively, if you are looking at averages then it is great you have identified that the missing values in the profit columns <b>do<\/b> have a value that we can give them. However, it is incorrect that <b>all<\/b> missing values have a value we can estimate. Some missing values we may simply not know at all!<\/p>   -  0   5  prt1-5-F       5  gives maize and sorghum  AlgEquiv  node6_test  1  1  0  =  0   -1  prt1-6-T   <p>It appears that you have correctly identified to fill in the missing values. However, check the value that you are using to replace the missing values with. Does that make sense in this context? It is not that the profit is unknown, it is that there was no money made at all.<\/p>   -  0   6  prt1-6-F       6  gives millet and maize  AlgEquiv  node7_test  1  1  0  =  0   -1  prt1-7-T   <p>It appears that you have correctly identified to fill in the missing values. However, check the value that you are using to replace the missing values with. Does that make sense in this context? It is not that the profit is unknown, it is that there was no money made at all.<\/p>   -  0   7  prt1-7-F       7  gives millet and sorghum  AlgEquiv  node8_test  1   0  =  1   -1  prt1-8-T   <p>It appears that you have replaced some of the missing values, but not all of them. If an individual grew a crop, but were unable to sell, they arguably do not have a profit so their missing values do have a value we can give them. If instead an individual never grew a crop, we can ignore their missing values.<\/p>   -  0   -1  prt1-8-F        prt3  1.0000000  1  1   corr_ans_list: [decimalplaces(ta_3,0), decimalplaces(ta_3,1), decimalplaces(ta_3,2), decimalplaces(ta_3,3), decimalplaces(ta_3,4), ta_3]; node1_test: if member(ans3, corr_ans_list) then 1 else 0;    0  check correct answer, possibly rounded  AlgEquiv  node1_test  1   0  =  1   -1  prt3-1-T   <p>Great! The unprofitable crops have been given a profit of zero since they were grown but generated no income.<\/p> <p>The crops that were never grown, so had no chance to generate income, have been set as missing. This is correct!<\/p>   =  0   -1  prt3-1-F   <p>You have correctly identified which missing values should be replaced. However, the value that you have replaced them with seems to be incorrect.<\/p> <p>Check what you have replaced the missing values with, does that make sense in this context? It is not that the profit is unknown, it is that there was no money made at all from some crops.<\/p>     766382234  1385186126  659133753  1821788129  1521746292  1648618228  1454693563  1625344872  1944660833  1777464209  696566202  1993916139  1169651549  1210017344  1420680205  883759535  2130767947  1804150212  883239853  996318757   1  Test case assuming the teacher's input gets full marks.   ans1  first(mcq_correct(ma_1))    ans2  first(mcq_correct(ma_2))    ans3  ta_3    prt1  1.0000000  0.0000000  prt1-8-T    prt3  1.0000000  0.0000000  prt3-1-T         Pivot Tables 1        Pivot Tables 1    <p>An experiment was performed to test the effect of two treatments on the yield. The two treatments are fertiliser and variety. There are three levels of fertiliser, and two different varieties.<\/p> <p>The task is to use the data below to answer the following questions <strong>using pivot tables<\/strong> to investigate how the treatments affect the yield.<\/p> <p><a href=\"[[textdownload name=\"data.csv\"]]{@stack_csv_formatter(data_set,header)@}[[\/textdownload]]\">Download Data<\/a><\/p> <br> <p>1. What is the {@quest_expr1@} yield obtained from the experiment? Give your answer to \\(2\\text{dp}\\)<\/p> <p>[[input:ans1]] [[validation:ans1]]<\/p> <p>[[feedback:prt1]]<\/p> <p>2. What is the {@quest_expr2@} yield for Variety \\(1\\)? Give your answer to \\(2\\text{dp}\\)<\/p> <p>[[input:ans2]] [[validation:ans2]]<\/p> <p>[[feedback:prt2]]<\/p> <p>3. What is the {@quest_expr3@} yield for Variety \\(1\\) when Fertiliser \\(1\\) is used? Give your answer to \\(2\\text{dp}\\)<\/p> <p>[[input:ans3]] [[validation:ans3]]<\/p> <p>[[feedback:prt3]]<\/p>    <p>Full details on how to create and use Pivot tables can be found <a href=\"https:\/\/docs.google.com\/document\/d\/1Q349NXt0AkStgVHHVkkDGBZVS-KT5Gl_IcdnSTemhEQ\/edit?usp=sharing\" target=\"_blank\">here<\/a>.   1  0.1  0    2025073100    \/*Information given by question authors*\/ factor_names:[\"Fertiliser\",\"Variety\"]; factors_info:[ [[0,\"Fertiliser 1\"],[5,\"Fertiliser 2\"],[7.5,\"Fertiliser 3\"]], [[0,\"Variety 1\"],[10,\"Variety 2\"]] ]; base_yield:50; error_mean:0; error_sd:5; replications:10; \/*Basic variables from inputs*\/ number_factors:length(factors_info); number_rows:product(length(factors_info[i]),i,1,length(factors_info))*replications; \/*Function to calculate the yield for a given data row*\/ \/*Input: list of coordinates for each factor*\/ \/*Output: expected yield for the given combination of factors without interactions*\/ effect_calculator(coords):=block( [ factors_info:factors_info, counter_1, effects_sum ], effects_sum:sum(factors_info[counter_1][coords[counter_1]][1],counter_1,1,length(factors_info)), return(effects_sum) ); \/*Function to create the labels for a given data row*\/ \/*Input: List of coordinates for each factor*\/ \/*Output: list of labels for the given combination of factors without interactions*\/ create_label(coords):=block( [ factors_info:factors_info, number_factors:number_factors, i, label_maker ], label_maker:makelist(factors_info[i][coords[i]][2],i,1,number_factors), return(label_maker) ); \/* Function to map position of item in list to coordinates in data list *\/ \/* Input: position of item in list, number between 1 and number_rows *\/ \/* Output: relevant coordinates in factors_info list *\/ pos_to_coords(num):=block( [factors_info:factors_info, number_factors:number_factors, number_rows:number_rows, factor_lengths, clock], factor_lengths: makelist(length(factors_info[i]),i,1,number_factors), \/* How regularly is each factor required to change value? *\/ clock:reverse(makelist( product(factor_lengths[j], j, number_factors+1-i, number_factors), i, 0, number_factors-1 )), return(makelist(mod(floor((num-1)\/clock[i]),factor_lengths[i])+1, i, 1, number_factors)) ); \/*Create the data set (all 0s) and the corresponding coordinates list*\/ data_set:makelist(makelist(0,j,1,number_factors+2),i,1,number_rows); coord_list:makelist(0,i,1,number_rows); \/*replce 0s with corresponding labels and generated yields (plus error term) using the relevant functions*\/ for i: 1 thru number_rows do ( coords: pos_to_coords(ceiling(i\/replications)), coord_list[i]: coords, yield_value: float(base_yield + effect_calculator(coords) + quantile_normal(rand(1.0),error_mean,error_sd)), label_value: create_label(coords), rep_value: if mod(i,replications) = 0 then replications else mod(i,replications), data_set[i]: append(label_value, [rep_value], [yield_value]) ); \/* Add headers row to data set *\/ header: append(factor_names, [\"Replication\", \"Yield\"]); data_set:append( [header], data_set ); \/* question 1 *\/ quest_expr1:rand([\"mean\",\"minimum\",\"maximum\"]); all_yields: makelist(data_set[i][4], i, 2, number_rows+1); ta_1: decimalplaces(if quest_expr1=\"mean\" then mean(all_yields) else if quest_expr1=\"minimum\" then first(sort(all_yields)) else if quest_expr1=\"maximum\" then last(sort(all_yields)) else if quest_expr1=\"median\" then median(all_yields), 2); \/* question 2 *\/ quest_expr2:rand([\"mean\",\"minimum\",\"maximum\"]); var1_list: sublist(data_set, lambda([x], is(x[2]=\"Variety 1\"))); var1_yields: makelist(var1_list[i][4], i, 1, length(var1_list)); ta_2: decimalplaces(if quest_expr2=\"mean\" then mean(var1_yields) else if quest_expr2=\"minimum\" then first(sort(var1_yields)) else if quest_expr2=\"maximum\" then last(sort(var1_yields)) else if quest_expr2=\"median\" then median(var1_yields), 2); \/* question 3 *\/ quest_expr3:rand([\"mean\",\"minimum\",\"maximum\"]); fert1_var1_list: sublist(var1_list, lambda([x], is(x[1]=\"Fertiliser 1\"))); fert1_var1_yields: makelist(fert1_var1_list[i][4], i, 1, length(fert1_var1_list)); ta_3: decimalplaces(if quest_expr3=\"mean\" then mean(fert1_var1_yields) else if quest_expr3=\"minimum\" then first(sort(fert1_var1_yields)) else if quest_expr3=\"maximum\" then last(sort(fert1_var1_yields)) else if quest_expr3=\"median\" then median(fert1_var1_yields), 2);       <p>What is the {@quest_expr1@} yield? Give to \\(2\\text{dp}\\) = {@ta_1@}<\/p> <p>What is the {@quest_expr2@} yield for Variety \\(1\\)? = {@ta_2@}<\/p> <p>What is the {@quest_expr3@} yield for Variety \\(1\\) when Fertiliser \\(1\\) is used? = {@ta_3@} <\/p>    <p id=\"author\">Mary Sayuni<\/p> <p id=\"concept\">https:\/\/docs.google.com\/document\/d\/1M1PSU_3ENRT4V35PLR4JsBVKLyTa6S3InVDAW4Hsqwg\/edit#heading=h.vy8x1tbmoha9<\/p> <p id=\"reviewer\">Dan Kelly<\/p> <p id=\"reviewer\"><\/p> <p id=\"description\"><\/p>   1  0  0   <span style=\"font-size: 1.5em; color:green;\"><i class=\"fa fa-check\"><\/i><\/span> Correct answer, well done.    <span style=\"font-size: 1.5em; color:orange;\"><i class=\"fa fa-adjust\"><\/i><\/span> Your answer is partially correct.    <span style=\"font-size: 1.5em; color:red;\"><i class=\"fa fa-times\"><\/i><\/span> Incorrect answer.   .  *10  dot  1  i  cos-1  lang  [  0    ans1  algebraic  ta_1  10  1  0   0    0  0  0  1  3     ans2  algebraic  ta_2  10  1  0   0    0  0  0  1  3     ans3  algebraic  ta_3  10  1  0   0    0  0  0  1  3     prt1  1.0000000  1  1   \/* node 3: check different summary statistic given *\/ all_summaries: [ decimalplaces(mean(all_yields),2), decimalplaces(first(sort(all_yields)),2), decimalplaces(last(sort(all_yields)),2), decimalplaces(median(all_yields),2) ]; node3_test: if member(ans1, all_summaries) then 1 else 0;    0  checks for correct summary  AlgEquiv  ans1  ta_1  2  1  =  1   -1  prt1-1-T   <p>You have correctly found the {@quest_expr1@} yield.<\/p>   =  0   1  prt1-1-F       1  check correct answer not to 2dp  NumAbsolute  ans1  ta_1  0.01  1  =  0.5   -1  prt1-2-T   <p>Your answer is correct, but do note that the question stated to give to \\(2\\text{dp}\\).<\/p>   -  0   2  prt1-2-F       2  check different summary statistic given  AlgEquiv  node3_test  1   1  =  0   -1  prt1-3-T   <p>Not quite, the question asking for the <b>{@quest_expr1@}<\/b> of the yield. <br>In a pivot table in Excel this can be achieved by clicking on the yield variable in the “Values” field, and selecting “Value Field Settings...”. <br>See <a href = “https:\/\/ecampus.idems.international\/course\/view.php?id=238&section=38”>here<\/a> for an example in Excel.<\/p>   -  0   -1  prt1-3-F   <p>Not quite. This can be achieved in spreadsheet software with PivotTables quite nicely. <br>For example, see <a href = “https:\/\/ecampus.idems.international\/course\/view.php?id=238&section=38”>here<\/a> how to set up PivotTables in Excel. <br>Here, we have just one variable, Yield, that we want to look at the summary of. So we just have to enter “Yield” into the “Value” box, and select the appropriate statistic.<\/p>      prt2  1.0000000  1  1   \/* node 3: check different summary statistic given *\/ all_var1_summaries: [ decimalplaces(mean(var1_yields),2), decimalplaces(first(sort(var1_yields)),2), decimalplaces(last(sort(var1_yields)),2), decimalplaces(median(var1_yields),2) ]; node3_test: if member(ans1, all_var1_summaries) then 1 else 0; \/* node 4: check summary statistic taken over all data *\/ node4_mist: decimalplaces(if quest_expr2=\"mean\" then mean(all_yields) else if quest_expr2=\"minimum\" then first(sort(all_yields)) else if quest_expr2=\"maximum\" then last(sort(all_yields)) else if quest_expr2=\"median\" then median(all_yields), 2);    0  checks for correct summary of variety 1  AlgEquiv  ans2  ta_2  2  0  =  1   -1  prt2-1-T   <p>You have correctly found the {@quest_expr2@} yield for variety \\(1\\).<\/p>   =  0   1  prt2-1-F       1  checks for correct answer not to 2dp  NumAbsolute  ans1  ta_2  0.01  0  =  0.5   -1  prt2-2-T   <p>Your answer is correct, but do note that the question stated to give to \\(2\\text{dp}\\).<\/p>   -  0   2  prt2-2-F       2  check different summary statistic given  AlgEquiv  node3_test  1   0  =  0   -1  prt2-3-T   <p>Not quite, the question asking for the <b>{@quest_expr2@}<\/b> of the yield. <br>In a pivot table in Excel this can be achieved by clicking on the yield variable in the “Values” field, and selecting “Value Field Settings...”. <br>See <a href = “https:\/\/ecampus.idems.international\/course\/view.php?id=238&section=38”>here<\/a> for an example in Excel.<\/p>   -  0   3  prt2-3-F       3  check for summary yield of all data  AlgEquiv  ans2  node4_mist   0  +  0   -1  prt2-4-T   <p>Close, you have correctly found the {@quest_expr2@} yield overall. But we want to look at just for variety \\(1\\). <br>This could be achieved by using the “Filter”, “Rows”, or “Columns” field if you put the \"Variety\" variable in it.<\/p>   -  0   -1  prt2-4-F   <p>Not quite. This can be achieved in spreadsheet software with PivotTables quite nicely. <br>For example, see <a href = “https:\/\/ecampus.idems.international\/course\/view.php?id=238&section=38”>here<\/a> how to set up PivotTables in Excel. <br>Here,\"Variety\" variable needs to be dragged into either rows or columns because we are interested in the maximum yield for Variety 1. we have just one variable, Yield, that we want to look at the summary of. So we just have to enter “Yield” into the “Value” box, and select the appropriate statistic.<\/p>      prt3  1.0000000  1  1   \/* node 3: check different summary statistic given *\/ all_fert1_var1_summaries: [ decimalplaces(mean(fert1_var1_yields),2), decimalplaces(first(sort(fert1_var1_yields)),2), decimalplaces(last(sort(fert1_var1_yields)),2), decimalplaces(median(fert1_var1_yields),2) ]; node3_test: if member(ans1, all_fert1_var1_summaries) then 1 else 0; \/* node 4: check summary statistic taken over all data *\/ node4_mist: decimalplaces(if quest_expr3=\"mean\" then mean(all_yields) else if quest_expr3=\"minimum\" then first(sort(all_yields)) else if quest_expr3=\"maximum\" then last(sort(all_yields)) else if quest_expr3=\"median\" then median(all_yields), 2); \/* node 5: check for statistics of variety 1 with fertiliser 2 *\/ fert2_var1_list: sublist(var1_list, lambda([x], is(x[1]=\"Fertiliser 2\"))); fert2_var1_yields: makelist(fert1_var1_list[i][4], i, 1, length(fert2_var1_list)); node5_mist: decimalplaces(if quest_expr3=\"mean\" then mean(fert2_var1_yields) else if quest_expr3=\"minimum\" then first(sort(fert2_var1_yields)) else if quest_expr3=\"maximum\" then last(sort(fert2_var1_yields)) else if quest_expr3=\"median\" then median(fert2_var1_yields), 2);    0  checks for correct summary of variety 1 with fertiliser 1  NumDecPlaces  ans3  ta_3  2  0  =  1   -1  prt3-1-T   <p>You have correctly found the {@quest_expr3@} yield for variety \\(1\\) with fertiliser \\(1\\).<\/p>   =  0   1  prt3-1-F       1  checks for correct answer not to 2dp  NumAbsolute  ans3  ta_3  0.01  0  =  0.5   -1  prt3-2-T   <p>Your answer is correct, but do note that the question stated to give to \\(2\\text{dp}\\).<\/p>   -  0   2  prt3-2-F       2  check different summary statistic given  AlgEquiv  node_3  true   0  =  0   -1  prt3-3-T   <p>Not quite, the question asking for the <b>{@quest_expr3@}<\/b> of the yield. <br>In a pivot table in Excel this can be achieved by clicking on the yield variable in the “Values” field, and selecting “Value Field Settings...”. <br>See <a href = “https:\/\/ecampus.idems.international\/course\/view.php?id=238&section=38”>here<\/a> for an example in Excel.<\/p>   -  0   3  prt3-3-F       3  check for summary yield of all data  AlgEquiv  ans3  node4_mist   0  +  0   -1  prt3-4-T   <p>Close, you have correctly found the {@quest_expr3@} yield overall. But we want to look at just for variety \\(1\\) with fertiliser \\(1\\). <br>This could be achieved by using the “Filter”, “Rows”, or “Columns” field if you put both \"Variety\" and \"Fertiliser\" variables in. It can be clearer to read if you put the two variables in different fields (e.g. one in Rows, one in Columns).<\/p>   -  0   4  prt3-4-F       4  checks for summary of variety 1 with fertiliser 2  AlgEquiv  ans3  node5_mist   0  +  0   -1  prt3-5-T   <p>Nearly! But it appears you have considered the {@quest_expr3@} yield for Variety \\(1\\) when <b>Fertiliser \\(2\\)<\/b> is used, whereas you should have considered when Fertiliser \\(1\\) is used.<\/p>   -  0   -1  prt3-5-F   <p>Not quite. This can be achieved in a spreadsheet software with PivotTables quite nicely. <br>For example, see <a href = “https:\/\/ecampus.idems.international\/course\/view.php?id=238&section=38”>here<\/a> how to set PivotTables up in Excel. <br>Here, we want to look at the summary of the yield. So we just have to enter “Yield” into the “Value” box, and select the appropriate statistic. <br>We want to look at the summary for Variety \\(1\\) and Fertiliser \\(1\\). This could be achieved by using the “Filter”, “Rows”, or “Columns” field if you put both Variety and Fertiliser variables in. It can be clearer to read if you put the two variables in different fields (e.g., one in rows, one in columns).<\/p>     1355139652  1475793692  1405099942  727222688  1764488602  1053645696  1288483347  475981690  481921617  1353148035  866212287  436996953  1660075351  730573743  904169792  1115876400  670670297  602749870  404838629  623713637  2118629351  2131612391  168296508  45063621  1495572133  1742423102  1402523416  308469964  185795511  1203733811  1074427199  549090432  1337413149  574739707  115640412  1407978313  256245980  1768024716  1008859308  1605583616  576027506  402504456  150988869  1300971250  1710526984  1642684398  847948150  847804899  1477761924  1892436444  72915408  185086187  1691708515  756983254  717066796  1512322050  1626724629  1221133754  2096203562  53795210  1630946381  2049744063  16078295  135814621  1034882438  938211424  359410580  278389719   1    ans1  ta_1    ans2  ta_2    ans3  ta_3    prt1  1.0000000  0.0000000  prt1-1-T    prt2  1.0000000  0.0000000  prt2-1-T    prt3  1.0000000  0.0000000  prt3-1-T         "
},
{
  "id": "sec-technical-skills-2-1",
  "level": "2",
  "url": "sec-technical-skills.html#sec-technical-skills-2-1",
  "type": "Checkpoint",
  "number": "[STRUCT].0",
  "title": "Pivot Table (Proportion).",
  "body": " Pivot Table (Proportion)        Pivot Table (Proportion)    <p>A survey was performed between farms to determine their planting preferences. Three variables are given in this survey:<\/p> <ol> <li>Sex of the farmer - male or female<\/li> <li>Village of the farmer - north or south<\/li> <li>Variety of the crop - A or B<\/li> <\/ol> <p>The task is to use the data below to answer the following questions <strong>using pivot tables<\/strong> to investigate the data.<\/p> <p><a href=\"[[textdownload name=\"data.csv\"]]{@stack_csv_formatter(data,factor_names)@}[[\/textdownload]]\">Download Data<\/a><\/p> <br> <p>Note: Leave your answer in fraction form<\/p> <p>1. What's the proportion of {@if quest_exp=\"Male\" then \"male farmers\" else if quest_exp=\"Female\" then \"female farmers\" else if quest_exp=\"North\" then \"farmers from the north village\" else if quest_exp=\"South\" then \"farmers from the south village\"@} who are planting Variety {@quest_var@}?<\/p> <p>[[input:ans1]] [[validation:ans1]]<\/p> <p>[[feedback:prt1]]<\/p> <p>2. Of those who planted Variety {@quest_var@}, what proportion of the farmers are {@if quest_exp=\"Male\" then \"male\" else if quest_exp=\"Female\" then \"female\" else if quest_exp=\"North\" then \"from the north village\" else if quest_exp=\"South\" then \"from the south village\"@}.<\/p> <p>[[input:ans2]] [[validation:ans2]]<\/p> <p>[[feedback:prt2]]<\/p> <p>3. What's the proportion of individuals who are {@if quest_exp=\"Male\" then \"male\" else if quest_exp=\"Female\" then \"female\" else if quest_exp=\"North\" then \"from the north village\" else if quest_exp=\"South\" then \"from the south village\"@} and planting Variety {@quest_var@}<\/p> <p>[[input:ans3]] [[validation:ans3]]<\/p> <p>[[feedback:prt3]]<\/p>      1  0.1  0    2025073100    \/* ------------- INFORMATION FROM QUESTION AUTHORS *\/ varietyA_prob: (rand(7)+2)\/10; factor_info: [ [\"Sex\", [ [\"Male\", 0.4], [\"Female\", 0.6] ]], [\"Village\", [ [\"North\", 0.2], [\"South\", 0.8] ]], [\"Variety\", [ [\"A\", varietyA_prob], [\"B\", 1-varietyA_prob] ]] ]; \/* Dataset dimensions *\/ number_rows: rand_with_step(91,99,1); \/* ------------- END AUTHOR INFO *\/ \/* ------------- DATA SET GENERATION *\/ column_data: []; \/* Useful variables *\/ number_factors: length(factor_info); factor_names: makelist(factor_info[i][1], i, 1, number_factors); \/* Generate data for each factor *\/ for factor in factor_info do block( \/* Generate probability ranges for each value *\/ number_options: length(factor[2]), option_values: makelist(factor[2][i][1], i, 1, number_options), option_probabilities: makelist(factor[2][i][2], i, 1, number_options), factor_data: [], \/* Generate randomised correct values *\/ \/* Assign each option in the list a interval in [0,1] of length equal to the associated probability *\/ value_prob_ranges: makelist( [sum(option_probabilities[j], j, 1, i-1), sum(option_probabilities[j], j, 1, i)], i, 1, number_options ), \/* Randomise choice of option by generating a number in [0,1] and determining in which interval it falls *\/ for i: 1 thru number_rows step 1 do block( rn: rand(1.0), for j: 1 thru number_options step 1 do block( if value_prob_ranges[j][1] <= rn and rn < value_prob_ranges[j][2] then factor_data: append(factor_data, [option_values[j]]) ) ), \/* Append data for each factor to the dataset *\/ column_data: append(column_data, [factor_data]) ); \/* Rotate the data to be given in rows rather than columns of each factor, also add header row *\/ data: makelist(makelist(column_data[j][i], j, 1, number_factors), i, 1, number_rows); data_set: append( [factor_names], data ); \/* ------------- END OF DATA SET GENERATION *\/ \/* ------------- QUESTION VARIABLES *\/ \/* Is the question generally about the sex or village of those surveyed? *\/ quest_form: rand([\"sex\", \"village\"]); quest_index: if quest_form=\"sex\" then 1 else if quest_form=\"village\" then 2; \/* Is the question about the men or women (eq. North or South village)? *\/ quest_exp: if quest_form=\"sex\" then rand([\"Male\", \"Female\"]) else if quest_form=\"village\" then rand([\"North\", \"South\"]); \/* Is the question about variety A or B of the crop? *\/ quest_var: rand([\"A\", \"B\"]); \/* Sublists containing only quest_exp, quest_var or both *\/ quest_exp_only: sublist(data_set, lambda([x], is(x[quest_index]=quest_exp))); quest_var_only: sublist(data_set, lambda([x], is(x[3]=quest_var))); quest_exp_and_var: sublist(quest_exp_only, lambda([x], is(x[3]=quest_var))); \/* Number of entries containing only quest_exp, quest_var or both *\/ no_quest_exp_only: length(quest_exp_only); no_quest_var_only: length(quest_var_only); no_quest_exp_and_var: length(quest_exp_and_var); \/* question 1 - what is the probability of \"quest_exp\" participants who are planting variety \"quest_var\"? *\/ ta_1: no_quest_exp_and_var\/no_quest_exp_only; \/* question 2 - of those who planted \"quest_var\", how many are \"quest_exp\"? *\/ ta_2: no_quest_exp_and_var\/no_quest_var_only; \/* question 3 - what proportion are \"quest_exp\" and planting \"quest_var\"? *\/ ta_3: no_quest_exp_and_var\/number_rows; \/* ------------- END OF QUESTION VARIABLES *\/       <p>1. Proportion of {@quest_exp@} farmers planting Variety {@quest_var@}<\/p> <p>{@ta_1@}<\/p> <p>2. Of those planting Variety {@quest_var@}, what proportion are {@quest_exp@}<\/p> <p>{@ta_2@}<\/p> <p>3. Proportion of individuals who are {@quest_exp@} and planting Variety {@quest_var@}<\/p> <p>{@ta_3@}<\/p>    <p id=\"author\">Dan Kelly<\/p> <p id=\"concept\">https:\/\/docs.google.com\/document\/d\/1yPGZysLZE1r3R_oom4SQiMknF64FzULcWvQMBF1uBsk\/edit#heading=h.wvpxq8elfr9z<\/p> <p id=\"reviewer\"><\/p> <p id=\"description\"><\/p>   1  0  0   <span style=\"font-size: 1.5em; color:green;\"><i class=\"fa fa-check\"><\/i><\/span> Correct answer, well done.    <span style=\"font-size: 1.5em; color:orange;\"><i class=\"fa fa-adjust\"><\/i><\/span> Your answer is partially correct.    <span style=\"font-size: 1.5em; color:red;\"><i class=\"fa fa-times\"><\/i><\/span> Incorrect answer.   .  *10  none  1  i  cos-1  lang  [  0    ans1  algebraic  ta_1  15  1  0   0   %  0  0  0  1  3     ans2  algebraic  ta_2  15  1  0   0    1  0  0  1  3     ans3  algebraic  ta_3  15  1  0   0    1  0  0  1  3     prt1  1.0000000  1  1   \/* wrong denominator *\/ node2_error: no_quest_exp_and_var\/number_rows; node3_error: no_quest_exp_and_var\/no_quest_var_only; \/* wrong numerator *\/ node4_error: no_quest_var_only\/number_rows; node5_error: no_quest_exp_only\/number_rows; \/* other mistake *\/ node6_error: no_quest_exp_only\/no_quest_var_only; \/*answer as rounded percentage?*\/ simp:false; rounded_percentage_check:if denom(ans1)=100 then 1 else 0; simp:true;    0  check correct answer  AlgEquiv  ans1  ta_1   0  =  1   -1  prt1-1-T   <p>The question is essentially asking for the fraction of {@if quest_exp=\"Male\" then \"male farmers\" else if quest_exp=\"Female\" then \"female farmers\" else if quest_exp=\"North\" then \"farmers from the north village\" else if quest_exp=\"South\" then \"farmers from the south village\"@} who engage in planting variety {@quest_var@}<\/p> <p>We find the proportion of {@if quest_exp=\"Male\" then \"male farmers\" else if quest_exp=\"Female\" then \"female farmers\" else if quest_exp=\"North\" then \"farmers from the north village\" else if quest_exp=\"South\" then \"farmers from the south village\"@} planting variety {@quest_var@} by dividing their number by the the number of rows in the data set \\(=\\displaystyle \\frac{{@no_quest_exp_and_var@}}{{@no_quest_exp_only@}}\\) <\/p>   =  0   6  prt1-1-F       1  wrong denominator  AlgEquiv  ans1  node2_error   0  =  0   -1  prt1-2-T   <p>It appears that the numerator of your proportion is correct, so you are looking at the right group of individuals. <br>However, we want to look at this <b>out of<\/b> the farmers who are {@if quest_exp=\"Male\" then \"male\" else if quest_exp=\"Female\" then \"female\" else if quest_exp=\"North\" then \"from the north village\" else if quest_exp=\"South\" then \"from the south village\"@}.<\/p>   -  0   2  prt1-2-F       2  wrong denominator  AlgEquiv  ans1  node3_error   0  +  0   -1  prt1-3-T   <p>It appears that the numerator of your proportion is correct, so you are looking at the right group of individuals. <br>However, we want to look at this <b>out of<\/b> the farmers who are {@if quest_exp=\"Male\" then \"male\" else if quest_exp=\"Female\" then \"female\" else if quest_exp=\"North\" then \"from the north village\" else if quest_exp=\"South\" then \"from the south village\"@}.<\/p>   -  0   3  prt1-3-F       3  wrong numerator  AlgEquiv  ans1  node4_error   0  +  0   -1  prt1-4-T   <p>It appears that the numerator of your proportion is not quite correct. <br>We want to look at for individuals who are both {@if quest_exp=\"Male\" then \"male\" else if quest_exp=\"Female\" then \"female\" else if quest_exp=\"North\" then \"from the north village\" else if quest_exp=\"South\" then \"from the south village\"@} <b>and<\/b> use variety {@quest_var@}.<\/p>   -  0   4  prt1-4-F       4  wrong numerator  AlgEquiv  ans1  node5_error   0  +  0   -1  prt1-5-T   <p>It appears that the numerator of your proportion is not quite correct. <br>We want to look at for individuals who are both {@if quest_exp=\"Male\" then \"male\" else if quest_exp=\"Female\" then \"female\" else if quest_exp=\"North\" then \"from the north village\" else if quest_exp=\"South\" then \"from the south village\"@} <b>and<\/b> use variety {@quest_var@}.<\/p>   -  0   5  prt1-5-F       5  other mistake  AlgEquiv  ans1  node6_error   0  +  0   -1  prt1-6-T   <p>Not quite. Have a think about the pivot table. We want to have a 2x2 table with {@quest_form@} by variety.<\/p>   -  0   -1  prt1-6-F       6  Classify cases where answer is rounded percentage  AlgEquiv  rounded_percentage_check  1   0  +  0   7  prt1-7-T     -  0   1  prt1-7-F       7  exact percentage  AlgEquiv  100*ans1  decimalplaces(float(ta_1)*100,0)   1  +  0.9   -1  prt1-8-T   <p>You gave your answer correctly as a rounded percentage. However, you were asked for the proportion.<\/p>   -  0   8  prt1-8-F       8  close percentage  NumAbsolute  100*ans1  decimalplaces(float(ta_1)*100,0)  1  1  +  0.5   -1  prt1-9-T   <p>It appears that you gave your answer as a rounded percentage while you were asked for the proportion. Additionally, and the rounding is not quite right.<\/p>   -  0   9  prt1-9-F   <p>It appears that you attempted to give your answer as a rounded percentage while you were asked for the proportion. <br>Therefore the denominator of your fraction should be the number of rows in the dataset.<\/p>     9  checks for decimalplaces  AlgEquiv  ans1  float(ta_1)   0  =  0.25   -1  prt1-10-T     -  0   -1  prt1-10-F        prt2  1.0000000  1  1   \/* wrong denominator *\/ node2_error: no_quest_exp_and_var\/number_rows; node3_error: no_quest_exp_and_var\/no_quest_exp_only; \/* wrong numerator *\/ node4_error: no_quest_var_only\/number_rows; node5_error: no_quest_exp_only\/number_rows; \/* other mistake *\/ node6_error: no_quest_var_only\/no_quest_exp_only; \/*answer as rounded percentage?*\/ simp:false; rounded_percentage_check:if denom(ans2)=100 then 1 else 0; simp:true;    0  check correct answer  AlgEquiv  ans2  ta_2   0  =  1   -1  prt2-1-T     =  0   6  prt2-1-F       1  wrong denominator  AlgEquiv  ans2  node2_error   0  +  0   -1  prt2-2-T   <p>It appears that the numerator of your proportion is correct, so you are looking at the right group of individuals. However, we want to look at this <b>out of<\/b> the farmers who planted variety {@quest_var@}.<\/p>   -  0   2  prt2-2-F       2  wrong denominator  AlgEquiv  ans2  node3_error   0  +  0   -1  prt2-3-T   <p>It appears that the numerator of your proportion is correct, so you are looking at the right group of individuals. However, we want to look at this <b>out of<\/b> the farmers who planted variety {@quest_var@}.<\/p>   -  0   3  prt2-3-F       3  wrong numerator  AlgEquiv  ans2  node4_error   0  +  0   -1  prt2-4-T   <p>It appears that the numerator of your proportion is not quite correct. We want to look at for individuals who are both {@if quest_exp=\"Male\" then \"male\" else if quest_exp=\"Female\" then \"female\" else if quest_exp=\"North\" then \"from the north village\" else if quest_exp=\"South\" then \"from the south village\"@} <b>and<\/b> use variety {@quest_var@}.<\/p>   -  0   4  prt2-4-F       4  wrong numerator  AlgEquiv  ans2  node5_error   0  +  0   -1  prt2-5-T   <p>It appears that the numerator of your proportion is not quite correct. We want to look at for individuals who are both {@if quest_exp=\"Male\" then \"male\" else if quest_exp=\"Female\" then \"female\" else if quest_exp=\"North\" then \"from the north village\" else if quest_exp=\"South\" then \"from the south village\"@} <b>and<\/b> use variety {@quest_var@}.<\/p>   -  0   5  prt2-5-F       5  other mistake  AlgEquiv  ans2  node6_error   0  +  0   -1  prt2-6-T   <p>Not quite. Have a think about the pivot table. We want to have a 2x2 table with {@quest_form@} by variety.<\/p>   -  0   -1  prt2-6-F       6  Classify cases where answer is rounded percentage  AlgEquiv  rounded_percentage_check  1   0  +  0   7  prt2-7-T     -  0   1  prt2-7-F       7  exact percentage  AlgEquiv  100*ans2  decimalplaces(float(ta_2)*100,0)   1  +  0.9   -1  prt2-8-T   <p>You gave your answer correctly as a rounded percentage. However, you were asked for the proportion.<\/p>   -  0   8  prt2-8-F       8  close percentage  NumAbsolute  100*ans2  decimalplaces(float(ta_2)*100,0)  1  1  +  0.5   -1  prt2-9-T   <p>It appears that you gave your answer as a rounded percentage while you were asked for the proportion. Additionally, and the rounding is not quite right.<\/p>   -  0   -1  prt2-9-F   <p>It appears that you attempted to give your answer as a rounded percentage while you were asked for the proportion. <br>Therefore the denominator of your fraction should be the number of rows in the dataset.<\/p>      prt3  1.0000000  1  1   \/* wrong denominator *\/ node2_error: no_quest_exp_and_var\/no_quest_var_only; node3_error: no_quest_exp_and_var\/no_quest_exp_only; \/* wrong numerator *\/ node4_error: no_quest_var_only\/number_rows; node5_error: no_quest_exp_only\/number_rows; \/* other mistakes *\/ node6_error: no_quest_exp_only\/no_quest_var_only; node7_error: no_quest_var_only\/no_quest_exp_only; \/*answer as rounded percentage?*\/ simp:false; rounded_percentage_check:if denom(ans1)=100 then 1 else 0; simp:true;    0  check correct answer  AlgEquiv  ans3  ta_3   0  =  1   -1  prt3-1-T   <p>The question is essentially asking for the fraction of individuals from {@if quest_exp=\"Male\" then \"male\" else if quest_exp=\"Female\" then \"female\" else if quest_exp=\"North\" then \"from the north village\" else if quest_exp=\"South\" then \"from the south village\"@} and planting Variety {@quest_var@} by dividing their number by the number of rows in the data set \\(={@ta_3@}\\) <\/p>   =  0   7  prt3-1-F       1  wrong denominator  AlgEquiv  ans3  node2_error   0  +  0   -1  prt3-2-T   <p>It appears that the numerator of your proportion is correct, so you are looking at the right group of individuals. However, we want to look at this <b>out of<\/b> all the farmers.<\/p>   -  0   2  prt3-2-F       2  wrong denominator  AlgEquiv  ans3  node3_error   0  +  0   -1  prt3-3-T   <p>It appears that the numerator of your proportion is correct, so you are looking at the right group of individuals. However, we want to look at this <b>out of<\/b> all the farmers.<\/p>   -  0   3  prt3-3-F       3  wrong numerator  AlgEquiv  ans3  node4_error   0  +  0   -1  prt3-4-T   <p>It appears that the numerator of your proportion is not quite correct. We want to look at for individuals who are both {@if quest_exp=\"Male\" then \"male\" else if quest_exp=\"Female\" then \"female\" else if quest_exp=\"North\" then \"from the north village\" else if quest_exp=\"South\" then \"from the south village\"@} <b>and<\/b> use variety {@quest_var@}.<\/p>   -  0   4  prt3-4-F       4  wrong numerator  AlgEquiv  ans3  node5_error   0  +  0   -1  prt3-5-T   <p>It appears that the numerator of your proportion is not quite correct. We want to look at for individuals who are both {@if quest_exp=\"Male\" then \"male\" else if quest_exp=\"Female\" then \"female\" else if quest_exp=\"North\" then \"from the north village\" else if quest_exp=\"South\" then \"from the south village\"@} <b>and<\/b> use variety {@quest_var@}.<\/p>   -  0   5  prt3-5-F       5  other mistakes  AlgEquiv  ans3  node6_error   0  +  0   -1  prt3-6-T   <p>Not quite. Have a think about the pivot table. We want to have a 2x2 table with {@quest_form@} by variety.<\/p>   -  0   6  prt3-6-F       6  other mistakes  AlgEquiv  ans3  node7_error   0  +  0   -1  prt3-7-T   <p>Not quite. Have a think about the pivot table. We want to have a 2x2 table with {@quest_form@} by variety.<\/p>   -  0   -1  prt3-7-F       7  Classify cases where answer is rounded percentage  AlgEquiv  rounded_percentage_check  1   0  +  0   8  prt3-8-T     -  0   1  prt3-8-F       8  exact percentage  AlgEquiv  100*ans3  decimalplaces(float(ta_3)*100,0)   1  +  0.9   -1  prt3-9-T   <p>You gave your answer correctly as a rounded percentage. However, you were asked for the proportion.<\/p>   -  0   9  prt3-9-F       9  close percentage  NumAbsolute  100*ans3  decimalplaces(float(ta_3)*100,0)  1  1  +  0.5   -1  prt3-10-T   <p>It appears that you gave your answer as a rounded percentage while you were asked for the proportion. Additionally, and the rounding is not quite right.<\/p>   -  0   -1  prt3-10-F   <p>It appears that you attempted to give your answer as a rounded percentage while you were asked for the proportion. <br>Therefore the denominator of your fraction should be the number of rows in the dataset.<\/p>     1177705686  1869894104  2099431645  1401350002  1309508461  791681937  1911896793  410931084  835612872  691372427  612924321  1701751675  218211428  2040613227  2117694960  2130360777  639571339  61514645  1004453818  1073641119  1251764276  1104149951  2116463331  159293109  861216255  1647883001  2101950508  176076653  658044513  125904139  1199501157  1667670667  2012974973  630993233  1834854489  1662004458  503126214  1330432592  1104541205  167769226   1  Test case assuming the teacher's input gets full marks.   ans1  ta_1    ans2  ta_2    ans3  ta_3    prt1  1.0000000  0.0000000  prt1-1-T    prt2  1.0000000  0.0000000  prt2-1-T    prt3  1.0000000  0.0000000  prt3-1-T       "
},
{
  "id": "sec-technical-skills-2-2",
  "level": "2",
  "url": "sec-technical-skills.html#sec-technical-skills-2-2",
  "type": "Checkpoint",
  "number": "[STRUCT].1",
  "title": "Filtering to Clean.",
  "body": " Filtering to Clean        Filtering to Clean    <p>A survey was conducted, involving 100 farmers, wherein they were provided with a questionnaire. The dataset contains information on three key variables resulting from this simulated survey: Age, Variety, and Yield. <\/p> <p><a href=\"[[textdownload name=\"data.csv\"]]{@stack_csv_formatter(data,factor_names)@}[[\/textdownload]]\">Download Data<\/a><\/p> <br> <p>To look at this data, we would like to know if younger or older farmers plant different varieties, and get different yields as a consequence. But to do that, we need to make sure that we are getting the right information. Before we can ask our question, we need to look at the variables. So the purpose of these questions are to check we are ready for analysis. We suggest using filtering techniques to clean the dataset to address the following questions.<\/p> <br> <p>1. What is the mean yield of this data set? <br>Give your answer to the nearest whole number.<\/p> <p>[[input:ans1]] [[validation:ans1]]<\/p> <p>[[feedback:prt1]]<\/p> <br> <p>2. What is the mean age of the farmers in this data set? <br>Give your answer to 2 decimal place.<\/p> <p>[[input:ans2]] [[validation:ans2]]<\/p> <p>[[feedback:prt2]]<\/p> <br> <p>3. How many farmers plant the {@quest3_option@} variety?<\/p> <p>[[input:ans3]] [[validation:ans3]]<\/p> <p>[[feedback:prt3]]<\/p> <br> <p>4. Does the age of the farmer have an effect on the yield?<\/p> <p>[[input:ans4]] [[validation:ans4]]<\/p> <p>[[feedback:prt4]]<\/p>      1  0.1  0    2025073100    \/* ------------- INFORMATION FROM QUESTION AUTHORS *\/ \/* [Factor name, data generation type, data generation info] *\/ \/* Factor name is given as a string *\/ \/* Data generation type is one from the list below. The generation info is given as a list and contains information both for calculating the correct randomized values which the data should take and the possible errors which can occur in the data: For qualitative data, possible errors are given in a list of the actual error value For quantitative data, possible errors are given in a list of formulae which can be applied to the correct values (these formula may of course be simply constant values!) The desired number of errors should also be given, each possible error in the list is then applied with equal probability *\/ \/* 1. \"Option from list\", [ [\"Option 1\", *probability 1*, errors list], [\"Option 2\", *probability 2*, errors list], ..., *number of errors* ] 2. \"Integer in range\", [ *lower bound*, *upper bound*, *mean* (need to add this functionality), error formulae list, *number of errors* ] 3. \"Sequential index\", [ *start value*, error formulae list, *number of errors* ] 4. \"Normal distribution\", [ *mean*, *standard deviation*, error formulae list, *number of errors* ] *\/ factor_info: [ [\"ID\", \"Sequential index\", [1, [], 0] ], [\"Sex\", \"Option from list\", [ [\"Male\", 0.5, [\"M\", \"m\", \"male\", \"man\"]], [\"Female\", 0.5, [\"F\", \"f\", \"female\", \"woman\", \"fem\", \"femelle\"]], rand_with_step(20,40,1) ]], [\"Age\", \"Integer in range\", [18, 65, 30, [2023-x], 1] ], [\"Variety\", \"Option from list\", [ [\"New\", 0.5, [\"N\", \"n\", \"new\", \"Nouveau\", \"nouveau\", \"nouv.\"]], [\"Traditional\", 0.5, [\"T\", \"t\", \"traditional\", \"Traditionnelle\", \"traditionnelle\", \"trad.\"]], rand_with_step(20,40,1) ]], [\"Yield\", \"Normal distribution\", [40000, 10000, [-x], 1] ] ]; \/* Dataset dimensions *\/ number_rows: 100; \/* ------------- END AUTHOR INFO *\/ \/* ------------- DATA SET GENERATION *\/ column_data: []; \/* Useful variables *\/ number_factors: length(factor_info); factor_names: makelist(factor_info[i][1], i, 1, number_factors); row_list: makelist(i, i, 1, number_rows); \/* Generate data for each factor *\/ for factor in factor_info do block( \/* \"Option from list\" factor type *\/ if factor[2] = \"Option from list\" then block( \/* Extract important information *\/ number_options: length(factor[3])-1, option_values: makelist(factor[3][i][1], i, 1, number_options), option_probabilities: makelist(factor[3][i][2], i, 1, number_options), option_errors: makelist(factor[3][i][3], i, 1, number_options), number_errors: last(factor[3]), factor_data: [], \/* Generate randomised correct values *\/ \/* Assign each option in the list a interval in [0,1] of length equal to the associated probability *\/ value_prob_ranges: makelist( [sum(option_probabilities[j], j, 1, i-1), sum(option_probabilities[j], j, 1, i)], i, 1, number_options ), \/* Randomise choice of option by generating a number in [0,1] and determining in which interval it falls *\/ for i: 1 thru number_rows step 1 do block( rn: rand(1.0), for j: 1 thru number_options step 1 do block( if value_prob_ranges[j][1] <= rn and rn < value_prob_ranges[j][2] then factor_data: append(factor_data, [option_values[j]]) ) ), \/* Introduce random errors in random positions *\/ error_rows: sort(rand_selection(row_list, number_errors)), for i: 1 thru number_errors step 1 do block( for j: 1 thru number_options do block( if factor_data[error_rows[i]] = option_values[j] then (factor_data[error_rows[i]]: rand(option_errors[j])) ) ) ) \/* \"Integer in range\" factor type *\/ else if factor[2] = \"Integer in range\" then block( \/* Extract important information *\/ option_errors: factor[3][4], number_errors: factor[3][5], \/* Generate randomised correct values *\/ factor_data: makelist(rand_with_step(factor[3][1], factor[3][2], 1), i, 1, number_rows), \/* Introduce random errors in random positions *\/ error_rows: sort(rand_selection(row_list, number_errors)), for i: 1 thru number_errors step 1 do ( factor_data[error_rows[i]]: ev(rand(option_errors), x=factor_data[error_rows[i]]) ) ) \/* \"Sequential index\" factor type *\/ else if factor[2] = \"Sequential index\" then block( \/* Extract important information *\/ option_errors: factor[3][2], number_errors: factor[3][3], \/* Generate randomised correct values *\/ factor_data: makelist(factor[3][1] - 1 + i, i, 1, number_rows), \/* Introduce random errors in random positions *\/ error_rows: sort(rand_selection(row_list, number_errors)), for i: 1 thru number_errors step 1 do ( factor_data[error_rows[i]]: ev(rand(option_errors), x=factor_data[error_rows[i]]) ) ) \/* \"Normal distribution\" factor type *\/ else if factor[2] = \"Normal distribution\" then block( \/* Extract important information *\/ option_errors: factor[3][3], number_errors: factor[3][4], \/* Generate randomised correct values *\/ factor_data: makelist(ceiling(random_normal(factor[3][1], factor[3][2])), i, 1, number_rows), \/* Introduce random errors in random positions *\/ error_rows: sort(rand_selection(row_list, number_errors)), for i: 1 thru number_errors step 1 do ( factor_data[error_rows[i]]: ev(rand(option_errors), x=factor_data[error_rows[i]]) ) ), \/* Append data for each factor to the dataset *\/ column_data: append(column_data, [factor_data]) ); \/* Rotate the data to be given in rows rather than columns of each factor, also add header row *\/ data: makelist(makelist(column_data[j][i], j, 1, number_factors), i, 1, number_rows); data_set: append([factor_names], data); \/* ------------- OTHER QUESTION VARIABLES *\/ \/* question 1 *\/ yield_list: last(column_data); mean_yield_with_errors: mean(yield_list); mean_yield_ignoring_errors: mean(sublist(yield_list, lambda([x], is(x>0)))); mean_yield_correcting_errors: mean(create_list(abs(x), x, yield_list)); \/* question 2 *\/ age_list: column_data[3]; mean_age_with_errors: mean(age_list); mean_age_ignoring_errors: mean(sublist(age_list, lambda([x], is(x<100)))); mean_age_correcting_errors: mean(create_list(block(if x<100 then return(x) else return(2023-x)), x, age_list)); \/* question 3 *\/ quest3_option: rand({\"new\", \"traditional\"}); variety_list: column_data[4]; \/* Lists of \"correct\" variety labels and \"alternate\"\/\"erroneous\" labels names *\/ corr_names: if quest3_option=\"new\" then [\"New\", \"new\"] else [\"Traditional\", \"traditional\"]; alt_names: if quest3_option=\"new\" then delete(\"new\", factor_info[4][3][1][3]) else delete(\"traditional\", factor_info[4][3][2][3]); \/* Number of instances of each variety label in the data set *\/ corr_names_count: create_list(length(sublist(variety_list, lambda([y], is(y=x)))), x, corr_names); tot_corr_names_count: corr_names_count[1] + corr_names_count[2]; alt_names_count: create_list(length(sublist(variety_list, lambda([y], is(y=x)))), x, alt_names); \/* Different counts the student could achieve taking different subsets of the correct\/alternate labels *\/ number_corr_names: [ \/* Capitalised correct labels only *\/ corr_names_count[1], \/* All correct labels (capitalised and lower case) *\/ tot_corr_names_count ]; number_some_alt_names: append( \/* All correct labels + any individual alternate label*\/ makelist(tot_corr_names_count + x, x, alt_names_count), \/* All correct labels + any one of letter labels, French labels or abbreviated labels *\/ [tot_corr_names_count + alt_names_count[1] + alt_names_count[2], tot_corr_names_count + alt_names_count[3] + alt_names_count[4], tot_corr_names_count + alt_names_count[5]], \/* All correct labels + any two of the above catagories *\/ [tot_corr_names_count + alt_names_count[1] + alt_names_count[2] + alt_names_count[3] + alt_names_count[4], tot_corr_names_count + alt_names_count[1] + alt_names_count[2] + alt_names_count[5], tot_corr_names_count + alt_names_count[3] + alt_names_count[4] + alt_names_count[5]] ); number_all_alt_names: tot_corr_names_count + alt_names_count[1] + alt_names_count[2] + alt_names_count[3] + alt_names_count[4] + alt_names_count[5]; \/* Plotting the age of the farmers against the yield *\/ corr_age_list: create_list(block(if x<100 then return(x) else return(2023-x)), x, age_list); corr_yield_list: create_list(abs(x), x, yield_list); age_yield_plot: makelist([corr_age_list[i], corr_yield_list[i]], i, 1, number_rows);       <p>1. What is the mean yield of this data set? <br>{@float(mean_yield_correcting_errors)@}<\/p> <p>2. What is the mean age of the farmers in this data set? <br>{@float(mean_age_correcting_errors)@}<\/p> <p>3. How many farmers plant the {@quest3_option@} variety? <br>{@number_all_alt_names@}<\/p> <p>4. Does the age of the farmer have an effect on the yield? <br>\"No\"<\/p>    <p id=\"author\">Dan Kelly<\/p> <p id=\"concept\">https:\/\/docs.google.com\/document\/d\/1lzEC4BPdzj3r6J2DFvEc4hBK3BOt6cCz4jrC4c1NWac\/edit?usp=drive_link<\/p> <p id=\"reviewer\"><\/p> <p id=\"description\"><\/p>   1  0  0   <span style=\"font-size: 1.5em; color:green;\"><i class=\"fa fa-check\"><\/i><\/span> Correct answer, well done.    <span style=\"font-size: 1.5em; color:orange;\"><i class=\"fa fa-adjust\"><\/i><\/span> Your answer is partially correct.    <span style=\"font-size: 1.5em; color:red;\"><i class=\"fa fa-times\"><\/i><\/span> Incorrect answer.   .  *10  none  1  i  cos-1  lang  [  0    ans1  algebraic  decimalplaces(mean_yield_correcting_errors,0)  15  1  0   0    0  0  0  1  3     ans2  algebraic  decimalplaces(mean_age_correcting_errors,2)  15  1  0   0    0  0  0  1  3     ans3  algebraic  number_all_alt_names  15  1  0   0    1  0  0  1  3     ans4  dropdown  [[\"Yes\", false], [\"No\", true]]  15  1  0   0    1  0  0  0  0     prt1  1.0000000  1  1      0  Gives mean yield with the errors  NumAbsolute  ans1  mean_yield_with_errors  1  0  =  0   -1  prt1-1-T   <p>Close, but you haven’t properly cleaned the yield variable. Have a look at the options in filtering to try and detect any incorrect values!<\/p>   =  0   -1  prt1-1-F       1  Ignores the erroneous values and gives mean yield  NumAbsolute  ans1  mean_yield_ignoring_errors  1  0  =  1   -1  prt1-2-T   <p>Great! You have successfully cleaned the yield variable. <br>If you can justify removing the incorrect value, then this is great - but in reality it is good practice to double check back with the surveyors, or other members who may know before changing a value. This can include the individual interviewed.<\/p>   -  0   2  prt1-2-F       2  Corrects the erroneous values and gives mean  NumAbsolute  ans1  mean_yield_correcting_errors  1  0  =  1   -1  prt1-3-T   <p>Great! You have successfully cleaned the yield variable. <br>If you can justify making the negative value as positive, then this is great - but in reality it is good practice to double check back with the surveyors, or other members who may know before changing a value. This can include the individual interviewed.<\/p>   -  0   0  prt1-3-F        prt2  1.0000000  1  1      0  Gives mean age with the errors  NumAbsolute  ans2  mean_age_with_errors  0.01  0  =  0   -1  prt2-1-T   <p>Close, but you haven’t properly cleaned the age variable. Have a look at the options in filtering to try and detect any incorrect values!<\/p>   =  0   -1  prt2-1-F       1  Ignores the erroneous values and gives mean yield  NumAbsolute  ans2  mean_age_ignoring_errors  0.01  0  =  1   -1  prt2-2-T   <p>Great! You have successfully cleaned the age variable. <br>It looks like you found that one individual gave a very high value, and set it as NA. If you can justify this, then this is great - but in reality it is good practice to double check back with the surveyors, or other members who may know before changing a value. This can include the individual interviewed; is it possible to follow up in case they gave their birth year not their age?<\/p>   -  0   2  prt2-2-F       2  Corrects the erroneous values and gives mean  NumAbsolute  ans2  mean_age_correcting_errors  0.01  0  =  1   -1  prt2-3-T   <p>Great! You have successfully cleaned the age variable. <br>It looks like you assumed one individual gave their year of birth not their age. If you can justify this, then this is great - but in reality it is good practice to double check back with the surveyors, or other members who may know before changing a value. This can include the individual interviewed.<\/p>   -  0   0  prt2-3-F        prt3  1.0000000  1  1   \/* node 1 *\/ node1_test: if member(ans3, number_corr_names) then 1 else 0; \/* node 2 *\/ node2_test: if member(ans3, number_some_alt_names) then 1 else 0;    0  Gives number without considering error values  AlgEquiv  node1_test  1   0  =  0   -1  prt3-1-T   <p>Close, but you haven’t properly cleaned the variety variable. Have a look at the options in filtering to try and detect any incorrect values.<\/p>   =  0   -1  prt3-1-F       1  Gives number considering some error values  AlgEquiv  node2_test  1   0  =  0.5   -1  prt3-2-T   <p>Close, but you haven’t properly cleaned the variety variable. Have a look at the options in filtering to try and detect any incorrect values.<\/p>   -  0   0  prt3-2-F       2  Gives number considering all error values  AlgEquiv  ans3  number_all_alt_names   0  =  1   -1  prt3-3-T   <p>Great! You have successfully cleaned the variety variable and found the correct number of individuals who plant that variety.<\/p>   -  0   1  prt3-3-F        prt4  1.0000000  1  1      0  Correct answer is \"No\"  AlgEquiv  ans4  \"No\"   0  =  1   -1  prt4-1-T   <p>Correct. In this simulated data, there was no effect. Any observed effect is just due to chance.<\/p> <p>To see this, you can consider a scatter plot of the data, below we have the age of the farmers on the \\(x\\)-axis and the yield on the \\(y\\)-axis.<\/p> <br> <p style=\"margin-left:30px\">{@ plot( [discrete, age_yield_plot], [x,0,70], [xlabel,\"Age\"], [y,0,ceiling(last(sort(corr_yield_list))\/10000)*10000], [ylabel,\"Yield\"], [style, [points, 2]], [point_type, asterisk], [plottags,false] ) @}<\/p>   =  0   -1  prt4-1-F   <p>In this simulated data, there was no effect. Any observed effect is just due to chance.<\/p> <p>To see this, you can consider a scatter plot of the data, below we have the age of the farmers on the \\(x\\)-axis and the yield on the \\(y\\)-axis.<\/p> <br> <p style=\"margin-left:30px\">{@ plot( [discrete, age_yield_plot], [x,0,70], [xlabel,\"Age\"], [y,0,ceiling(last(sort(corr_yield_list))\/10000)*10000], [ylabel,\"Yield\"], [style, [points, 2]], [point_type, asterisk], [plottags,false] ) @}<\/p>     1380901209  222344047  286706238  806083264  1752894148  173097596  1237847435  1380091418  120293376  1025989901  1686933893  1763901196  459626713  770256681  1570466202   1  Test case assuming the teacher's input gets full marks.   ans1  decimalplaces(mean_yield_correcting_errors,0)    ans2  decimalplaces(mean_age_correcting_errors,2)    ans3  number_all_alt_names    ans4  first(mcq_correct([[\"Yes\", false], [\"No\", true]]))    prt1  1.0000000  0.0000000  prt1-3-T    prt2  1.0000000  0.0000000  prt2-3-T    prt3  1.0000000  0.0000000  prt3-3-T    prt4  1.0000000  0.0000000  prt4-1-T       "
},
{
  "id": "sec-technical-skills-2-3",
  "level": "2",
  "url": "sec-technical-skills.html#sec-technical-skills-2-3",
  "type": "Checkpoint",
  "number": "[STRUCT].2",
  "title": "Appending Data.",
  "body": " Appending Data   This question uses a fixed external data set, converted to csv using custom Javascript within the STACK question. This is currently not supported in our PreText implementation; thus this question doesn't work here.        Appending Data    <p>Rainfall data were taken in two regions in Ghana: Elamat and Palstond. However, the data has been collected into two data frames: one contains data from 1990-1999, and the other from 2000-2016.<\/p> <p>The former data set contains the station name, the date, year, rainfall (mm), minimum temperature (Celsius), and maximum temperature (Celsius).<\/p> <p>The latter data set contains the station name, date, year, rainfall (cm), minimum temperature (Celsius), and maximum temperature (Celsius), and hours of sunshine.<\/p> <p>The task is to combine the data sets and answer the following questions: <br><em>(Note that this is “made up” data)<\/em><\/p> <p><button onclick=\"exportToCsv1990()\">Download Data: 1990-1999<\/button><\/p> <p><button onclick=\"exportToCsv2000()\">Download Data: 2000-2016<\/button><\/p> <br> <p>1. Which year had the least overall rainfall?<\/p> <p>[[input:ans1]] [[validation:ans1]]<\/p> <br> <p>2. Which region had more rainfall between 1990-2016 (inclusive)?<\/p> <p>[[input:ans2]] [[validation:ans2]]<\/p> <br> <p>3. How much rainfall was there in total across both stations in 2016 in \\(mm\\)?<\/p> <br><em>Give your answer to 2 decimal places.<\/em><\/p> <p>[[input:ans3]] [[validation:ans3]]<\/p> <p>[[feedback:prt1]]<\/p> <script> var Results1990; var Results2000; fetch(\"https:\/\/raw.githubusercontent.com\/IDEMSInternational\/wxmaxima-stack\/main\/data-files\/ghana-1990-1999.txt\") .then(res => res.json()) .then(data => { Results1990 = data; }) fetch(\"https:\/\/raw.githubusercontent.com\/IDEMSInternational\/wxmaxima-stack\/main\/data-files\/ghana-2000-2016.txt\") .then(res => res.json()) .then(data => { Results2000 = data; }) exportToCsv1990 = function(file_name) { var CsvString = \"\"; Results1990.forEach(function(RowItem, RowIndex) { RowItem.forEach(function(ColItem, ColIndex) { CsvString += ColItem; if( ColIndex < RowItem.length - 1){ CsvString += ','; } }); CsvString += \"\\r\\n\"; }); CsvString = \"data:application\/csv,\" + encodeURIComponent(CsvString); var x = document.createElement(\"A\"); x.setAttribute(\"href\", CsvString ); x.setAttribute(\"download\",\"data_set.csv\"); document.body.appendChild(x); x.click(); } exportToCsv2000 = function(file_name) { var CsvString = \"\"; Results2000.forEach(function(RowItem, RowIndex) { RowItem.forEach(function(ColItem, ColIndex) { CsvString += ColItem; if( ColIndex < RowItem.length - 1){ CsvString += ','; } }); CsvString += \"\\r\\n\"; }); CsvString = \"data:application\/csv,\" + encodeURIComponent(CsvString); var x = document.createElement(\"A\"); x.setAttribute(\"href\", CsvString ); x.setAttribute(\"download\",\"data_set.csv\"); document.body.appendChild(x); x.click(); } <\/script>      1  0.1  0    2025073100    ma1: [ [1990, false], [1991, false], [1992, true], [1993, false], [1994, false], [1995, false], [1996, false], [1997, false], [1998, false], [1999, false], [2000, false], [2001, false], [2002, false], [2003, false], [2004, false], [2005, false], [2006, false], [2007, false], [2008, false], [2009, false], [2010, false], [2011, false], [2012, false], [2013, false], [2014, false], [2015, false], [2016, false] ]; ma2: [ [\"Palstond\", false], [\"Elamat\", true], [\"Unknown\", false] ]; ta3: 1869.80;            1  0  0   <span style=\"font-size: 1.5em; color:green;\"><i class=\"fa fa-check\"><\/i><\/span> Correct answer, well done.    <span style=\"font-size: 1.5em; color:orange;\"><i class=\"fa fa-adjust\"><\/i><\/span> Your answer is partially correct.    <span style=\"font-size: 1.5em; color:red;\"><i class=\"fa fa-times\"><\/i><\/span> Incorrect answer.   .  *10  none  1  i  cos-1  lang  [  0    ans1  dropdown  ma1  15  1  0   0    1  0  0  0  0     ans2  dropdown  ma2  15  1  0   0    1  0  0  0  0     ans3  algebraic  ta3  15  1  0   0    0  0  0  1  3     prt1  1.0000000  1  1   \/* node 1: check answers correct *\/ node1_test: if ans1=1992 and ans2=\"Elamat\" and ans3=1869.80 then 1 else 0; \/* node 2: fails to compare the units in each question *\/ node2_test: if ans1=2013 and ans2=\"Palstond\" and ans3=186.98 then 1 else 0; \/* node 3: treats 2000-16 stations as unknown *\/ node3_test: if ans1=1992 and member(ans2, [\"Palstond\", \"Unknown\"]) and ans3=1869.80 then 1 else 0; \/* node 4: disregards the order of the columns *\/ node4_test: if ans1=2013 and ans2=\"Elamat\" and member(ans3, [1869.8, 186.98]) then 1 else 0; \/* node 5: disregards the order of the columns *\/ node5_test: if ans1=1992 and ans2=\"Palstond\" and member(ans3, [17567.7, 175677]) then 1 else 0;    0  check correct answers  AlgEquiv  node1_test  1   1  =  1   -1  prt1-1-T   <p>Great! It appears that when combining the data sets, you have taken into account the different units used! <br>In addition, it seems that you have correctly appended the data sets together. <\/p> <br> <p>There is a worked solution of this problem <a href=\"https:\/\/ecampus.idems.international\/course\/view.php?id=238&amp;section=97\">here<\/a>. <\/p>   =  0   1  prt1-1-F       1  fails to compare the units in each question  AlgEquiv  node2_test  1   1  +  0   -1  prt1-2-T   <p>It appears that when combining the data sets, you have not taken into account the different units used. <br>Have a look at a plot of your rainfall by year. Does anything seem odd here? <br>We mentioned in the initial question that rainfall is measured in cm in one data set and mm in another. <\/p> <br> <p style=\"margin-left:30px\"><img src=\"https:\/\/github.com\/IDEMSInternational\/wxmaxima-stack\/blob\/main\/data-files\/appending-data-1.jpg?raw=true\"><\/p> <br> <p>Try again, but if stuck there is a worked solution of this problem <a href=\"https:\/\/ecampus.idems.international\/course\/view.php?id=238&amp;section=97\">here<\/a>. <\/p>   -  0   2  prt1-2-F       2  treats 2000-16 stations as unknown  AlgEquiv  node3_test  1   1  +  0   -1  prt1-3-T   <p>It appears that when combining the data sets, you have taken into account the different units used, which is great! <br>However, have a look at a plot of your rainfall by year with station included. Does anything seem odd here? <br>All stations from the year 2000 are unknown. Have a look at the station variable name in the two initial data sets. Can you see why this might have happened when combining the data? <\/p> <br> <p style=\"margin-left:30px\"><img src=\"https:\/\/github.com\/IDEMSInternational\/wxmaxima-stack\/blob\/main\/data-files\/appending-data-2.jpg?raw=true\"><\/p> <br> <p>Try again, but if stuck there is a worked solution of this problem <a href=\"https:\/\/ecampus.idems.international\/course\/view.php?id=238&amp;section=97\">here<\/a>. <\/p>   -  0   3  prt1-3-F       3  disregards the order of the columns  AlgEquiv  node4_test  1   0  +  0   -1  prt1-4-T   <p>It appears that when combining the data sets, you have not taken into account the order of the columns. <br>Have a look at the data - the columns are in a different order in the two data sets. <br>We can visualise this further by a plot of rainfall by year <br>We want to put both of the data sheets together. For this we go to Prepare &gt; Data Reshape &gt; Append dialogue in R-Instat. We suggest having a look at the tutorial on merging and appending data in R-Instat. <\/p> <br> <p style=\"margin-left:30px\"><img src=\"https:\/\/github.com\/IDEMSInternational\/wxmaxima-stack\/blob\/main\/data-files\/appending-data-4.jpg?raw=true\"><\/p> <br> <p>Try again, but if stuck there is a worked solution of this problem <a href=\"https:\/\/ecampus.idems.international\/course\/view.php?id=238&amp;section=97\">here<\/a>. <\/p>   -  0   4  prt1-4-F       4  disregards the order of the columns  AlgEquiv  node5_test  1   0  +  0   -1  prt1-5-T   <p>It appears that when combining the data sets, you have not taken into account the order of the columns. <br>Have a look at the data - the columns are in a different order in the two data sets. <br>We can visualise this further by a plot of rainfall by year <br>We want to put both of the data sheets together. For this we go to Prepare &gt; Data Reshape &gt; Append dialogue in R-Instat. We suggest having a look at the tutorial on merging and appending data in R-Instat. <\/p> <br> <p style=\"margin-left:30px\"><img src=\"https:\/\/github.com\/IDEMSInternational\/wxmaxima-stack\/blob\/main\/data-files\/appending-data-3.jpg?raw=true\"><\/p> <p>Try again, but if stuck there is a worked solution of this problem <a href=\"https:\/\/ecampus.idems.international\/course\/view.php?id=238&amp;section=97\">here<\/a>. <\/p>   -  0   -1  prt1-5-F   <p>Not quite - are you looking at the <b>overall rainfall<\/b> for each year? <br>We want to put both of the data sheets together. For this we go to Prepare &gt; Data Reshape &gt; Append dialogue in R-Instat. We suggest having a look at the tutorial on merging and appending data in R-Instat. <\/p> <br> <p>Try again, but if stuck there is a worked solution of this problem <a href=\"https:\/\/ecampus.idems.international\/course\/view.php?id=238&amp;section=97\">here<\/a>. <\/p>      1  Test case assuming the teacher's input gets full marks.   ans1  first(mcq_correct(ma1))    ans2  first(mcq_correct(ma2))    ans3  ta3    prt1  1.0000000  0.0000000  prt1-1-T       "
},
{
  "id": "sec-technical-skills-2-4",
  "level": "2",
  "url": "sec-technical-skills.html#sec-technical-skills-2-4",
  "type": "Checkpoint",
  "number": "[STRUCT].3",
  "title": "Missing Values.",
  "body": " Missing Values   This question uses a fixed external data set, converted to csv using custom Javascript within the STACK question. This is currently not supported in our PreText implementation; thus this question doesn't work here.        Missing Values    <p>Let's consider a survey conducted with 100 farms to gather information about their crop habits. Each farm was asked three specific questions regarding Maize, Sorghum, and Millet.<\/p> <ol> <li> Did they grow the crop last year?<\/li> <li>If yes, did the crop succeed enough to be sold?<\/li> <li>If sold, what was their profit?<\/li> <\/ol> <p><button onclick=\"exportToCsv()\">Download Data<\/button><\/p> <br> <p>Use the data provided to determine:<\/p> <p>1. &nbsp; (a) Which crop was the most profitable <strong>on average<\/strong>? <\/p><p style=\"margin-left:24px\">[[input:ans1]] [[validation:ans1]]<\/p> <p style=\"margin-left:24px\">(b) Which one was the least profitable <strong>on average<\/strong>? <\/p><p style=\"margin-left:24px\">[[input:ans2]] [[validation:ans2]]<\/p> <p>[[feedback:prt1]]<\/p> <br> <p>2. What is the mean profit for {@q2_crop@}?<\/p> <p>[[input:ans3]] [[validation:ans3]]<\/p> <p>[[feedback:prt3]]<\/p> <script> var Results; fetch(\"https:\/\/raw.githubusercontent.com\/IDEMSInternational\/wxmaxima-stack\/main\/data-files\/missing_values_1.txt\") .then(res => res.json()) .then(data => { Results = data; }) exportToCsv = function(file_name) { var CsvString = \"\"; Results.forEach(function(RowItem, RowIndex) { RowItem.forEach(function(ColItem, ColIndex) { CsvString += ColItem; if( ColIndex < RowItem.length - 1){ CsvString += ','; } }); CsvString += \"\\r\\n\"; }); CsvString = \"data:application\/csv,\" + encodeURIComponent(CsvString); var x = document.createElement(\"A\"); x.setAttribute(\"href\", CsvString ); x.setAttribute(\"download\",\"data_set.csv\"); document.body.appendChild(x); x.click(); } <\/script>      1  0.1  0    2025073100    ma_1: [[\"Sorghum\", false], [\"Millet\", true], [\"Maize\", false]]; ma_2: [[\"Sorghum\", true], [\"Millet\", false], [\"Maize\", false]]; q2_crop: rand([\"Maize\", \"Sorghum\", \"Millet\"]); ta_3: if q2_crop=\"Maize\" then 78.17708 elseif q2_crop=\"Sorghum\" then 66.15116 elseif q2_crop=\"Millet\" then 90.45833;       <p>Use the data provided to determine:<\/p> <p>1a. Which crop was the most profitable? = Sorghum<\/p> <p>1b. Which one was the least profitable? = Millet<\/p> <p>2. What is the mean profit for {@q2_crop@}? = {@ta_3@}<\/p>    <p id=\"author\">Mary Sayuni<\/p> <p id=\"concept\">https:\/\/docs.google.com\/document\/d\/1rByNEf43H7gNmyYm2Ez_O5pNMIFZPVzd0JTynd9a11M\/edit#heading=h.wvpxq8elfr9z<\/p> <p id=\"reviewer\">Dan Kelly<\/p> <p id=\"description\"><\/p>   1  0  0   <span style=\"font-size: 1.5em; color:green;\"><i class=\"fa fa-check\"><\/i><\/span> Correct answer, well done.    <span style=\"font-size: 1.5em; color:orange;\"><i class=\"fa fa-adjust\"><\/i><\/span> Your answer is partially correct.    <span style=\"font-size: 1.5em; color:red;\"><i class=\"fa fa-times\"><\/i><\/span> Incorrect answer.   .  *10  none  1  i  cos-1  lang  [  0    ans1  dropdown  ma_1  10  1  0   0    1  0  0  0  0     ans2  dropdown  ma_2  10  1  0   0    1  0  0  0  0     ans3  algebraic  ta_3  10  1  0   0    0  0  0  0  0     prt1  1.0000000  1  1   node3_test: if ans1=\"Sorghum\" and ans2=\"Millet\" then 1 else 0; node4_test: if ans1=\"Sorghum\" and ans2=\"Maize\" then 1 else 0; node5_test: if ans1=\"Maize\" and ans2=\"Millet\" then 1 else 0; node6_test: if ans1=\"Maize\" and ans2=\"Sorghum\" then 1 else 0; node7_test: if ans1=\"Millet\" and ans2=\"Maize\" then 1 else 0; node8_test: if ans1=\"Millet\" and ans2=\"Sorghum\" then 1 else 0;    2  gives sorghum and millet  AlgEquiv  node3_test  1  1  0  =  0   -1  prt1-3-T   <p>It appears that all of the missing values have been ignored in this question. However, we are looking at the most profitable crop. There are some crops which were grown which were not sold. Arguably the missing values in the profit columns therefore <b>do<\/b> have a value that we can give them.<\/p> <p>Alternatively, to get this answer it is possible that you have replaced the missing values with a different value, such as the mean. What value have you replaced them with? Does that make sense in this context? The mean, for example, might not make sense here. It is not that the profit is unknown, it is that there was no money made at all.<\/p>   -  0   3  prt1-3-F       3  gives sorghum and maize  AlgEquiv  node4_test  1  1  0  =  0   -1  prt1-4-T   <p>It appears that you have correctly identified to fill in the missing values. However, check the value that you are using to replace the missing values with. Does that make sense in this context? It is not that the profit is unknown, it is that there was no money made at all.<\/p>   -  0   4  prt1-4-F       4  gives maize and millet  AlgEquiv  node5_test  1  1  0  =  0   -1  prt1-5-T   <p>It appears that one of two things has happened here. We recommend looking at the averages not the sum, this is due to a difference in group sizes.<\/p><p>Alternatively, if you are looking at averages then it is great you have identified that the missing values in the profit columns <b>do<\/b> have a value that we can give them. However, it is incorrect that <b>all<\/b> missing values have a value we can estimate. Some missing values we may simply not know at all!<\/p>   -  0   5  prt1-5-F       5  gives maize and sorghum  AlgEquiv  node6_test  1  1  0  =  0   -1  prt1-6-T   <p>It appears that you have correctly identified to fill in the missing values. However, check the value that you are using to replace the missing values with. Does that make sense in this context? It is not that the profit is unknown, it is that there was no money made at all.<\/p>   -  0   6  prt1-6-F       6  gives millet and maize  AlgEquiv  node7_test  1  1  0  =  0   -1  prt1-7-T   <p>It appears that you have correctly identified to fill in the missing values. However, check the value that you are using to replace the missing values with. Does that make sense in this context? It is not that the profit is unknown, it is that there was no money made at all.<\/p>   -  0   7  prt1-7-F       7  gives millet and sorghum  AlgEquiv  node8_test  1   0  =  1   -1  prt1-8-T   <p>It appears that you have replaced some of the missing values, but not all of them. If an individual grew a crop, but were unable to sell, they arguably do not have a profit so their missing values do have a value we can give them. If instead an individual never grew a crop, we can ignore their missing values.<\/p>   -  0   -1  prt1-8-F        prt3  1.0000000  1  1   corr_ans_list: [decimalplaces(ta_3,0), decimalplaces(ta_3,1), decimalplaces(ta_3,2), decimalplaces(ta_3,3), decimalplaces(ta_3,4), ta_3]; node1_test: if member(ans3, corr_ans_list) then 1 else 0;    0  check correct answer, possibly rounded  AlgEquiv  node1_test  1   0  =  1   -1  prt3-1-T   <p>Great! The unprofitable crops have been given a profit of zero since they were grown but generated no income.<\/p> <p>The crops that were never grown, so had no chance to generate income, have been set as missing. This is correct!<\/p>   =  0   -1  prt3-1-F   <p>You have correctly identified which missing values should be replaced. However, the value that you have replaced them with seems to be incorrect.<\/p> <p>Check what you have replaced the missing values with, does that make sense in this context? It is not that the profit is unknown, it is that there was no money made at all from some crops.<\/p>     766382234  1385186126  659133753  1821788129  1521746292  1648618228  1454693563  1625344872  1944660833  1777464209  696566202  1993916139  1169651549  1210017344  1420680205  883759535  2130767947  1804150212  883239853  996318757   1  Test case assuming the teacher's input gets full marks.   ans1  first(mcq_correct(ma_1))    ans2  first(mcq_correct(ma_2))    ans3  ta_3    prt1  1.0000000  0.0000000  prt1-8-T    prt3  1.0000000  0.0000000  prt3-1-T       "
},
{
  "id": "sec-technical-skills-2-5",
  "level": "2",
  "url": "sec-technical-skills.html#sec-technical-skills-2-5",
  "type": "Checkpoint",
  "number": "[STRUCT].4",
  "title": "Pivot Tables 1.",
  "body": " Pivot Tables 1        Pivot Tables 1    <p>An experiment was performed to test the effect of two treatments on the yield. The two treatments are fertiliser and variety. There are three levels of fertiliser, and two different varieties.<\/p> <p>The task is to use the data below to answer the following questions <strong>using pivot tables<\/strong> to investigate how the treatments affect the yield.<\/p> <p><a href=\"[[textdownload name=\"data.csv\"]]{@stack_csv_formatter(data_set,header)@}[[\/textdownload]]\">Download Data<\/a><\/p> <br> <p>1. What is the {@quest_expr1@} yield obtained from the experiment? Give your answer to \\(2\\text{dp}\\)<\/p> <p>[[input:ans1]] [[validation:ans1]]<\/p> <p>[[feedback:prt1]]<\/p> <p>2. What is the {@quest_expr2@} yield for Variety \\(1\\)? Give your answer to \\(2\\text{dp}\\)<\/p> <p>[[input:ans2]] [[validation:ans2]]<\/p> <p>[[feedback:prt2]]<\/p> <p>3. What is the {@quest_expr3@} yield for Variety \\(1\\) when Fertiliser \\(1\\) is used? Give your answer to \\(2\\text{dp}\\)<\/p> <p>[[input:ans3]] [[validation:ans3]]<\/p> <p>[[feedback:prt3]]<\/p>    <p>Full details on how to create and use Pivot tables can be found <a href=\"https:\/\/docs.google.com\/document\/d\/1Q349NXt0AkStgVHHVkkDGBZVS-KT5Gl_IcdnSTemhEQ\/edit?usp=sharing\" target=\"_blank\">here<\/a>.   1  0.1  0    2025073100    \/*Information given by question authors*\/ factor_names:[\"Fertiliser\",\"Variety\"]; factors_info:[ [[0,\"Fertiliser 1\"],[5,\"Fertiliser 2\"],[7.5,\"Fertiliser 3\"]], [[0,\"Variety 1\"],[10,\"Variety 2\"]] ]; base_yield:50; error_mean:0; error_sd:5; replications:10; \/*Basic variables from inputs*\/ number_factors:length(factors_info); number_rows:product(length(factors_info[i]),i,1,length(factors_info))*replications; \/*Function to calculate the yield for a given data row*\/ \/*Input: list of coordinates for each factor*\/ \/*Output: expected yield for the given combination of factors without interactions*\/ effect_calculator(coords):=block( [ factors_info:factors_info, counter_1, effects_sum ], effects_sum:sum(factors_info[counter_1][coords[counter_1]][1],counter_1,1,length(factors_info)), return(effects_sum) ); \/*Function to create the labels for a given data row*\/ \/*Input: List of coordinates for each factor*\/ \/*Output: list of labels for the given combination of factors without interactions*\/ create_label(coords):=block( [ factors_info:factors_info, number_factors:number_factors, i, label_maker ], label_maker:makelist(factors_info[i][coords[i]][2],i,1,number_factors), return(label_maker) ); \/* Function to map position of item in list to coordinates in data list *\/ \/* Input: position of item in list, number between 1 and number_rows *\/ \/* Output: relevant coordinates in factors_info list *\/ pos_to_coords(num):=block( [factors_info:factors_info, number_factors:number_factors, number_rows:number_rows, factor_lengths, clock], factor_lengths: makelist(length(factors_info[i]),i,1,number_factors), \/* How regularly is each factor required to change value? *\/ clock:reverse(makelist( product(factor_lengths[j], j, number_factors+1-i, number_factors), i, 0, number_factors-1 )), return(makelist(mod(floor((num-1)\/clock[i]),factor_lengths[i])+1, i, 1, number_factors)) ); \/*Create the data set (all 0s) and the corresponding coordinates list*\/ data_set:makelist(makelist(0,j,1,number_factors+2),i,1,number_rows); coord_list:makelist(0,i,1,number_rows); \/*replce 0s with corresponding labels and generated yields (plus error term) using the relevant functions*\/ for i: 1 thru number_rows do ( coords: pos_to_coords(ceiling(i\/replications)), coord_list[i]: coords, yield_value: float(base_yield + effect_calculator(coords) + quantile_normal(rand(1.0),error_mean,error_sd)), label_value: create_label(coords), rep_value: if mod(i,replications) = 0 then replications else mod(i,replications), data_set[i]: append(label_value, [rep_value], [yield_value]) ); \/* Add headers row to data set *\/ header: append(factor_names, [\"Replication\", \"Yield\"]); data_set:append( [header], data_set ); \/* question 1 *\/ quest_expr1:rand([\"mean\",\"minimum\",\"maximum\"]); all_yields: makelist(data_set[i][4], i, 2, number_rows+1); ta_1: decimalplaces(if quest_expr1=\"mean\" then mean(all_yields) else if quest_expr1=\"minimum\" then first(sort(all_yields)) else if quest_expr1=\"maximum\" then last(sort(all_yields)) else if quest_expr1=\"median\" then median(all_yields), 2); \/* question 2 *\/ quest_expr2:rand([\"mean\",\"minimum\",\"maximum\"]); var1_list: sublist(data_set, lambda([x], is(x[2]=\"Variety 1\"))); var1_yields: makelist(var1_list[i][4], i, 1, length(var1_list)); ta_2: decimalplaces(if quest_expr2=\"mean\" then mean(var1_yields) else if quest_expr2=\"minimum\" then first(sort(var1_yields)) else if quest_expr2=\"maximum\" then last(sort(var1_yields)) else if quest_expr2=\"median\" then median(var1_yields), 2); \/* question 3 *\/ quest_expr3:rand([\"mean\",\"minimum\",\"maximum\"]); fert1_var1_list: sublist(var1_list, lambda([x], is(x[1]=\"Fertiliser 1\"))); fert1_var1_yields: makelist(fert1_var1_list[i][4], i, 1, length(fert1_var1_list)); ta_3: decimalplaces(if quest_expr3=\"mean\" then mean(fert1_var1_yields) else if quest_expr3=\"minimum\" then first(sort(fert1_var1_yields)) else if quest_expr3=\"maximum\" then last(sort(fert1_var1_yields)) else if quest_expr3=\"median\" then median(fert1_var1_yields), 2);       <p>What is the {@quest_expr1@} yield? Give to \\(2\\text{dp}\\) = {@ta_1@}<\/p> <p>What is the {@quest_expr2@} yield for Variety \\(1\\)? = {@ta_2@}<\/p> <p>What is the {@quest_expr3@} yield for Variety \\(1\\) when Fertiliser \\(1\\) is used? = {@ta_3@} <\/p>    <p id=\"author\">Mary Sayuni<\/p> <p id=\"concept\">https:\/\/docs.google.com\/document\/d\/1M1PSU_3ENRT4V35PLR4JsBVKLyTa6S3InVDAW4Hsqwg\/edit#heading=h.vy8x1tbmoha9<\/p> <p id=\"reviewer\">Dan Kelly<\/p> <p id=\"reviewer\"><\/p> <p id=\"description\"><\/p>   1  0  0   <span style=\"font-size: 1.5em; color:green;\"><i class=\"fa fa-check\"><\/i><\/span> Correct answer, well done.    <span style=\"font-size: 1.5em; color:orange;\"><i class=\"fa fa-adjust\"><\/i><\/span> Your answer is partially correct.    <span style=\"font-size: 1.5em; color:red;\"><i class=\"fa fa-times\"><\/i><\/span> Incorrect answer.   .  *10  dot  1  i  cos-1  lang  [  0    ans1  algebraic  ta_1  10  1  0   0    0  0  0  1  3     ans2  algebraic  ta_2  10  1  0   0    0  0  0  1  3     ans3  algebraic  ta_3  10  1  0   0    0  0  0  1  3     prt1  1.0000000  1  1   \/* node 3: check different summary statistic given *\/ all_summaries: [ decimalplaces(mean(all_yields),2), decimalplaces(first(sort(all_yields)),2), decimalplaces(last(sort(all_yields)),2), decimalplaces(median(all_yields),2) ]; node3_test: if member(ans1, all_summaries) then 1 else 0;    0  checks for correct summary  AlgEquiv  ans1  ta_1  2  1  =  1   -1  prt1-1-T   <p>You have correctly found the {@quest_expr1@} yield.<\/p>   =  0   1  prt1-1-F       1  check correct answer not to 2dp  NumAbsolute  ans1  ta_1  0.01  1  =  0.5   -1  prt1-2-T   <p>Your answer is correct, but do note that the question stated to give to \\(2\\text{dp}\\).<\/p>   -  0   2  prt1-2-F       2  check different summary statistic given  AlgEquiv  node3_test  1   1  =  0   -1  prt1-3-T   <p>Not quite, the question asking for the <b>{@quest_expr1@}<\/b> of the yield. <br>In a pivot table in Excel this can be achieved by clicking on the yield variable in the “Values” field, and selecting “Value Field Settings...”. <br>See <a href = “https:\/\/ecampus.idems.international\/course\/view.php?id=238&section=38”>here<\/a> for an example in Excel.<\/p>   -  0   -1  prt1-3-F   <p>Not quite. This can be achieved in spreadsheet software with PivotTables quite nicely. <br>For example, see <a href = “https:\/\/ecampus.idems.international\/course\/view.php?id=238&section=38”>here<\/a> how to set up PivotTables in Excel. <br>Here, we have just one variable, Yield, that we want to look at the summary of. So we just have to enter “Yield” into the “Value” box, and select the appropriate statistic.<\/p>      prt2  1.0000000  1  1   \/* node 3: check different summary statistic given *\/ all_var1_summaries: [ decimalplaces(mean(var1_yields),2), decimalplaces(first(sort(var1_yields)),2), decimalplaces(last(sort(var1_yields)),2), decimalplaces(median(var1_yields),2) ]; node3_test: if member(ans1, all_var1_summaries) then 1 else 0; \/* node 4: check summary statistic taken over all data *\/ node4_mist: decimalplaces(if quest_expr2=\"mean\" then mean(all_yields) else if quest_expr2=\"minimum\" then first(sort(all_yields)) else if quest_expr2=\"maximum\" then last(sort(all_yields)) else if quest_expr2=\"median\" then median(all_yields), 2);    0  checks for correct summary of variety 1  AlgEquiv  ans2  ta_2  2  0  =  1   -1  prt2-1-T   <p>You have correctly found the {@quest_expr2@} yield for variety \\(1\\).<\/p>   =  0   1  prt2-1-F       1  checks for correct answer not to 2dp  NumAbsolute  ans1  ta_2  0.01  0  =  0.5   -1  prt2-2-T   <p>Your answer is correct, but do note that the question stated to give to \\(2\\text{dp}\\).<\/p>   -  0   2  prt2-2-F       2  check different summary statistic given  AlgEquiv  node3_test  1   0  =  0   -1  prt2-3-T   <p>Not quite, the question asking for the <b>{@quest_expr2@}<\/b> of the yield. <br>In a pivot table in Excel this can be achieved by clicking on the yield variable in the “Values” field, and selecting “Value Field Settings...”. <br>See <a href = “https:\/\/ecampus.idems.international\/course\/view.php?id=238&section=38”>here<\/a> for an example in Excel.<\/p>   -  0   3  prt2-3-F       3  check for summary yield of all data  AlgEquiv  ans2  node4_mist   0  +  0   -1  prt2-4-T   <p>Close, you have correctly found the {@quest_expr2@} yield overall. But we want to look at just for variety \\(1\\). <br>This could be achieved by using the “Filter”, “Rows”, or “Columns” field if you put the \"Variety\" variable in it.<\/p>   -  0   -1  prt2-4-F   <p>Not quite. This can be achieved in spreadsheet software with PivotTables quite nicely. <br>For example, see <a href = “https:\/\/ecampus.idems.international\/course\/view.php?id=238&section=38”>here<\/a> how to set up PivotTables in Excel. <br>Here,\"Variety\" variable needs to be dragged into either rows or columns because we are interested in the maximum yield for Variety 1. we have just one variable, Yield, that we want to look at the summary of. So we just have to enter “Yield” into the “Value” box, and select the appropriate statistic.<\/p>      prt3  1.0000000  1  1   \/* node 3: check different summary statistic given *\/ all_fert1_var1_summaries: [ decimalplaces(mean(fert1_var1_yields),2), decimalplaces(first(sort(fert1_var1_yields)),2), decimalplaces(last(sort(fert1_var1_yields)),2), decimalplaces(median(fert1_var1_yields),2) ]; node3_test: if member(ans1, all_fert1_var1_summaries) then 1 else 0; \/* node 4: check summary statistic taken over all data *\/ node4_mist: decimalplaces(if quest_expr3=\"mean\" then mean(all_yields) else if quest_expr3=\"minimum\" then first(sort(all_yields)) else if quest_expr3=\"maximum\" then last(sort(all_yields)) else if quest_expr3=\"median\" then median(all_yields), 2); \/* node 5: check for statistics of variety 1 with fertiliser 2 *\/ fert2_var1_list: sublist(var1_list, lambda([x], is(x[1]=\"Fertiliser 2\"))); fert2_var1_yields: makelist(fert1_var1_list[i][4], i, 1, length(fert2_var1_list)); node5_mist: decimalplaces(if quest_expr3=\"mean\" then mean(fert2_var1_yields) else if quest_expr3=\"minimum\" then first(sort(fert2_var1_yields)) else if quest_expr3=\"maximum\" then last(sort(fert2_var1_yields)) else if quest_expr3=\"median\" then median(fert2_var1_yields), 2);    0  checks for correct summary of variety 1 with fertiliser 1  NumDecPlaces  ans3  ta_3  2  0  =  1   -1  prt3-1-T   <p>You have correctly found the {@quest_expr3@} yield for variety \\(1\\) with fertiliser \\(1\\).<\/p>   =  0   1  prt3-1-F       1  checks for correct answer not to 2dp  NumAbsolute  ans3  ta_3  0.01  0  =  0.5   -1  prt3-2-T   <p>Your answer is correct, but do note that the question stated to give to \\(2\\text{dp}\\).<\/p>   -  0   2  prt3-2-F       2  check different summary statistic given  AlgEquiv  node_3  true   0  =  0   -1  prt3-3-T   <p>Not quite, the question asking for the <b>{@quest_expr3@}<\/b> of the yield. <br>In a pivot table in Excel this can be achieved by clicking on the yield variable in the “Values” field, and selecting “Value Field Settings...”. <br>See <a href = “https:\/\/ecampus.idems.international\/course\/view.php?id=238&section=38”>here<\/a> for an example in Excel.<\/p>   -  0   3  prt3-3-F       3  check for summary yield of all data  AlgEquiv  ans3  node4_mist   0  +  0   -1  prt3-4-T   <p>Close, you have correctly found the {@quest_expr3@} yield overall. But we want to look at just for variety \\(1\\) with fertiliser \\(1\\). <br>This could be achieved by using the “Filter”, “Rows”, or “Columns” field if you put both \"Variety\" and \"Fertiliser\" variables in. It can be clearer to read if you put the two variables in different fields (e.g. one in Rows, one in Columns).<\/p>   -  0   4  prt3-4-F       4  checks for summary of variety 1 with fertiliser 2  AlgEquiv  ans3  node5_mist   0  +  0   -1  prt3-5-T   <p>Nearly! But it appears you have considered the {@quest_expr3@} yield for Variety \\(1\\) when <b>Fertiliser \\(2\\)<\/b> is used, whereas you should have considered when Fertiliser \\(1\\) is used.<\/p>   -  0   -1  prt3-5-F   <p>Not quite. This can be achieved in a spreadsheet software with PivotTables quite nicely. <br>For example, see <a href = “https:\/\/ecampus.idems.international\/course\/view.php?id=238&section=38”>here<\/a> how to set PivotTables up in Excel. <br>Here, we want to look at the summary of the yield. So we just have to enter “Yield” into the “Value” box, and select the appropriate statistic. <br>We want to look at the summary for Variety \\(1\\) and Fertiliser \\(1\\). This could be achieved by using the “Filter”, “Rows”, or “Columns” field if you put both Variety and Fertiliser variables in. It can be clearer to read if you put the two variables in different fields (e.g., one in rows, one in columns).<\/p>     1355139652  1475793692  1405099942  727222688  1764488602  1053645696  1288483347  475981690  481921617  1353148035  866212287  436996953  1660075351  730573743  904169792  1115876400  670670297  602749870  404838629  623713637  2118629351  2131612391  168296508  45063621  1495572133  1742423102  1402523416  308469964  185795511  1203733811  1074427199  549090432  1337413149  574739707  115640412  1407978313  256245980  1768024716  1008859308  1605583616  576027506  402504456  150988869  1300971250  1710526984  1642684398  847948150  847804899  1477761924  1892436444  72915408  185086187  1691708515  756983254  717066796  1512322050  1626724629  1221133754  2096203562  53795210  1630946381  2049744063  16078295  135814621  1034882438  938211424  359410580  278389719   1    ans1  ta_1    ans2  ta_2    ans3  ta_3    prt1  1.0000000  0.0000000  prt1-1-T    prt2  1.0000000  0.0000000  prt2-1-T    prt3  1.0000000  0.0000000  prt3-1-T       "
},
{
  "id": "backmatter-2",
  "level": "1",
  "url": "backmatter-2.html",
  "type": "Colophon",
  "number": "",
  "title": "Colophon",
  "body": " This book was authored in PreTeXt . By the following contibutiong team;   Rodgers Maragia    Daniel Murunga    Henry Onyango    Isdora Akinyi    Michael Onyimbo    Joseph Baya    Armstrong Opondo    Eric Morara    Sheila Cherotich    Hariet Moraa    Monica Auma    Georg Osang     "
}
]

var ptx_lunr_idx = lunr(function () {
  this.ref('id')
  this.field('title')
  this.field('body')
  this.metadataWhitelist = ['position']

  ptx_lunr_docs.forEach(function (doc) {
    this.add(doc)
  }, this)
})
