<?xml version="1.0" encoding="UTF-8"?>
<quiz>
  <question type="stack">
    <name>
      <text>Model Comparison</text>
    </name>
    <questiontext format="html">
      <text><![CDATA[<p>This question is based on research by Dr. Francis Torgbor in his MPhil Thesis.</p>

<p>The thesis looks to create a useful guide in preparation of the effect of rainfall patterns in Ghana. Understanding and modelling rainfall patterns is important. To understand and model the patterns, we need to account for the variability - there is a large variability in rainfall, and this variability can have serious implications on various aspects such as food production and livelihoods. In an attempt to attain a model that describes the pattern for the chance of rain, multiple models were found and then compared to find the “best” model. We will look at two of these models, and call them Model A and Model B.</p>

<p>The difference between Model A and B is about whether interactions should be included. That is, in Model B, the Markov component corresponding to the dependence of the rainfall on previous days interacts with the seasonality. In Model A, there is no interaction.</p>

<p>This illustrative scenario compares the performance of Model A with Model B.</p>

<p>An Analysis of Deviance table can be performed to look at the fit of generalised linear models (GLMs). In brief, deviance is a measure of the difference between the actual values and the fitted model. Like in an ANOVA, an Analysis of Deviance gives a residual deviance - this is  the variability that is not accounted for in the model. Therefore, a smaller residual deviance is preferable when fitting a model.</p>

<br>

<table>
    <tbody><tr>
        <td width="180px" style="padding:5px"><b>Model A:</b></td>
        <td width="100px"></td>
        <td width="100px"></td>
        <td width="50px"></td>
        <td width="180px" style="padding:5px"><b>Model B:</b></td>
        <td width="100px"></td>
        <td width="100px"></td>
    </tr>

    <tr>
        <td style="border: 1px solid black; border-collapse: collapse; padding:5px"><b>Source of Deviation</b></td>
        <td style="border: 1px solid black; border-collapse: collapse; padding:5px"><b>DF</b></td>
        <td style="border: 1px solid black; border-collapse: collapse; padding:5px"><b>Deviance</b></td>
        <td></td>
        <td style="border: 1px solid black; border-collapse: collapse; padding:5px"><b>Source of Deviation</b></td>
        <td style="border: 1px solid black; border-collapse: collapse; padding:5px"><b>DF</b></td>
        <td style="border: 1px solid black; border-collapse: collapse; padding:5px"><b>Deviance</b></td>
    </tr>

    <tr>
        <td style="border: 1px solid black; border-collapse: collapse; padding:5px">Accounted for</td>
        <td style="border: 1px solid black; border-collapse: collapse; padding:5px">{@modA_df_accounted@}</td>
        <td style="border: 1px solid black; border-collapse: collapse; padding:5px">{@modA_dev_accounted@}</td>
        <td></td>
        <td style="border: 1px solid black; border-collapse: collapse; padding:5px">Accounted for</td>
        <td style="border: 1px solid black; border-collapse: collapse; padding:5px">{@modB_df_accounted@}</td>
        <td style="border: 1px solid black; border-collapse: collapse; padding:5px">{@modB_dev_accounted@}</td>
    </tr>

    <tr>
        <td style="border: 1px solid black; border-collapse: collapse; padding:5px">Residual</td>
        <td style="border: 1px solid black; border-collapse: collapse; padding:5px">{@modA_df_residual@}</td>
        <td style="border: 1px solid black; border-collapse: collapse; padding:5px">{@modA_dev_residual@}</td>
        <td></td>
        <td style="border: 1px solid black; border-collapse: collapse; padding:5px">Residual</td>
        <td style="border: 1px solid black; border-collapse: collapse; padding:5px">{@modB_df_residual@}</td>
        <td style="border: 1px solid black; border-collapse: collapse; padding:5px">{@modB_dev_residual@}</td>
    </tr>

    <tr>
        <td style="border: 1px solid black; border-collapse: collapse; padding:5px">Total</td>
        <td style="border: 1px solid black; border-collapse: collapse; padding:5px">{@modA_df_total@}</td>
        <td style="border: 1px solid black; border-collapse: collapse; padding:5px">{@modA_dev_total@}</td>
        <td></td>
        <td style="border: 1px solid black; border-collapse: collapse; padding:5px">Total</td>
        <td style="border: 1px solid black; border-collapse: collapse; padding:5px">{@modB_df_total@}</td>
        <td style="border: 1px solid black; border-collapse: collapse; padding:5px">{@modB_dev_total@}</td>
    </tr>
</tbody></table>

<br>

<p>1. Which is the correct model?</p>
<p>[[input:ans1]] [[validation:ans1]]</p>
<p>[[feedback:prt1]]</p>

<br>

<p>2. Given the information you have, which model accounts for more variability out of A and B?</p>
<p>[[input:ans2]] [[validation:ans2]]</p>
<p>[[feedback:prt2]]</p>

<br>

<p>3. We now use the Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC) to compare these models. In both cases, a model with a lower AIC or BIC value is said to perform better.</p>

<table>
    <tbody><tr>
        <td width="100px" style="border: 1px solid black; border-collapse: collapse; padding:5px"><b>Model</b></td>
        <td width="100px" style="border: 1px solid black; border-collapse: collapse; padding:5px"><b>Parameters</b></td>
        <td width="100px" style="border: 1px solid black; border-collapse: collapse; padding:5px"><b>AIC</b></td>
        <td width="100px" style="border: 1px solid black; border-collapse: collapse; padding:5px"><b>BIC</b></td>
    </tr>
    <tr>
        <td width="100px" style="border: 1px solid black; border-collapse: collapse; padding:5px">A</td>
        <td width="100px" style="border: 1px solid black; border-collapse: collapse; padding:5px">{@modA_param@}</td>
        <td width="100px" style="border: 1px solid black; border-collapse: collapse; padding:5px">{@modA_AIC@}</td>
        <td width="100px" style="border: 1px solid black; border-collapse: collapse; padding:5px">{@modA_BIC@}</td>
    </tr>
    <tr>
        <td width="100px" style="border: 1px solid black; border-collapse: collapse; padding:5px">B</td>
        <td width="100px" style="border: 1px solid black; border-collapse: collapse; padding:5px">{@modB_param@}</td>
        <td width="100px" style="border: 1px solid black; border-collapse: collapse; padding:5px">{@modB_AIC@}</td>
        <td width="100px" style="border: 1px solid black; border-collapse: collapse; padding:5px">{@modB_BIC@}</td>
    </tr>
</tbody></table>

<br>

<p>Which model performs better out of A and B?</p>
<p>[[input:ans3]] [[validation:ans3]]</p>
<p>[[feedback:prt3]]</p>]]></text>
    </questiontext>
    <generalfeedback format="html">
      <text/>
    </generalfeedback>
    <defaultgrade>1</defaultgrade>
    <penalty>0.1</penalty>
    <hidden>0</hidden>
    <idnumber/>
    <stackversion>
      <text>2025073100</text>
    </stackversion>
    <questionvariables>
      <text><![CDATA[modA_df_accounted: 7;
modA_dev_accounted: 3417;
modA_df_residual: 16771;
modA_dev_residual: 13015;
modA_df_total: modA_df_accounted+modA_df_residual;
modA_dev_total: modA_dev_accounted+modA_dev_residual;

modB_df_accounted: 19;
modB_dev_accounted: 3521;
modB_df_residual: 16759;
modB_dev_residual: 12911;
modB_df_total: modB_df_accounted+modB_df_residual;
modB_dev_total: modB_dev_accounted+modB_dev_residual;

modA_param: 8;
modA_AIC: 13031;
modA_BIC: 13092;
modB_param: 20;
modB_AIC: 12951;
modB_BIC: 13106;

m_ans1: [
    ["A", false],
    ["B", false],
    ["Neither", true]
];

m_ans2: [
    ["A", false],
    ["B", true],
    ["It depends", false]
];

m_ans3: [
    ["A", false],
    ["B", false],
    ["It depends", true]
];]]></text>
    </questionvariables>
    <specificfeedback format="html">
      <text/>
    </specificfeedback>
    <questionnote format="moodle_auto_format">
      <text/>
    </questionnote>
    <questiondescription format="html">
      <text><![CDATA[<p id="author">Dan Kelly</p>
<p id="concept">https://docs.google.com/document/d/1SCVlmN0RPhDBou73SBHXyo6eZdo0PWDsFmgj1H2Jly8/edit</p>
<p id="reviewer"></p>
<p id="description"></p>]]></text>
    </questiondescription>
    <questionsimplify>1</questionsimplify>
    <assumepositive>0</assumepositive>
    <assumereal>0</assumereal>
    <prtcorrect format="html">
      <text><![CDATA[<span style="font-size: 1.5em; color:green;"><i class="fa fa-check"></i></span> Correct answer, well done.]]></text>
    </prtcorrect>
    <prtpartiallycorrect format="html">
      <text><![CDATA[<span style="font-size: 1.5em; color:orange;"><i class="fa fa-adjust"></i></span> Your answer is partially correct.]]></text>
    </prtpartiallycorrect>
    <prtincorrect format="html">
      <text><![CDATA[<span style="font-size: 1.5em; color:red;"><i class="fa fa-times"></i></span> Incorrect answer.]]></text>
    </prtincorrect>
    <decimals>.</decimals>
    <scientificnotation>*10</scientificnotation>
    <multiplicationsign>none</multiplicationsign>
    <sqrtsign>1</sqrtsign>
    <complexno>i</complexno>
    <inversetrig>cos-1</inversetrig>
    <logicsymbol>lang</logicsymbol>
    <matrixparens>[</matrixparens>
    <isbroken>0</isbroken>
    <variantsselectionseed/>
    <input>
      <name>ans1</name>
      <type>dropdown</type>
      <tans>m_ans1</tans>
      <boxsize>15</boxsize>
      <strictsyntax>1</strictsyntax>
      <insertstars>0</insertstars>
      <syntaxhint/>
      <syntaxattribute>0</syntaxattribute>
      <forbidwords/>
      <allowwords/>
      <forbidfloat>1</forbidfloat>
      <requirelowestterms>0</requirelowestterms>
      <checkanswertype>0</checkanswertype>
      <mustverify>0</mustverify>
      <showvalidation>0</showvalidation>
      <options/>
    </input>
    <input>
      <name>ans2</name>
      <type>dropdown</type>
      <tans>m_ans2</tans>
      <boxsize>15</boxsize>
      <strictsyntax>1</strictsyntax>
      <insertstars>0</insertstars>
      <syntaxhint/>
      <syntaxattribute>0</syntaxattribute>
      <forbidwords/>
      <allowwords/>
      <forbidfloat>1</forbidfloat>
      <requirelowestterms>0</requirelowestterms>
      <checkanswertype>0</checkanswertype>
      <mustverify>0</mustverify>
      <showvalidation>0</showvalidation>
      <options/>
    </input>
    <input>
      <name>ans3</name>
      <type>dropdown</type>
      <tans>m_ans3</tans>
      <boxsize>15</boxsize>
      <strictsyntax>1</strictsyntax>
      <insertstars>0</insertstars>
      <syntaxhint/>
      <syntaxattribute>0</syntaxattribute>
      <forbidwords/>
      <allowwords/>
      <forbidfloat>1</forbidfloat>
      <requirelowestterms>0</requirelowestterms>
      <checkanswertype>0</checkanswertype>
      <mustverify>0</mustverify>
      <showvalidation>0</showvalidation>
      <options/>
    </input>
    <prt>
      <name>prt1</name>
      <value>1.0000000</value>
      <autosimplify>1</autosimplify>
      <feedbackstyle>1</feedbackstyle>
      <feedbackvariables>
        <text/>
      </feedbackvariables>
      <node>
        <name>0</name>
        <description>check correct answer</description>
        <answertest>AlgEquiv</answertest>
        <sans>ans1</sans>
        <tans><![CDATA["Neither"]]></tans>
        <testoptions/>
        <quiet>0</quiet>
        <truescoremode>=</truescoremode>
        <truescore>1</truescore>
        <truepenalty/>
        <truenextnode>-1</truenextnode>
        <trueanswernote>prt1-1-T</trueanswernote>
        <truefeedback format="html">
          <text><![CDATA[<p>Great! We asked for the <b>correct</b> model. But, no model is correct.
<br>Let’s rephrase.</p>]]></text>
        </truefeedback>
        <falsescoremode>=</falsescoremode>
        <falsescore>0</falsescore>
        <falsepenalty/>
        <falsenextnode>-1</falsenextnode>
        <falseanswernote>prt1-1-F</falseanswernote>
        <falsefeedback format="html">
          <text><![CDATA[<p>Nice try! But, we asked for the <b>correct</b> model. However, no model is correct.
<br>Let’s rephrase.</p>]]></text>
        </falsefeedback>
      </node>
    </prt>
    <prt>
      <name>prt2</name>
      <value>1.0000000</value>
      <autosimplify>1</autosimplify>
      <feedbackstyle>1</feedbackstyle>
      <feedbackvariables>
        <text/>
      </feedbackvariables>
      <node>
        <name>0</name>
        <description>check correct answer</description>
        <answertest>AlgEquiv</answertest>
        <sans>ans2</sans>
        <tans><![CDATA["B"]]></tans>
        <testoptions/>
        <quiet>0</quiet>
        <truescoremode>=</truescoremode>
        <truescore>1</truescore>
        <truepenalty/>
        <truenextnode>-1</truenextnode>
        <trueanswernote>prt2-1-T</trueanswernote>
        <truefeedback format="html">
          <text><![CDATA[<p>The residual deviance is <b>smaller</b> in model B than in model A, so model B accounts for more variability than A.</p>]]></text>
        </truefeedback>
        <falsescoremode>=</falsescoremode>
        <falsescore>0</falsescore>
        <falsepenalty/>
        <falsenextnode>1</falsenextnode>
        <falseanswernote>prt2-1-F</falseanswernote>
        <falsefeedback format="html">
          <text/>
        </falsefeedback>
      </node>
      <node>
        <name>1</name>
        <description>feedback for incorrect answers</description>
        <answertest>AlgEquiv</answertest>
        <sans>ans2</sans>
        <tans><![CDATA["A"]]></tans>
        <testoptions/>
        <quiet>0</quiet>
        <truescoremode>+</truescoremode>
        <truescore>0</truescore>
        <truepenalty/>
        <truenextnode>-1</truenextnode>
        <trueanswernote>prt2-2-T</trueanswernote>
        <truefeedback format="html">
          <text><![CDATA[<p>Not quite, we want the model with the <b>smallest</b> residual deviance. 
<br>We can see that model B has a smaller residual deviance than model A. This means that more variability is accounted for in model B.</p>]]></text>
        </truefeedback>
        <falsescoremode>-</falsescoremode>
        <falsescore>0</falsescore>
        <falsepenalty/>
        <falsenextnode>-1</falsenextnode>
        <falseanswernote>prt2-2-F</falseanswernote>
        <falsefeedback format="html">
          <text><![CDATA[<p>Not quite, the deviance is a measure of variability, and here the residual deviance is <b>smaller</b> in model B than in model A. 
<br>Hence, Model B accounts for more variability than A.</p>]]></text>
        </falsefeedback>
      </node>
    </prt>
    <prt>
      <name>prt3</name>
      <value>1.0000000</value>
      <autosimplify>1</autosimplify>
      <feedbackstyle>1</feedbackstyle>
      <feedbackvariables>
        <text/>
      </feedbackvariables>
      <node>
        <name>0</name>
        <description>check correct answer</description>
        <answertest>AlgEquiv</answertest>
        <sans>ans3</sans>
        <tans><![CDATA["It depends"]]></tans>
        <testoptions/>
        <quiet>0</quiet>
        <truescoremode>=</truescoremode>
        <truescore>1</truescore>
        <truepenalty/>
        <truenextnode>-1</truenextnode>
        <trueanswernote>prt3-1-T</trueanswernote>
        <truefeedback format="html">
          <text><![CDATA[<p>Which measure is the one to use here depends on your research question:
    <br>Is it better to account for more variability, or to account for variability more efficiently? This is the difference between AIC and BIC.
</p>
<br>
<p>We have two different model comparisons, AIC and BIC. These categorise models differently because they are prioritising different things.</p>
<p>We shouldn’t always use one comparison method over the other, but rather use the approach that makes more sense in the context: This comes back to the objectives on what is the best approach to compare models. Whether it is good or not, is whether it is useful for your research objectives.</p>
<p>In this particular case, the author states that 
“In this context, a suitable model is being regarded as the model that explains more variability but with less complexity.”</p>
<p>In other words, they favour BIC over AIC, so, in their context, they prefer Model A over B.</p>
<p>While the statistical model is important for publication, the choice of model often makes little difference in terms of interpretation.</p><em>

For more information, if you are interested:<br></em>Some model comparison metrics define a better model as one that accounts for more variability, this is like seen with AIC. In this instance, Model B outperforms Model A. 

Some model comparison metrics define a better model as one that accounts for variability efficiently, that is, with fewer parameters. This is like seen with the second method using BIC. 

BIC penalises more complexity in a model (that is, models with more parameters - including interactions) more than AIC. Hence, the BIC suggests that Model A outperforms Model B.]]></text>
        </truefeedback>
        <falsescoremode>=</falsescoremode>
        <falsescore>0</falsescore>
        <falsepenalty/>
        <falsenextnode>1</falsenextnode>
        <falseanswernote>prt3-1-F</falseanswernote>
        <falsefeedback format="html">
          <text/>
        </falsefeedback>
      </node>
      <node>
        <name>1</name>
        <description>feedback for incorrect answers</description>
        <answertest>AlgEquiv</answertest>
        <sans>ans3</sans>
        <tans><![CDATA["A"]]></tans>
        <testoptions/>
        <quiet>0</quiet>
        <truescoremode>+</truescoremode>
        <truescore>0</truescore>
        <truepenalty/>
        <truenextnode>-1</truenextnode>
        <trueanswernote>prt3-2-T</trueanswernote>
        <truefeedback format="html">
          <text><![CDATA[<p>That could be correct but it depends on the research question. Is it more important to account for more variability or to account for variability more efficiently?
<br>The smaller AIC value suggests that Model B outperforms A. But, the smaller BIC value suggests that Model A outperforms B.
<br>Whether we want to use AIC or BIC is unknown here <b>since the research objectives have not been stated in the question</b>.</p><p><br></p><p></p><p>We have two different model comparisons, AIC and BIC. These categorise models differently because they are prioritising different things.</p><p>We shouldn’t always use one comparison method over the other, but rather use the approach that makes more sense in the context: This comes back to the objectives on what is the best approach to compare models. Whether it is good or not, is whether it is useful for your research objectives.</p><p>In this particular case, the author states that “In this context, a suitable model is being regarded as the model that explains more variability but with less complexity.”</p><p>In other words, they favour BIC over AIC, so, in their context, they prefer Model A over B.</p><p>While the statistical model is important for publication, the choice of model often makes little difference in terms of interpretation.</p><em>For more information, if you are interested:<br></em>Some model comparison metrics define a better model as one that accounts for more variability, this is like seen with AIC. In this instance, Model B outperforms Model A. Some model comparison metrics define a better model as one that accounts for variability efficiently, that is, with fewer parameters. This is like seen with the second method using BIC. BIC penalises more complexity in a model (that is, models with more parameters - including interactions) more than AIC. Hence, the BIC suggests that Model A outperforms Model B.<br><p></p>]]></text>
        </truefeedback>
        <falsescoremode>-</falsescoremode>
        <falsescore>0</falsescore>
        <falsepenalty/>
        <falsenextnode>-1</falsenextnode>
        <falseanswernote>prt3-2-F</falseanswernote>
        <falsefeedback format="html">
          <text><![CDATA[<p>That could be correct but it depends on the research question. Is it more important to account for more variability or to account for variability more efficiently?
<br>The smaller AIC value suggests that Model B outperforms A. But, the smaller BIC value suggests that Model A outperforms B.
<br>Whether we want to use AIC or BIC is unknown here <b>since the research objectives have not been stated in the question</b>.</p><p><br></p><p></p><p>We have two different model comparisons, AIC and BIC. These categorise models differently because they are prioritising different things.</p><p>We shouldn’t always use one comparison method over the other, but rather use the approach that makes more sense in the context: This comes back to the objectives on what is the best approach to compare models. Whether it is good or not, is whether it is useful for your research objectives.</p><p>In this particular case, the author states that “In this context, a suitable model is being regarded as the model that explains more variability but with less complexity.”</p><p>In other words, they favour BIC over AIC, so, in their context, they prefer Model A over B.</p><p>While the statistical model is important for publication, the choice of model often makes little difference in terms of interpretation.</p><em>For more information, if you are interested:<br></em>Some model comparison metrics define a better model as one that accounts for more variability, this is like seen with AIC. In this instance, Model B outperforms Model A. Some model comparison metrics define a better model as one that accounts for variability efficiently, that is, with fewer parameters. This is like seen with the second method using BIC. BIC penalises more complexity in a model (that is, models with more parameters - including interactions) more than AIC. Hence, the BIC suggests that Model A outperforms Model B.<br><p></p>]]></text>
        </falsefeedback>
      </node>
    </prt>
    <qtest>
      <testcase>1</testcase>
      <description>Test case assuming the teacher's input gets full marks.</description>
      <testinput>
        <name>ans1</name>
        <value>first(mcq_correct(m_ans1))</value>
      </testinput>
      <testinput>
        <name>ans2</name>
        <value>first(mcq_correct(m_ans2))</value>
      </testinput>
      <testinput>
        <name>ans3</name>
        <value>first(mcq_correct(m_ans3))</value>
      </testinput>
      <expected>
        <name>prt1</name>
        <expectedscore>1.0000000</expectedscore>
        <expectedpenalty>0.0000000</expectedpenalty>
        <expectedanswernote>prt1-1-T</expectedanswernote>
      </expected>
      <expected>
        <name>prt2</name>
        <expectedscore>1.0000000</expectedscore>
        <expectedpenalty>0.0000000</expectedpenalty>
        <expectedanswernote>prt2-1-T</expectedanswernote>
      </expected>
      <expected>
        <name>prt3</name>
        <expectedscore>1.0000000</expectedscore>
        <expectedpenalty>0.0000000</expectedpenalty>
        <expectedanswernote>prt3-1-T</expectedanswernote>
      </expected>
    </qtest>
  </question>
</quiz>
